{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "# import summary\n",
    "from model_model import WIDAEV1\n",
    "from model_dataset import DS_Tools\n",
    "from model_dataset import WordDatasetWord as TrainDataset\n",
    "from model_dataset import TargetVowelDataset as TestDataset\n",
    "from model_dataset import Normalizer, DeNormalizer, TokenMap\n",
    "from model_dataset import MelSpecTransformDB as TheTransform\n",
    "from paths import *\n",
    "from misc_my_utils import *\n",
    "from misc_recorder import *\n",
    "from model_loss import *\n",
    "from model_padding import generate_mask_from_lengths_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_guide_path = os.path.join(src_, \"guide_train.csv\")\n",
    "valid_guide_path = os.path.join(src_, \"guide_validation.csv\")\n",
    "test_guide_path = os.path.join(src_, \"guide_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'chapter' 'ninety' ... 'sceptics' 'commingled' 'slided']\n"
     ]
    }
   ],
   "source": [
    "train_guide = pd.read_csv(train_guide_path)\n",
    "valid_guide = pd.read_csv(valid_guide_path)\n",
    "test_guide = pd.read_csv(test_guide_path)\n",
    "\n",
    "concatenated_guide = pd.concat([train_guide, valid_guide, test_guide])\n",
    "\n",
    "unique_words = concatenated_guide['word'].unique()\n",
    "print(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       segment              file   id  startTime  endTime  nSample  word_id  \\\n",
      "0          sil  1034-121119-0000    0       0.00     0.19     3040      NaN   \n",
      "14          sp  1034-121119-0000   14       1.72     2.45    11680      NaN   \n",
      "19          sp  1034-121119-0000   19       3.16     6.05    46240      NaN   \n",
      "37          sp  1034-121119-0000   37       7.71     7.86     2400      NaN   \n",
      "38         sil  1034-121119-0001    0       0.00     0.32     5120      NaN   \n",
      "...        ...               ...  ...        ...      ...      ...      ...   \n",
      "376735      sp   887-123291-0042   48       4.17     4.56     6240      NaN   \n",
      "376754      sp   887-123291-0042   67       6.65     7.31    10560      NaN   \n",
      "376780      sp   887-123291-0042   93       9.18     9.67     7840      NaN   \n",
      "376783      sp   887-123291-0042   96      10.18    10.30     1920      NaN   \n",
      "376840      sp   887-123291-0042  153      15.10    15.24     2240      NaN   \n",
      "\n",
      "       word  in_id segment_nostress stress_type  \\\n",
      "0       NaN    NaN              sil         SNA   \n",
      "14      NaN    NaN               sp         SNA   \n",
      "19      NaN    NaN               sp         SNA   \n",
      "37      NaN    NaN               sp         SNA   \n",
      "38      NaN    NaN              sil         SNA   \n",
      "...     ...    ...              ...         ...   \n",
      "376735  NaN    NaN               sp         SNA   \n",
      "376754  NaN    NaN               sp         SNA   \n",
      "376780  NaN    NaN               sp         SNA   \n",
      "376783  NaN    NaN               sp         SNA   \n",
      "376840  NaN    NaN               sp         SNA   \n",
      "\n",
      "                                         phone_path  \\\n",
      "0       1034/121119/0000/1034-121119-0000-0000.flac   \n",
      "14      1034/121119/0000/1034-121119-0000-0014.flac   \n",
      "19      1034/121119/0000/1034-121119-0000-0019.flac   \n",
      "37      1034/121119/0000/1034-121119-0000-0037.flac   \n",
      "38      1034/121119/0001/1034-121119-0001-0000.flac   \n",
      "...                                             ...   \n",
      "376735    887/123291/0042/887-123291-0042-0048.flac   \n",
      "376754    887/123291/0042/887-123291-0042-0067.flac   \n",
      "376780    887/123291/0042/887-123291-0042-0093.flac   \n",
      "376783    887/123291/0042/887-123291-0042-0096.flac   \n",
      "376840    887/123291/0042/887-123291-0042-0153.flac   \n",
      "\n",
      "                                          word_path  speaker  word_startTime  \\\n",
      "0       1034/121119/0000/1034-121119-0000-xxxx.flac     1034             NaN   \n",
      "14      1034/121119/0000/1034-121119-0000-xxxx.flac     1034             NaN   \n",
      "19      1034/121119/0000/1034-121119-0000-xxxx.flac     1034             NaN   \n",
      "37      1034/121119/0000/1034-121119-0000-xxxx.flac     1034             NaN   \n",
      "38      1034/121119/0001/1034-121119-0001-xxxx.flac     1034             NaN   \n",
      "...                                             ...      ...             ...   \n",
      "376735    887/123291/0042/887-123291-0042-xxxx.flac      887             NaN   \n",
      "376754    887/123291/0042/887-123291-0042-xxxx.flac      887             NaN   \n",
      "376780    887/123291/0042/887-123291-0042-xxxx.flac      887             NaN   \n",
      "376783    887/123291/0042/887-123291-0042-xxxx.flac      887             NaN   \n",
      "376840    887/123291/0042/887-123291-0042-xxxx.flac      887             NaN   \n",
      "\n",
      "        word_endTime  word_nSample                   wuid  \n",
      "0                NaN           NaN  1034-121119-0000-xxxx  \n",
      "14               NaN           NaN  1034-121119-0000-xxxx  \n",
      "19               NaN           NaN  1034-121119-0000-xxxx  \n",
      "37               NaN           NaN  1034-121119-0000-xxxx  \n",
      "38               NaN           NaN  1034-121119-0001-xxxx  \n",
      "...              ...           ...                    ...  \n",
      "376735           NaN           NaN   887-123291-0042-xxxx  \n",
      "376754           NaN           NaN   887-123291-0042-xxxx  \n",
      "376780           NaN           NaN   887-123291-0042-xxxx  \n",
      "376783           NaN           NaN   887-123291-0042-xxxx  \n",
      "376840           NaN           NaN   887-123291-0042-xxxx  \n",
      "\n",
      "[190068 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# nan should be those silent parts. We still include a nan in the list, but we will not use it.\n",
    "\n",
    "nan_rows = concatenated_guide[concatenated_guide['word'].isna()]\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "unique_words_list = unique_words.tolist()\n",
    "\n",
    "# Specify the file path where you want to save the list\n",
    "file_path = os.path.join(src_, \"unique_words_list.dict\")\n",
    "\n",
    "# Save the list using pickle\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(unique_words_list, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(unique_words_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
