{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Phone Training - English\n",
    "Version 2:  This version has a core structure using HM-RNN. Unlike traditional approaches, our model can automatically detect boundaries. It is trainable and updates the upper layer only upon detecting boundaries. This makes our model suitable for detecting boundaries and capturing the representations of sub-segments based on these detected boundaries. In essence, our model performs boundary detection and representation learning simultaneously.\n",
    "\n",
    "Version 3: this version completed the coding of the core model structure as well as the dataloading, preprocessing, padding and loss calculation processes. At present we only try mel->model -> mel structure, since wav <> wav would introduce extra complexion. In addition, our model will process padded multi-batch tensors as normal but count for the paddings (ignore paddings) during calculation. \n",
    "\n",
    "Version 4: this version is testing whether our hmrnn is not working. It imports a modified version of model: model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('./multiscale_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it, masked_loss\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import PhonLearn_Net\n",
    "from model_test import PhonLearn_Net, DirectPassModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范用语；规定两种方式：全加载；按rec加载（舍弃了按chunk加载，处理起来更简单）\n",
    "# RandomPhoneDataset; AnnoPhoneDataset; AnnoSeqDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset that loads cutted wave files from disk and returns input-output pairs for\n",
    "    training autoencoder. \n",
    "    \n",
    "    Version 3: wav -> mel\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, load_dir, load_control_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the class by reading a CSV file and merging the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        The function reads the CSV file from the provided control path, extracts the \"rec\" and \"idx\" columns,\n",
    "        and concatenates the values from these columns using an underscore. It then appends the \".wav\" extension\n",
    "        to each of the merged strings and converts the merged pandas Series to a list, which is assigned to\n",
    "        the 'dataset' attribute of the class.\n",
    "\n",
    "        Args:\n",
    "        load_dir (str): The directory containing the files to load.\n",
    "        load_control_path (str): The path to the CSV file containing the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        Attributes:\n",
    "        dataset (list): A list of merged strings from the \"rec\" and \"idx\" columns, with the \".wav\" extension.\n",
    "        \"\"\"\n",
    "        control_file = pd.read_csv(load_control_path)\n",
    "        control_file = control_file[control_file['n_frames'] > 0]\n",
    "        control_file = control_file[control_file['duration'] <= 2.0]\n",
    "        \n",
    "        # Extract the \"rec\" and \"idx\" columns\n",
    "        rec_col = control_file['rec'].astype(str)\n",
    "        idx_col = control_file['idx'].astype(str).str.zfill(8)\n",
    "        \n",
    "        # Merge the two columns by concatenating the strings with '_' and append extension name\n",
    "        merged_col = rec_col + '_' + idx_col + \".wav\"\n",
    "        \n",
    "        self.dataset = merged_col.tolist()\n",
    "        self.load_dir = load_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: The number of input-output pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input_data, output_data) for the given index.\n",
    "\n",
    "        The function first checks if the provided index is a tensor, and if so, converts it to a list.\n",
    "        It then constructs the file path for the .wav file using the dataset attribute and the provided index.\n",
    "        The .wav file is loaded using torchaudio, and its data is normalized. If a transform is provided,\n",
    "        the data is transformed using the specified transform. Finally, the input_data and output_data are\n",
    "        set to the same data (creating a tuple), and the tuple is returned.\n",
    "\n",
    "        Args:\n",
    "        idx (int or torch.Tensor): The index of the desired data.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing input_data and output_data, both of which are the audio data\n",
    "               from the .wav file at the specified index.\n",
    "\n",
    "        Note: \n",
    "        This function assumes that the class has the following attributes:\n",
    "        - self.load_dir (str): The directory containing the .wav files.\n",
    "        - self.dataset (list): A list of .wav file names.\n",
    "        - self.transform (callable, optional): An optional transform to apply to the audio data.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        wav_name = os.path.join(self.load_dir,\n",
    "                                self.dataset[idx])\n",
    "        \n",
    "        data, sample_rate = torchaudio.load(wav_name, normalize=True)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        # # Prepare for possible in-out discrepencies in the future\n",
    "        # input_data = data\n",
    "        # output_data = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "def collate_fn(xx):\n",
    "    # only working for one data at the moment\n",
    "    batch_first = True\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=batch_first, padding_value=0)\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "\n",
    "class MyTransform(nn.Module): \n",
    "    def __init__(self, sample_rate, n_fft): \n",
    "        super().__init__()\n",
    "        self.transform = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft)\n",
    "    \n",
    "    def forward(self, waveform): \n",
    "        mel_spec = self.transform(waveform)\n",
    "        mel_spec = mel_spec.squeeze()\n",
    "        mel_spec = mel_spec.permute(1, 0) # (F, L) -> (L, F)\n",
    "        return mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: THIS IS HOW WE CAN CREATE THE DATASET AND DATALOADER\n",
    "# sample_rate = 16000\n",
    "# n_fft = 400\n",
    "\n",
    "# transform = MyTransform(sample_rate, n_fft)\n",
    "\n",
    "# ds = PhoneDataset(phone_seg_random_path, phone_seg_random_log_path + \"s0101a.csv\", transform=transform)\n",
    "\n",
    "# test_dl = DataLoader(ds, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# indata, in_lens = next(iter(test_dl))\n",
    "\n",
    "# print(indata.shape, in_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# SEGMENTS_IN_CHUNK = 100  # set_size\n",
    "\n",
    "INPUT_DIM = 128\n",
    "OUTPUT_DIM = 128\n",
    "\n",
    "INTER_DIM_0 = 64\n",
    "INTER_DIM_1 = 32\n",
    "INTER_DIM_2 = 8\n",
    "INTER_DIM_3 = 3\n",
    "\n",
    "SIZE_LIST = [INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "recon_loss = nn.MSELoss(reduction='mean')\n",
    "model = DirectPassModel(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "                      in2_size=INTER_DIM_0, hid_size=INTER_DIM_3, out_size=OUTPUT_DIM)\n",
    "# model = PhonLearn_Net(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "#                       in2_size=INTER_DIM_0, hid_size=INTER_DIM_3, out_size=OUTPUT_DIM)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirectPassModel(\n",
       "  (lin_1): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (lin_2): Linear(in_features=3, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NNHDmuigs8OB"
   },
   "outputs": [],
   "source": [
    "# Define recorders of training hists, for ease of extension\n",
    "class Recorder: \n",
    "    def __init__(self, IOPath): \n",
    "        self.record = []\n",
    "        self.IOPath = IOPath\n",
    "\n",
    "    def save(self): \n",
    "        pass\n",
    "    \n",
    "    def append(self, content): \n",
    "        self.record.append(content)\n",
    "    \n",
    "    def get(self): \n",
    "        return self.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kGMfle47t3Hj"
   },
   "outputs": [],
   "source": [
    "class LossRecorder(Recorder): \n",
    "    def read(self): \n",
    "        # only used by loss hists \n",
    "        with open(self.IOPath, 'rb') as f:\n",
    "            self.record = pickle.load(f)\n",
    "    \n",
    "    def save(self): \n",
    "        with open(self.IOPath, 'wb') as file:\n",
    "            pickle.dump(self.record, file)\n",
    "\n",
    "\n",
    "class HistRecorder(Recorder):     \n",
    "    def save(self): \n",
    "        with open(self.IOPath, \"a\") as txt:\n",
    "            txt.write(\"\\n\".join(self.record))\n",
    "    \n",
    "    def print(self, content): \n",
    "        self.append(content)\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "ts = str(get_timestamp())\n",
    "# ts = \"0130021416\"\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    # model_name = last_model_name\n",
    "    model_name = \"PT_0130021416_9.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model = PhonLearn_Net()\n",
    "    model.load_state_dict(state)\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldlmdl/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = PhoneDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "small_len = int(0.1 * len(ds))\n",
    "other_len = len(ds) - small_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "valid_len = len(ds) - train_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            batch = x.size(0)\n",
    "            # print(x.size(1))\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            recon_x, _ = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "            \n",
    "            loss = masked_loss(recon_loss, recon_x, x, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            # loss = loss / batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 20 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "                gc.collect()\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            batch = x.size(0)\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            recon_x, _ = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "\n",
    "            loss = masked_loss(recon_loss, recon_x, x, x_mask)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            if idx % 20 == 0:\n",
    "                # \\t Recon {recon / batch: .3f} \\t KL {kl / batch: .3f}\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "                gc.collect()\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss  32.760 in Step 0\n",
      "Training loss  85.418 in Step 20\n",
      "Training loss  222.111 in Step 40\n",
      "Training loss  82.446 in Step 60\n",
      "Training loss  36.572 in Step 80\n",
      "Training loss  53.870 in Step 100\n",
      "Training loss  87.025 in Step 120\n",
      "Training loss  80.536 in Step 140\n",
      "Training loss  107.628 in Step 160\n",
      "※※※Training loss  139.292※※※\n",
      "Training timepoint saved\n",
      "Valid loss  117.711 in Step 0\n",
      "Valid loss  155.930 in Step 20\n",
      "Valid loss  118.402 in Step 40\n",
      "※※※Valid loss  124.194※※※\n",
      "Epoch 1\n",
      "Training loss  232.053 in Step 0\n",
      "Training loss  111.669 in Step 20\n",
      "Training loss  47.499 in Step 40\n",
      "Training loss  40.826 in Step 60\n",
      "Training loss  68.250 in Step 80\n",
      "Training loss  80.952 in Step 100\n",
      "Training loss  294.707 in Step 120\n",
      "Training loss  27.244 in Step 140\n",
      "Training loss  128.042 in Step 160\n",
      "※※※Training loss  130.749※※※\n",
      "Training timepoint saved\n",
      "Valid loss  15.114 in Step 0\n",
      "Valid loss  36.511 in Step 20\n",
      "Valid loss  46.805 in Step 40\n",
      "※※※Valid loss  111.143※※※\n",
      "Epoch 2\n",
      "Training loss  115.488 in Step 0\n",
      "Training loss  279.035 in Step 20\n",
      "Training loss  201.382 in Step 40\n",
      "Training loss  62.324 in Step 60\n",
      "Training loss  72.422 in Step 80\n",
      "Training loss  127.743 in Step 100\n",
      "Training loss  24.522 in Step 120\n",
      "Training loss  19.249 in Step 140\n",
      "Training loss  119.955 in Step 160\n",
      "※※※Training loss  114.707※※※\n",
      "Training timepoint saved\n",
      "Valid loss  15.438 in Step 0\n",
      "Valid loss  89.284 in Step 20\n",
      "Valid loss  51.939 in Step 40\n",
      "※※※Valid loss  99.762※※※\n",
      "Epoch 3\n",
      "Training loss  191.741 in Step 0\n",
      "Training loss  88.816 in Step 20\n",
      "Training loss  295.798 in Step 40\n",
      "Training loss  42.910 in Step 60\n",
      "Training loss  87.594 in Step 80\n",
      "Training loss  147.023 in Step 100\n",
      "Training loss  889.790 in Step 120\n",
      "Training loss  97.169 in Step 140\n",
      "Training loss  20.391 in Step 160\n",
      "※※※Training loss  102.189※※※\n",
      "Training timepoint saved\n",
      "Valid loss  22.263 in Step 0\n",
      "Valid loss  219.983 in Step 20\n",
      "Valid loss  139.796 in Step 40\n",
      "※※※Valid loss  90.618※※※\n",
      "Epoch 4\n",
      "Training loss  452.637 in Step 0\n",
      "Training loss  65.112 in Step 20\n",
      "Training loss  644.010 in Step 40\n",
      "Training loss  81.473 in Step 60\n",
      "Training loss  16.759 in Step 80\n",
      "Training loss  46.971 in Step 100\n",
      "Training loss  28.955 in Step 120\n",
      "Training loss  451.432 in Step 140\n",
      "Training loss  100.573 in Step 160\n",
      "※※※Training loss  98.332※※※\n",
      "Training timepoint saved\n",
      "Valid loss  30.303 in Step 0\n",
      "Valid loss  10.246 in Step 20\n",
      "Valid loss  326.471 in Step 40\n",
      "※※※Valid loss  87.683※※※\n",
      "Epoch 5\n",
      "Training loss  31.307 in Step 0\n",
      "Training loss  55.130 in Step 20\n",
      "Training loss  406.458 in Step 40\n",
      "Training loss  57.091 in Step 60\n",
      "Training loss  121.561 in Step 80\n",
      "Training loss  29.076 in Step 100\n",
      "Training loss  39.892 in Step 120\n",
      "Training loss  12.929 in Step 140\n",
      "Training loss  137.231 in Step 160\n",
      "※※※Training loss  95.806※※※\n",
      "Training timepoint saved\n",
      "Valid loss  12.214 in Step 0\n",
      "Valid loss  21.883 in Step 20\n",
      "Valid loss  57.177 in Step 40\n",
      "※※※Valid loss  85.267※※※\n",
      "Epoch 6\n",
      "Training loss  102.201 in Step 0\n",
      "Training loss  162.801 in Step 20\n",
      "Training loss  20.125 in Step 40\n",
      "Training loss  523.420 in Step 60\n",
      "Training loss  25.244 in Step 80\n",
      "Training loss  594.130 in Step 100\n",
      "Training loss  12.018 in Step 120\n",
      "Training loss  58.396 in Step 140\n",
      "Training loss  133.557 in Step 160\n",
      "※※※Training loss  93.928※※※\n",
      "Training timepoint saved\n",
      "Valid loss  61.006 in Step 0\n",
      "Valid loss  15.873 in Step 20\n",
      "Valid loss  40.271 in Step 40\n",
      "※※※Valid loss  82.673※※※\n",
      "Epoch 7\n",
      "Training loss  103.939 in Step 0\n",
      "Training loss  9.861 in Step 20\n",
      "Training loss  30.589 in Step 40\n",
      "Training loss  54.008 in Step 60\n",
      "Training loss  36.791 in Step 80\n",
      "Training loss  540.000 in Step 100\n",
      "Training loss  13.760 in Step 120\n",
      "Training loss  39.960 in Step 140\n",
      "Training loss  2.903 in Step 160\n",
      "※※※Training loss  91.131※※※\n",
      "Training timepoint saved\n",
      "Valid loss  56.367 in Step 0\n",
      "Valid loss  14.688 in Step 20\n",
      "Valid loss  29.688 in Step 40\n",
      "※※※Valid loss  82.489※※※\n",
      "Epoch 8\n",
      "Training loss  366.688 in Step 0\n",
      "Training loss  88.369 in Step 20\n",
      "Training loss  26.424 in Step 40\n",
      "Training loss  17.833 in Step 60\n",
      "Training loss  13.501 in Step 80\n",
      "Training loss  13.710 in Step 100\n",
      "Training loss  18.836 in Step 120\n",
      "Training loss  45.255 in Step 140\n",
      "Training loss  245.853 in Step 160\n",
      "※※※Training loss  89.559※※※\n",
      "Training timepoint saved\n",
      "Valid loss  32.137 in Step 0\n",
      "Valid loss  29.367 in Step 20\n",
      "Valid loss  129.720 in Step 40\n",
      "※※※Valid loss  81.151※※※\n",
      "Epoch 9\n",
      "Training loss  60.073 in Step 0\n",
      "Training loss  17.905 in Step 20\n",
      "Training loss  73.288 in Step 40\n",
      "Training loss  18.572 in Step 60\n",
      "Training loss  678.327 in Step 80\n",
      "Training loss  51.723 in Step 100\n",
      "Training loss  144.542 in Step 120\n",
      "Training loss  129.798 in Step 140\n",
      "Training loss  23.050 in Step 160\n",
      "※※※Training loss  90.028※※※\n",
      "Training timepoint saved\n",
      "Valid loss  45.214 in Step 0\n",
      "Valid loss  392.704 in Step 20\n",
      "Valid loss  31.315 in Step 40\n",
      "※※※Valid loss  80.782※※※\n",
      "Epoch 10\n",
      "Training loss  12.337 in Step 0\n",
      "Training loss  31.279 in Step 20\n",
      "Training loss  63.616 in Step 40\n",
      "Training loss  57.269 in Step 60\n",
      "Training loss  464.217 in Step 80\n",
      "Training loss  148.071 in Step 100\n",
      "Training loss  113.675 in Step 120\n",
      "Training loss  43.994 in Step 140\n",
      "Training loss  10.132 in Step 160\n",
      "※※※Training loss  88.215※※※\n",
      "Training timepoint saved\n",
      "Valid loss  70.497 in Step 0\n",
      "Valid loss  190.336 in Step 20\n",
      "Valid loss  18.427 in Step 40\n",
      "※※※Valid loss  79.970※※※\n",
      "Epoch 11\n",
      "Training loss  78.268 in Step 0\n",
      "Training loss  61.160 in Step 20\n",
      "Training loss  116.227 in Step 40\n",
      "Training loss  238.454 in Step 60\n",
      "Training loss  104.687 in Step 80\n",
      "Training loss  91.377 in Step 100\n",
      "Training loss  73.274 in Step 120\n",
      "Training loss  23.105 in Step 140\n",
      "Training loss  26.951 in Step 160\n",
      "※※※Training loss  87.658※※※\n",
      "Training timepoint saved\n",
      "Valid loss  37.980 in Step 0\n",
      "Valid loss  197.733 in Step 20\n",
      "Valid loss  39.963 in Step 40\n",
      "※※※Valid loss  78.077※※※\n",
      "Epoch 12\n",
      "Training loss  11.421 in Step 0\n",
      "Training loss  339.307 in Step 20\n",
      "Training loss  52.410 in Step 40\n",
      "Training loss  97.113 in Step 60\n",
      "Training loss  10.518 in Step 80\n",
      "Training loss  89.486 in Step 100\n",
      "Training loss  55.220 in Step 120\n",
      "Training loss  173.691 in Step 140\n",
      "Training loss  225.172 in Step 160\n",
      "※※※Training loss  86.989※※※\n",
      "Training timepoint saved\n",
      "Valid loss  135.060 in Step 0\n",
      "Valid loss  46.665 in Step 20\n",
      "Valid loss  116.574 in Step 40\n",
      "※※※Valid loss  76.913※※※\n",
      "Epoch 13\n",
      "Training loss  24.190 in Step 0\n",
      "Training loss  16.185 in Step 20\n",
      "Training loss  119.600 in Step 40\n",
      "Training loss  24.366 in Step 60\n",
      "Training loss  29.832 in Step 80\n",
      "Training loss  41.471 in Step 100\n",
      "Training loss  42.276 in Step 120\n",
      "Training loss  54.263 in Step 140\n",
      "Training loss  12.734 in Step 160\n",
      "※※※Training loss  86.321※※※\n",
      "Training timepoint saved\n",
      "Valid loss  13.034 in Step 0\n",
      "Valid loss  26.192 in Step 20\n",
      "Valid loss  11.601 in Step 40\n",
      "※※※Valid loss  76.394※※※\n",
      "Epoch 14\n",
      "Training loss  77.532 in Step 0\n",
      "Training loss  29.249 in Step 20\n",
      "Training loss  15.430 in Step 40\n",
      "Training loss  178.324 in Step 60\n",
      "Training loss  68.611 in Step 80\n",
      "Training loss  131.409 in Step 100\n",
      "Training loss  97.502 in Step 120\n",
      "Training loss  44.245 in Step 140\n",
      "Training loss  20.177 in Step 160\n",
      "※※※Training loss  85.816※※※\n",
      "Training timepoint saved\n",
      "Valid loss  45.267 in Step 0\n",
      "Valid loss  21.068 in Step 20\n",
      "Valid loss  9.374 in Step 40\n",
      "※※※Valid loss  76.675※※※\n",
      "Epoch 15\n",
      "Training loss  83.351 in Step 0\n",
      "Training loss  34.035 in Step 20\n",
      "Training loss  95.532 in Step 40\n",
      "Training loss  43.997 in Step 60\n",
      "Training loss  42.054 in Step 80\n",
      "Training loss  27.264 in Step 100\n",
      "Training loss  26.764 in Step 120\n",
      "Training loss  26.360 in Step 140\n",
      "Training loss  42.026 in Step 160\n",
      "※※※Training loss  85.578※※※\n",
      "Training timepoint saved\n",
      "Valid loss  132.278 in Step 0\n",
      "Valid loss  29.757 in Step 20\n",
      "Valid loss  59.638 in Step 40\n",
      "※※※Valid loss  74.588※※※\n",
      "Epoch 16\n",
      "Training loss  32.012 in Step 0\n",
      "Training loss  22.532 in Step 20\n",
      "Training loss  48.566 in Step 40\n",
      "Training loss  29.807 in Step 60\n",
      "Training loss  5.060 in Step 80\n",
      "Training loss  75.608 in Step 100\n",
      "Training loss  184.457 in Step 120\n",
      "Training loss  43.741 in Step 140\n",
      "Training loss  13.789 in Step 160\n",
      "※※※Training loss  85.212※※※\n",
      "Training timepoint saved\n",
      "Valid loss  243.713 in Step 0\n",
      "Valid loss  99.514 in Step 20\n",
      "Valid loss  12.567 in Step 40\n",
      "※※※Valid loss  74.744※※※\n",
      "Epoch 17\n",
      "Training loss  15.271 in Step 0\n",
      "Training loss  312.504 in Step 20\n",
      "Training loss  10.476 in Step 40\n",
      "Training loss  20.031 in Step 60\n",
      "Training loss  291.355 in Step 80\n",
      "Training loss  11.591 in Step 100\n",
      "Training loss  43.207 in Step 120\n",
      "Training loss  149.349 in Step 140\n",
      "Training loss  11.515 in Step 160\n",
      "※※※Training loss  85.107※※※\n",
      "Training timepoint saved\n",
      "Valid loss  36.222 in Step 0\n",
      "Valid loss  66.880 in Step 20\n",
      "Valid loss  75.170 in Step 40\n",
      "※※※Valid loss  73.710※※※\n",
      "Epoch 18\n",
      "Training loss  5.257 in Step 0\n",
      "Training loss  34.864 in Step 20\n",
      "Training loss  22.836 in Step 40\n",
      "Training loss  11.617 in Step 60\n",
      "Training loss  29.581 in Step 80\n",
      "Training loss  176.399 in Step 100\n",
      "Training loss  74.443 in Step 120\n",
      "Training loss  332.393 in Step 140\n",
      "Training loss  38.030 in Step 160\n",
      "※※※Training loss  83.933※※※\n",
      "Training timepoint saved\n",
      "Valid loss  28.105 in Step 0\n",
      "Valid loss  59.921 in Step 20\n",
      "Valid loss  186.796 in Step 40\n",
      "※※※Valid loss  74.596※※※\n",
      "Epoch 19\n",
      "Training loss  35.024 in Step 0\n",
      "Training loss  37.064 in Step 20\n",
      "Training loss  165.299 in Step 40\n",
      "Training loss  310.208 in Step 60\n",
      "Training loss  37.068 in Step 80\n",
      "Training loss  72.315 in Step 100\n",
      "Training loss  21.287 in Step 120\n",
      "Training loss  189.229 in Step 140\n",
      "Training loss  89.192 in Step 160\n",
      "※※※Training loss  83.629※※※\n",
      "Training timepoint saved\n",
      "Valid loss  64.923 in Step 0\n",
      "Valid loss  23.341 in Step 20\n",
      "Valid loss  7.608 in Step 40\n",
      "※※※Valid loss  73.142※※※\n",
      "Epoch 20\n",
      "Training loss  49.893 in Step 0\n",
      "Training loss  45.426 in Step 20\n",
      "Training loss  16.409 in Step 40\n",
      "Training loss  60.605 in Step 60\n",
      "Training loss  30.763 in Step 80\n",
      "Training loss  269.283 in Step 100\n",
      "Training loss  168.954 in Step 120\n",
      "Training loss  13.735 in Step 140\n",
      "Training loss  60.772 in Step 160\n",
      "※※※Training loss  82.689※※※\n",
      "Training timepoint saved\n",
      "Valid loss  23.264 in Step 0\n",
      "Valid loss  92.357 in Step 20\n",
      "Valid loss  63.324 in Step 40\n",
      "※※※Valid loss  77.131※※※\n",
      "Epoch 21\n",
      "Training loss  51.586 in Step 0\n",
      "Training loss  139.267 in Step 20\n",
      "Training loss  69.665 in Step 40\n",
      "Training loss  26.038 in Step 60\n",
      "Training loss  127.356 in Step 80\n",
      "Training loss  23.897 in Step 100\n",
      "Training loss  47.389 in Step 120\n",
      "Training loss  31.206 in Step 140\n",
      "Training loss  181.973 in Step 160\n",
      "※※※Training loss  82.107※※※\n",
      "Training timepoint saved\n",
      "Valid loss  99.901 in Step 0\n",
      "Valid loss  49.871 in Step 20\n",
      "Valid loss  16.445 in Step 40\n",
      "※※※Valid loss  71.673※※※\n",
      "Epoch 22\n",
      "Training loss  96.269 in Step 0\n",
      "Training loss  347.795 in Step 20\n",
      "Training loss  26.011 in Step 40\n",
      "Training loss  79.799 in Step 60\n",
      "Training loss  453.719 in Step 80\n",
      "Training loss  21.032 in Step 100\n",
      "Training loss  73.890 in Step 120\n",
      "Training loss  116.267 in Step 140\n",
      "Training loss  53.880 in Step 160\n",
      "※※※Training loss  81.748※※※\n",
      "Training timepoint saved\n",
      "Valid loss  142.153 in Step 0\n",
      "Valid loss  18.468 in Step 20\n",
      "Valid loss  7.260 in Step 40\n",
      "※※※Valid loss  71.550※※※\n",
      "Epoch 23\n",
      "Training loss  37.188 in Step 0\n",
      "Training loss  32.161 in Step 20\n",
      "Training loss  31.955 in Step 40\n",
      "Training loss  87.394 in Step 60\n",
      "Training loss  16.304 in Step 80\n",
      "Training loss  59.718 in Step 100\n",
      "Training loss  17.785 in Step 120\n",
      "Training loss  245.952 in Step 140\n",
      "Training loss  97.227 in Step 160\n",
      "※※※Training loss  81.822※※※\n",
      "Training timepoint saved\n",
      "Valid loss  266.619 in Step 0\n",
      "Valid loss  18.714 in Step 20\n",
      "Valid loss  59.676 in Step 40\n",
      "※※※Valid loss  69.610※※※\n",
      "Epoch 24\n",
      "Training loss  16.294 in Step 0\n",
      "Training loss  49.786 in Step 20\n",
      "Training loss  46.419 in Step 40\n",
      "Training loss  17.267 in Step 60\n",
      "Training loss  37.891 in Step 80\n",
      "Training loss  18.569 in Step 100\n",
      "Training loss  167.038 in Step 120\n",
      "Training loss  33.843 in Step 140\n",
      "Training loss  69.087 in Step 160\n",
      "※※※Training loss  81.537※※※\n",
      "Training timepoint saved\n",
      "Valid loss  85.593 in Step 0\n",
      "Valid loss  17.144 in Step 20\n",
      "Valid loss  101.446 in Step 40\n",
      "※※※Valid loss  72.646※※※\n",
      "Epoch 25\n",
      "Training loss  12.130 in Step 0\n",
      "Training loss  51.614 in Step 20\n",
      "Training loss  178.572 in Step 40\n",
      "Training loss  132.871 in Step 60\n",
      "Training loss  126.202 in Step 80\n",
      "Training loss  38.912 in Step 100\n",
      "Training loss  23.396 in Step 120\n",
      "Training loss  139.482 in Step 140\n",
      "Training loss  114.431 in Step 160\n",
      "※※※Training loss  80.884※※※\n",
      "Training timepoint saved\n",
      "Valid loss  35.116 in Step 0\n",
      "Valid loss  31.813 in Step 20\n",
      "Valid loss  62.685 in Step 40\n",
      "※※※Valid loss  71.032※※※\n",
      "Epoch 26\n",
      "Training loss  35.505 in Step 0\n",
      "Training loss  47.265 in Step 20\n",
      "Training loss  14.034 in Step 40\n",
      "Training loss  50.139 in Step 60\n",
      "Training loss  149.983 in Step 80\n",
      "Training loss  56.433 in Step 100\n",
      "Training loss  43.820 in Step 120\n",
      "Training loss  227.717 in Step 140\n",
      "Training loss  10.053 in Step 160\n",
      "※※※Training loss  80.494※※※\n",
      "Training timepoint saved\n",
      "Valid loss  21.469 in Step 0\n",
      "Valid loss  35.343 in Step 20\n",
      "Valid loss  43.380 in Step 40\n",
      "※※※Valid loss  68.989※※※\n",
      "Epoch 27\n",
      "Training loss  10.615 in Step 0\n",
      "Training loss  11.687 in Step 20\n",
      "Training loss  139.076 in Step 40\n",
      "Training loss  15.344 in Step 60\n",
      "Training loss  21.994 in Step 80\n",
      "Training loss  128.107 in Step 100\n",
      "Training loss  78.156 in Step 120\n",
      "Training loss  8.567 in Step 140\n",
      "Training loss  50.895 in Step 160\n",
      "※※※Training loss  79.494※※※\n",
      "Training timepoint saved\n",
      "Valid loss  19.536 in Step 0\n",
      "Valid loss  27.387 in Step 20\n",
      "Valid loss  125.758 in Step 40\n",
      "※※※Valid loss  67.709※※※\n",
      "Epoch 28\n",
      "Training loss  41.404 in Step 0\n",
      "Training loss  19.484 in Step 20\n",
      "Training loss  154.446 in Step 40\n",
      "Training loss  1.822 in Step 60\n",
      "Training loss  21.592 in Step 80\n",
      "Training loss  59.978 in Step 100\n",
      "Training loss  152.309 in Step 120\n",
      "Training loss  136.951 in Step 140\n",
      "Training loss  89.867 in Step 160\n",
      "※※※Training loss  79.797※※※\n",
      "Training timepoint saved\n",
      "Valid loss  59.795 in Step 0\n",
      "Valid loss  159.785 in Step 20\n",
      "Valid loss  98.664 in Step 40\n",
      "※※※Valid loss  68.373※※※\n",
      "Epoch 29\n",
      "Training loss  48.002 in Step 0\n",
      "Training loss  5.810 in Step 20\n",
      "Training loss  90.350 in Step 40\n",
      "Training loss  148.893 in Step 60\n",
      "Training loss  15.059 in Step 80\n",
      "Training loss  36.441 in Step 100\n",
      "Training loss  7.616 in Step 120\n",
      "Training loss  109.047 in Step 140\n",
      "Training loss  41.679 in Step 160\n",
      "※※※Training loss  79.179※※※\n",
      "Training timepoint saved\n",
      "Valid loss  155.716 in Step 0\n",
      "Valid loss  19.840 in Step 20\n",
      "Valid loss  19.415 in Step 40\n",
      "※※※Valid loss  67.826※※※\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "valid_losses.save()\n",
    "train_losses.save()\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fad545e36d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_UcLyHcQMGu0",
    "outputId": "4b56200c-1dc4-4286-b51a-d19e9c75ddd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0613160106'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E6-6g-sW3zeg"
   },
   "source": [
    "We can see that with Sigmoid the model seems to perform slightly worse, but this should not be a big problem. Then the decision might depend more on whether the use of it is common and justifiable. I don't think it's common, and the use of it does not seem to be analytically necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNJ0DAlaWrEE"
   },
   "outputs": [],
   "source": [
    "class ResAECluster(ResAE): \n",
    "    def __init__(self, input_dim=INPUT_DIM, inter_dim1=INTER_DIM_1, inter_dim2=INTER_DIM_2, inter_dim3=INTER_DIM_3, latent_dim=LATENT_DIM, output_dim=OUTPUT_DIM): \n",
    "        super().__init__(input_dim, inter_dim1, inter_dim2, inter_dim3, latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        org_size = x.size()\n",
    "        batch = org_size[0]\n",
    "        x = x.view(batch, -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        # mu, logvar = h.chunk(2, dim=1)\n",
    "        # z = self.reparameterise(mu, logvar)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFrvzaGC45Gi"
   },
   "outputs": [],
   "source": [
    "seq = \"_01_05\"\n",
    "tags = pd.read_csv(tags_name + seq + \".csv\")\n",
    "gsds = GroundedSoundDataset(tags, test_name + seq + \".npy\")\n",
    "eval_loader = DataLoader(gsds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QARr-C_qpBLb",
    "outputId": "acd5e8ab-1ef6-4968-c205-b437ecfd7b8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'model_english_0130021416_29_full'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXLqyT3PYFkR"
   },
   "outputs": [],
   "source": [
    "# model_name = last_model_name\n",
    "model_name = \"model_english_0130021416_13_full\"\n",
    "model_path = save_dir + model_name + \".pt\"\n",
    "state = torch.load(model_path)\n",
    "model = ResAECluster()\n",
    "model.load_state_dict(state)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "hiddens = None\n",
    "tags = None\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (s, e, t) in enumerate(eval_loader):\n",
    "        s = s.to(device)\n",
    "        hidden = model(s)\n",
    "        hidden = hidden.cpu().data.numpy()\n",
    "\n",
    "        if hiddens is not None: \n",
    "            hiddens = np.concatenate((hiddens, hidden), axis=0)\n",
    "            tags = np.concatenate((tags, t), axis=0)\n",
    "        else: \n",
    "            hiddens = hidden\n",
    "            tags = t\n",
    "num_phones = np.unique(tags).shape[0]\n",
    "kmeansmodel = KMeans(n_clusters=num_phones) # , random_state=0\n",
    "clusters = kmeansmodel.fit_predict(hiddens)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenclusters.npy\", clusters)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenrepresentation.npy\", hiddens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzTuc2Mz6niT"
   },
   "outputs": [],
   "source": [
    "h, c, v = homogeneity_completeness_v_measure(tags, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ogsEovzEbpc",
    "outputId": "3cd43d32-f30c-4fb3-f5eb-945d6dd0ecc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_01_05 0.30813685860010276 0.2726217590636009 0.2892933823757265\n"
     ]
    }
   ],
   "source": [
    "print(seq, h, c, v) # trained on sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMFbNimpx-iJ"
   },
   "outputs": [],
   "source": [
    "# _17_24 0.3429902101084872 0.329164358854651 0.33593508938856537   # 256+8\n",
    "# _17_24 0.3071758873778334 0.2958512436337788 0.3014072290332542   # 128+4\n",
    "# _17_24 0.3048181747064378 0.303971996633573 0.3043944976042278    # 128+2\n",
    "# _17_24 0.3109960687106377 0.3020004935745723 0.3064322772063619   # 256+2, 2res\n",
    "# _17_24 0.27632046463064963 0.29796767719078493 0.28673608598337974    # 256+64+2, 2res, new model\n",
    "# _17_24 0.29619001674434664 0.30940705212658304 0.30265430485339223    # 256+64+4, 0res\n",
    "# _17_24 0.3394207670351701 0.3356821861468344 0.33754112484613674      # 256+64+4, 2res\n",
    "# _17_24 0.3246121630042821 0.3173438869288583 0.32093687897447765  # 256+3, 2res, not very bad. So we may try this. This is error, decoder only having 1 res\n",
    "# _17_24 0.3227539602867097 0.32256957773330264 0.3226617426690128  # 256+3, 2res\n",
    "# _17_24 0.3403517130774138 0.33762198107176034 0.33898135170147237 # 256+3, 1res\n",
    "# _17_24 0.3202704367215642 0.31097127191607643 0.3155523587925454  # 256+3, 0res\n",
    "\n",
    "\n",
    "# _01_05 0.30784101366300043 0.2717512535534188 0.28867252408265254"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gYDGP0Cdf1o"
   },
   "source": [
    "总的来说分成四个，神经网层来进行降维处理，得到的损失比较大，但是 hcv值倒是接近不过，如果能尽量的接近原作的模型结构，我们就不去动它了，所以可能目前来看最好的是保留两个降为层加上两个残差层，最后从256降到2，也许是最好的结果当然降到4也是可以的，都是比较低的维度，不过如果我们想要直接能够，在，可视的空间中画出这些点来，2或者3可能会比四更好一些。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nTTdgp_HokAn"
   },
   "source": [
    "从使用不同数量残插块儿的实验结果来看，是由一个残渣块，应该是最好的解决方式，使用零个或两个第三个都可能是都会使hcv值相对降低。由此来看在选择，隐性层纬度为三的情况下，我们应该选择适用一个参差款。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdQ9f85WY1K"
   },
   "source": [
    "### Conclusion\n",
    "Adding new data slightly improves the performance of the model in HCV score, in addition, shuffling the training data largely lowers the HGV score perhaps we should discuss this phenomenon and justify use no shuffling during training. Perhaps this is because of some sort of phonotactics or naturalness of sound streams. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kjoJ2fFKpmVC"
   },
   "source": [
    "Good news is that for the English model it performs similar well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPWgjpid7PR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
