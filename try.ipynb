{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from paths import *\n",
    "from misc_tools import AudioCut\n",
    "from misc_my_utils import time_to_frame\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_file = pd.read_csv(os.path.join(src_, \"guide_train.csv\"))\n",
    "guide_file = guide_file[~guide_file[\"segment_nostress\"].isin([\"sil\", \"sp\", \"spn\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deshort = guide_file[guide_file['word_nSample'] > 400]\n",
    "delong = guide_file[guide_file['word_nSample'] <= 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deshort) / len(guide_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922523566098395"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(delong) / len(guide_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['segment', 'file', 'id', 'startTime', 'endTime', 'nSample', 'word_id',\n",
       "       'word', 'in_id', 'segment_nostress', 'stress_type', 'phone_path',\n",
       "       'word_path', 'speaker', 'word_startTime', 'word_endTime',\n",
       "       'word_nSample', 'wuid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth(length, bp_pair):\n",
    "    # Initialize the ground truth tensor with zeros or a placeholder value\n",
    "    ground_truth = torch.zeros(length, dtype=torch.int)\n",
    "\n",
    "    # Start index for the first phoneme\n",
    "    start_idx = 0\n",
    "\n",
    "    # Process all but the last phoneme using the boundaries\n",
    "    for (boundary, phoneme) in bp_pair[:-1]:\n",
    "        ground_truth[start_idx:boundary] = phoneme\n",
    "        start_idx = boundary\n",
    "\n",
    "    # Handle the last phoneme, ensuring it extends to the end of the mel spectrogram if necessary\n",
    "    ground_truth[start_idx:] = bp_pair[-1][0]\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenMap: \n",
    "    def __init__(self, token_list, starter=1):  \n",
    "        self.token2idx = {element: index + starter for index, element in enumerate(token_list)}\n",
    "        self.idx2token = {index + starter: element for index, element in enumerate(token_list)}\n",
    "    \n",
    "    def encode(self, token): \n",
    "        return self.token2idx[token]\n",
    "    \n",
    "    def decode(self, idx): \n",
    "        return self.idx2token[idx]\n",
    "    \n",
    "    def token_num(self): \n",
    "        return len(self.token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = guide_file.drop_duplicates(subset='wuid')\n",
    "word_nSamples_list = ((unique_df['word_nSample'] // 200).astype(int) + 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "    mylist = pickle.load(file)\n",
    "\n",
    "# Now you can use the loaded object\n",
    "mapper = TokenMap(mylist, starter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = guide_file.groupby('wuid').apply(lambda x: [(mapper.encode(row[\"segment_nostress\"]), time_to_frame(row['endTime'] - row['word_startTime'])) for index, row in x.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391018/3761935688.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  create_ground_truth(word_nSamples_list[i], grouped[i])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 30, 30, 30, 30, 35, 35, 35, 35, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "create_ground_truth(word_nSamples_list[i], grouped[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391018/587015168.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mappedgt = [create_ground_truth(word_nSamples_list[i], grouped[i]) for i in range(len(grouped))]\n"
     ]
    }
   ],
   "source": [
    "mappedgt = [create_ground_truth(word_nSamples_list[i], grouped[i]) for i in range(len(grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgf = guide_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgf[\"startFrame\"] = modgf.apply(lambda x: time_to_frame(x['startTime'] - x['word_startTime']), axis=1)\n",
    "modgf[\"endFrame\"] = modgf.apply(lambda x: time_to_frame(x['endTime'] - x['word_startTime']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>nSample</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>in_id</th>\n",
       "      <th>segment_nostress</th>\n",
       "      <th>stress_type</th>\n",
       "      <th>phone_path</th>\n",
       "      <th>word_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_startTime</th>\n",
       "      <th>word_endTime</th>\n",
       "      <th>word_nSample</th>\n",
       "      <th>wuid</th>\n",
       "      <th>startFrame</th>\n",
       "      <th>endFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>SNA</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0003.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UH1</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>2.0</td>\n",
       "      <td>UH</td>\n",
       "      <td>1</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0004.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>3.0</td>\n",
       "      <td>K</td>\n",
       "      <td>SNA</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0005.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0007.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0002.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1069-133699-0000-0002</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AE1</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>14</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1920</td>\n",
       "      <td>4.0</td>\n",
       "      <td>after</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AE</td>\n",
       "      <td>1</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0014.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0004.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>1069-133699-0000-0004</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376832</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>145</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.27</td>\n",
       "      <td>960</td>\n",
       "      <td>45.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0145.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0045.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.27</td>\n",
       "      <td>960.0</td>\n",
       "      <td>887-123291-0042-0045</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376833</th>\n",
       "      <td>F</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>146</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1920</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0146.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376834</th>\n",
       "      <td>AO1</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>147</td>\n",
       "      <td>14.39</td>\n",
       "      <td>14.48</td>\n",
       "      <td>1440</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AO</td>\n",
       "      <td>1</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0147.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376835</th>\n",
       "      <td>L</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>148</td>\n",
       "      <td>14.48</td>\n",
       "      <td>14.55</td>\n",
       "      <td>1120</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0148.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376836</th>\n",
       "      <td>S</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>149</td>\n",
       "      <td>14.55</td>\n",
       "      <td>14.58</td>\n",
       "      <td>480</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>4.0</td>\n",
       "      <td>S</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0149.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment              file   id  startTime  endTime  nSample  word_id  \\\n",
       "3            T  1069-133699-0000    3       0.70     0.79     1440      1.0   \n",
       "4          UH1  1069-133699-0000    4       0.79     0.92     2080      1.0   \n",
       "5            K  1069-133699-0000    5       0.92     1.02     1600      1.0   \n",
       "7          AH0  1069-133699-0000    7       1.05     1.16     1760      2.0   \n",
       "14         AE1  1069-133699-0000   14       1.69     1.81     1920      4.0   \n",
       "...        ...               ...  ...        ...      ...      ...      ...   \n",
       "376832     AH0   887-123291-0042  145      14.21    14.27      960     45.0   \n",
       "376833       F   887-123291-0042  146      14.27    14.39     1920     46.0   \n",
       "376834     AO1   887-123291-0042  147      14.39    14.48     1440     46.0   \n",
       "376835       L   887-123291-0042  148      14.48    14.55     1120     46.0   \n",
       "376836       S   887-123291-0042  149      14.55    14.58      480     46.0   \n",
       "\n",
       "         word  in_id segment_nostress stress_type  \\\n",
       "3        took    1.0                T         SNA   \n",
       "4        took    2.0               UH           1   \n",
       "5        took    3.0                K         SNA   \n",
       "7           a    1.0               AH           0   \n",
       "14      after    1.0               AE           1   \n",
       "...       ...    ...              ...         ...   \n",
       "376832      a    1.0               AH           0   \n",
       "376833  false    1.0                F         SNA   \n",
       "376834  false    2.0               AO           1   \n",
       "376835  false    3.0                L         SNA   \n",
       "376836  false    4.0                S         SNA   \n",
       "\n",
       "                                         phone_path  \\\n",
       "3       1069/133699/0000/1069-133699-0000-0003.flac   \n",
       "4       1069/133699/0000/1069-133699-0000-0004.flac   \n",
       "5       1069/133699/0000/1069-133699-0000-0005.flac   \n",
       "7       1069/133699/0000/1069-133699-0000-0007.flac   \n",
       "14      1069/133699/0000/1069-133699-0000-0014.flac   \n",
       "...                                             ...   \n",
       "376832    887/123291/0042/887-123291-0042-0145.flac   \n",
       "376833    887/123291/0042/887-123291-0042-0146.flac   \n",
       "376834    887/123291/0042/887-123291-0042-0147.flac   \n",
       "376835    887/123291/0042/887-123291-0042-0148.flac   \n",
       "376836    887/123291/0042/887-123291-0042-0149.flac   \n",
       "\n",
       "                                          word_path  speaker  word_startTime  \\\n",
       "3       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "4       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "5       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "7       1069/133699/0000/1069-133699-0000-0002.flac     1069            1.05   \n",
       "14      1069/133699/0000/1069-133699-0000-0004.flac     1069            1.69   \n",
       "...                                             ...      ...             ...   \n",
       "376832    887/123291/0042/887-123291-0042-0045.flac      887           14.21   \n",
       "376833    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376834    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376835    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376836    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "\n",
       "        word_endTime  word_nSample                   wuid  startFrame  \\\n",
       "3               1.02        5120.0  1069-133699-0000-0001           0   \n",
       "4               1.02        5120.0  1069-133699-0000-0001           7   \n",
       "5               1.02        5120.0  1069-133699-0000-0001          17   \n",
       "7               1.16        1760.0  1069-133699-0000-0002           0   \n",
       "14              2.04        5600.0  1069-133699-0000-0004           0   \n",
       "...              ...           ...                    ...         ...   \n",
       "376832         14.27         960.0   887-123291-0042-0045           0   \n",
       "376833         14.58        4960.0   887-123291-0042-0046           0   \n",
       "376834         14.58        4960.0   887-123291-0042-0046           9   \n",
       "376835         14.58        4960.0   887-123291-0042-0046          16   \n",
       "376836         14.58        4960.0   887-123291-0042-0046          22   \n",
       "\n",
       "        endFrame  \n",
       "3              7  \n",
       "4             17  \n",
       "5             25  \n",
       "7              8  \n",
       "14             9  \n",
       "...          ...  \n",
       "376832         4  \n",
       "376833         9  \n",
       "376834        16  \n",
       "376835        22  \n",
       "376836        24  \n",
       "\n",
       "[261050 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selwuid = modgf[\"wuid\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "randlist = [np.random.choice(len(selwuid)) for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_phone_df = modgf[modgf[\"segment_nostress\"] == \"IY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "selwuid = modgf[\"wuid\"].unique()[randlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedgf = modgf[modgf[\"wuid\"].isin(selwuid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_phone_df = selectedgf[selectedgf[\"segment_nostress\"] == \"AH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>nSample</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>in_id</th>\n",
       "      <th>segment_nostress</th>\n",
       "      <th>stress_type</th>\n",
       "      <th>phone_path</th>\n",
       "      <th>word_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_startTime</th>\n",
       "      <th>word_endTime</th>\n",
       "      <th>word_nSample</th>\n",
       "      <th>wuid</th>\n",
       "      <th>startFrame</th>\n",
       "      <th>endFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0040</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>was</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0040/1069-133699-0040-0004.flac</td>\n",
       "      <td>1069/133699/0040/1069-133699-0040-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1069-133699-0040-0001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0048</td>\n",
       "      <td>104</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1440</td>\n",
       "      <td>26.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0048/1069-133699-0048-0104.flac</td>\n",
       "      <td>1069/133699/0048/1069-133699-0048-0026.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1069-133699-0048-0026</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19009</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-124588-0010</td>\n",
       "      <td>111</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.18</td>\n",
       "      <td>640</td>\n",
       "      <td>31.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/124588/0010/118-124588-0010-0111.flac</td>\n",
       "      <td>118/124588/0010/118-124588-0010-0031.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.18</td>\n",
       "      <td>640.0</td>\n",
       "      <td>118-124588-0010-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22314</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-47824-0009</td>\n",
       "      <td>42</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.49</td>\n",
       "      <td>480</td>\n",
       "      <td>11.0</td>\n",
       "      <td>lessens</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/47824/0009/118-47824-0009-0042.flac</td>\n",
       "      <td>118/47824/0009/118-47824-0009-0011.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.58</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>118-47824-0009-0011</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24176</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-47824-0027</td>\n",
       "      <td>60</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.35</td>\n",
       "      <td>640</td>\n",
       "      <td>18.0</td>\n",
       "      <td>openly</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/47824/0027/118-47824-0027-0060.flac</td>\n",
       "      <td>118/47824/0027/118-47824-0027-0018.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>118-47824-0027-0018</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26904</th>\n",
       "      <td>AH1</td>\n",
       "      <td>118-47824-0050</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>underbrush</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0003.flac</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0001.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>118-47824-0050-0001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26910</th>\n",
       "      <td>AH2</td>\n",
       "      <td>118-47824-0050</td>\n",
       "      <td>9</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>underbrush</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>2</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0009.flac</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0001.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>118-47824-0050-0001</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44666</th>\n",
       "      <td>AH0</td>\n",
       "      <td>150-132655-0020</td>\n",
       "      <td>14</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>150/132655/0020/150-132655-0020-0014.flac</td>\n",
       "      <td>150/132655/0020/150-132655-0020-0003.flac</td>\n",
       "      <td>150</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.38</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>150-132655-0020-0003</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51976</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1502-122619-0006</td>\n",
       "      <td>50</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.20</td>\n",
       "      <td>640</td>\n",
       "      <td>12.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1502/122619/0006/1502-122619-0006-0050.flac</td>\n",
       "      <td>1502/122619/0006/1502-122619-0006-0012.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.24</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1502-122619-0006-0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56474</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1502-122619-0046</td>\n",
       "      <td>33</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1280</td>\n",
       "      <td>8.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1502/122619/0046/1502-122619-0046-0033.flac</td>\n",
       "      <td>1502/122619/0046/1502-122619-0046-0008.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1502-122619-0046-0008</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57607</th>\n",
       "      <td>AH1</td>\n",
       "      <td>1502-122619-0056</td>\n",
       "      <td>97</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.61</td>\n",
       "      <td>640</td>\n",
       "      <td>20.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>1502/122619/0056/1502-122619-0056-0097.flac</td>\n",
       "      <td>1502/122619/0056/1502-122619-0056-0020.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1502-122619-0056-0020</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61616</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0000</td>\n",
       "      <td>74</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1120</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0000/1992-141719-0000-0074.flac</td>\n",
       "      <td>1992/141719/0000/1992-141719-0000-0018.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1992-141719-0000-0018</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63966</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0017</td>\n",
       "      <td>47</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.10</td>\n",
       "      <td>800</td>\n",
       "      <td>10.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0017/1992-141719-0017-0047.flac</td>\n",
       "      <td>1992/141719/0017/1992-141719-0017-0010.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1992-141719-0017-0010</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69305</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0055</td>\n",
       "      <td>134</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.21</td>\n",
       "      <td>800</td>\n",
       "      <td>39.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0055/1992-141719-0055-0134.flac</td>\n",
       "      <td>1992/141719/0055/1992-141719-0055-0039.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.21</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1992-141719-0055-0039</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82105</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2092-145709-0016</td>\n",
       "      <td>87</td>\n",
       "      <td>10.31</td>\n",
       "      <td>10.34</td>\n",
       "      <td>480</td>\n",
       "      <td>26.0</td>\n",
       "      <td>can</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2092/145709/0016/2092-145709-0016-0087.flac</td>\n",
       "      <td>2092/145709/0016/2092-145709-0016-0026.flac</td>\n",
       "      <td>2092</td>\n",
       "      <td>10.19</td>\n",
       "      <td>10.41</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>2092-145709-0016-0026</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86489</th>\n",
       "      <td>AH1</td>\n",
       "      <td>2159-179154-0027</td>\n",
       "      <td>118</td>\n",
       "      <td>10.07</td>\n",
       "      <td>10.12</td>\n",
       "      <td>800</td>\n",
       "      <td>30.0</td>\n",
       "      <td>subject</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>2159/179154/0027/2159-179154-0027-0118.flac</td>\n",
       "      <td>2159/179154/0027/2159-179154-0027-0030.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>9.96</td>\n",
       "      <td>10.41</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>2159-179154-0027-0030</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92032</th>\n",
       "      <td>AH1</td>\n",
       "      <td>2159-179156-0026</td>\n",
       "      <td>81</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.96</td>\n",
       "      <td>480</td>\n",
       "      <td>20.0</td>\n",
       "      <td>pulse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>2159/179156/0026/2159-179156-0026-0081.flac</td>\n",
       "      <td>2159/179156/0026/2159-179156-0026-0020.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>6.79</td>\n",
       "      <td>7.21</td>\n",
       "      <td>6720.0</td>\n",
       "      <td>2159-179156-0026-0020</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93684</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2159-179157-0003</td>\n",
       "      <td>57</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.95</td>\n",
       "      <td>960</td>\n",
       "      <td>11.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2159/179157/0003/2159-179157-0003-0057.flac</td>\n",
       "      <td>2159/179157/0003/2159-179157-0003-0011.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>2159-179157-0003-0011</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102889</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2836-5354-0031</td>\n",
       "      <td>24</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.24</td>\n",
       "      <td>800</td>\n",
       "      <td>6.0</td>\n",
       "      <td>isabel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2836/5354/0031/2836-5354-0031-0024.flac</td>\n",
       "      <td>2836/5354/0031/2836-5354-0031-0006.flac</td>\n",
       "      <td>2836</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.48</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>2836-5354-0031-0006</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120503</th>\n",
       "      <td>AH0</td>\n",
       "      <td>298-126790-0038</td>\n",
       "      <td>54</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>960</td>\n",
       "      <td>15.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>298/126790/0038/298-126790-0038-0054.flac</td>\n",
       "      <td>298/126790/0038/298-126790-0038-0015.flac</td>\n",
       "      <td>298</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>960.0</td>\n",
       "      <td>298-126790-0038-0015</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125414</th>\n",
       "      <td>AH0</td>\n",
       "      <td>298-126791-0021</td>\n",
       "      <td>107</td>\n",
       "      <td>7.86</td>\n",
       "      <td>7.91</td>\n",
       "      <td>800</td>\n",
       "      <td>27.0</td>\n",
       "      <td>noticed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>298/126791/0021/298-126791-0021-0107.flac</td>\n",
       "      <td>298/126791/0021/298-126791-0021-0027.flac</td>\n",
       "      <td>298</td>\n",
       "      <td>7.65</td>\n",
       "      <td>8.04</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>298-126791-0021-0027</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146738</th>\n",
       "      <td>AH0</td>\n",
       "      <td>302-123523-0029</td>\n",
       "      <td>17</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.71</td>\n",
       "      <td>960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>302/123523/0029/302-123523-0029-0017.flac</td>\n",
       "      <td>302/123523/0029/302-123523-0029-0002.flac</td>\n",
       "      <td>302</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>302-123523-0029-0002</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153279</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3168-173564-0041</td>\n",
       "      <td>55</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.11</td>\n",
       "      <td>1120</td>\n",
       "      <td>15.0</td>\n",
       "      <td>wounded</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3168/173564/0041/3168-173564-0041-0055.flac</td>\n",
       "      <td>3168/173564/0041/3168-173564-0041-0015.flac</td>\n",
       "      <td>3168</td>\n",
       "      <td>5.79</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6080.0</td>\n",
       "      <td>3168-173564-0041-0015</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162095</th>\n",
       "      <td>AH0</td>\n",
       "      <td>322-124146-0002</td>\n",
       "      <td>18</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.81</td>\n",
       "      <td>640</td>\n",
       "      <td>3.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>322/124146/0002/322-124146-0002-0018.flac</td>\n",
       "      <td>322/124146/0002/322-124146-0002-0003.flac</td>\n",
       "      <td>322</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>322-124146-0002-0003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168418</th>\n",
       "      <td>AH0</td>\n",
       "      <td>322-124147-0022</td>\n",
       "      <td>117</td>\n",
       "      <td>12.88</td>\n",
       "      <td>12.94</td>\n",
       "      <td>960</td>\n",
       "      <td>28.0</td>\n",
       "      <td>dearest</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>322/124147/0022/322-124147-0022-0117.flac</td>\n",
       "      <td>322/124147/0022/322-124147-0022-0028.flac</td>\n",
       "      <td>322</td>\n",
       "      <td>12.68</td>\n",
       "      <td>13.08</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>322-124147-0022-0028</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178551</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3240-131231-0023</td>\n",
       "      <td>11</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3240/131231/0023/3240-131231-0023-0011.flac</td>\n",
       "      <td>3240/131231/0023/3240-131231-0023-0003.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3240-131231-0023-0003</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182196</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3240-131231-0055</td>\n",
       "      <td>9</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1280</td>\n",
       "      <td>2.0</td>\n",
       "      <td>july</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3240/131231/0055/3240-131231-0055-0009.flac</td>\n",
       "      <td>3240/131231/0055/3240-131231-0055-0002.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>3240-131231-0055-0002</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183419</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3240-131231-0065</td>\n",
       "      <td>87</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.36</td>\n",
       "      <td>640</td>\n",
       "      <td>24.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3240/131231/0065/3240-131231-0065-0087.flac</td>\n",
       "      <td>3240/131231/0065/3240-131231-0065-0024.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>3240-131231-0065-0024</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194998</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3440-171006-0020</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blushing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3440/171006/0020/3440-171006-0020-0003.flac</td>\n",
       "      <td>3440/171006/0020/3440-171006-0020-0000.flac</td>\n",
       "      <td>3440</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.57</td>\n",
       "      <td>6560.0</td>\n",
       "      <td>3440-171006-0020-0000</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206558</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3440-171009-0070</td>\n",
       "      <td>100</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.05</td>\n",
       "      <td>480</td>\n",
       "      <td>28.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3440/171009/0070/3440-171009-0070-0100.flac</td>\n",
       "      <td>3440/171009/0070/3440-171009-0070-0028.flac</td>\n",
       "      <td>3440</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>3440-171009-0070-0028</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209417</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4923-0009</td>\n",
       "      <td>100</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.55</td>\n",
       "      <td>960</td>\n",
       "      <td>25.0</td>\n",
       "      <td>pilot's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4923/0009/3807-4923-0009-0100.flac</td>\n",
       "      <td>3807/4923/0009/3807-4923-0009-0025.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.65</td>\n",
       "      <td>6880.0</td>\n",
       "      <td>3807-4923-0009-0025</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213880</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4923-0040</td>\n",
       "      <td>91</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.07</td>\n",
       "      <td>480</td>\n",
       "      <td>26.0</td>\n",
       "      <td>polite</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4923/0040/3807-4923-0040-0091.flac</td>\n",
       "      <td>3807/4923/0040/3807-4923-0040-0026.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>7.96</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>3807-4923-0040-0026</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216975</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0002</td>\n",
       "      <td>111</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1760</td>\n",
       "      <td>30.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0002/3807-4955-0002-0111.flac</td>\n",
       "      <td>3807/4955/0002/3807-4955-0002-0030.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.66</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3807-4955-0002-0030</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219823</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0020</td>\n",
       "      <td>17</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.49</td>\n",
       "      <td>960</td>\n",
       "      <td>3.0</td>\n",
       "      <td>plus</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0020/3807-4955-0020-0017.flac</td>\n",
       "      <td>3807/4955/0020/3807-4955-0020-0003.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>3807-4955-0020-0003</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222669</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0038</td>\n",
       "      <td>58</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.73</td>\n",
       "      <td>480</td>\n",
       "      <td>16.0</td>\n",
       "      <td>vulcan's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0058.flac</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0016.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>3807-4955-0038-0016</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222672</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4955-0038</td>\n",
       "      <td>61</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.93</td>\n",
       "      <td>640</td>\n",
       "      <td>16.0</td>\n",
       "      <td>vulcan's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0061.flac</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0016.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>3807-4955-0038-0016</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228370</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186236-0001</td>\n",
       "      <td>19</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.69</td>\n",
       "      <td>960</td>\n",
       "      <td>5.0</td>\n",
       "      <td>servants</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186236/0001/4195-186236-0001-0019.flac</td>\n",
       "      <td>4195/186236/0001/4195-186236-0001-0005.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>4195-186236-0001-0005</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234828</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186237-0023</td>\n",
       "      <td>17</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.19</td>\n",
       "      <td>640</td>\n",
       "      <td>6.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186237/0023/4195-186237-0023-0017.flac</td>\n",
       "      <td>4195/186237/0023/4195-186237-0023-0006.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>4195-186237-0023-0006</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235992</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186237-0030</td>\n",
       "      <td>115</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.34</td>\n",
       "      <td>640</td>\n",
       "      <td>27.0</td>\n",
       "      <td>truthful</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186237/0030/4195-186237-0030-0115.flac</td>\n",
       "      <td>4195/186237/0030/4195-186237-0030-0027.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>9.95</td>\n",
       "      <td>10.42</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>4195-186237-0030-0027</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238732</th>\n",
       "      <td>AH1</td>\n",
       "      <td>4195-186238-0017</td>\n",
       "      <td>87</td>\n",
       "      <td>8.92</td>\n",
       "      <td>8.97</td>\n",
       "      <td>800</td>\n",
       "      <td>26.0</td>\n",
       "      <td>come</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>4195/186238/0017/4195-186238-0017-0087.flac</td>\n",
       "      <td>4195/186238/0017/4195-186238-0017-0026.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>8.78</td>\n",
       "      <td>9.04</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>4195-186238-0017-0026</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240265</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4397-15666-0001</td>\n",
       "      <td>41</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.40</td>\n",
       "      <td>480</td>\n",
       "      <td>10.0</td>\n",
       "      <td>local</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4397/15666/0001/4397-15666-0001-0041.flac</td>\n",
       "      <td>4397/15666/0001/4397-15666-0001-0010.flac</td>\n",
       "      <td>4397</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.47</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>4397-15666-0001-0010</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251966</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4397-15678-0013</td>\n",
       "      <td>79</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.05</td>\n",
       "      <td>480</td>\n",
       "      <td>19.0</td>\n",
       "      <td>terminus</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4397/15678/0013/4397-15678-0013-0079.flac</td>\n",
       "      <td>4397/15678/0013/4397-15678-0013-0019.flac</td>\n",
       "      <td>4397</td>\n",
       "      <td>6.78</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>4397-15678-0013-0019</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264094</th>\n",
       "      <td>AH0</td>\n",
       "      <td>446-123502-0000</td>\n",
       "      <td>107</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>800</td>\n",
       "      <td>31.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>446/123502/0000/446-123502-0000-0107.flac</td>\n",
       "      <td>446/123502/0000/446-123502-0000-0031.flac</td>\n",
       "      <td>446</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.35</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>446-123502-0000-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270544</th>\n",
       "      <td>AH1</td>\n",
       "      <td>446-123502-0046</td>\n",
       "      <td>44</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.14</td>\n",
       "      <td>800</td>\n",
       "      <td>11.0</td>\n",
       "      <td>from</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>446/123502/0046/446-123502-0046-0044.flac</td>\n",
       "      <td>446/123502/0046/446-123502-0046-0011.flac</td>\n",
       "      <td>446</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>446-123502-0046-0011</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275088</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4788-294466-0029</td>\n",
       "      <td>22</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.37</td>\n",
       "      <td>960</td>\n",
       "      <td>6.0</td>\n",
       "      <td>that</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4788/294466/0029/4788-294466-0029-0022.flac</td>\n",
       "      <td>4788/294466/0029/4788-294466-0029-0006.flac</td>\n",
       "      <td>4788</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>4788-294466-0029-0006</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282021</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4788-94904-0004</td>\n",
       "      <td>136</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.45</td>\n",
       "      <td>1600</td>\n",
       "      <td>33.0</td>\n",
       "      <td>than</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4788/94904/0004/4788-94904-0004-0136.flac</td>\n",
       "      <td>4788/94904/0004/4788-94904-0004-0033.flac</td>\n",
       "      <td>4788</td>\n",
       "      <td>12.26</td>\n",
       "      <td>12.52</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>4788-94904-0004-0033</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289220</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5163-18515-0011</td>\n",
       "      <td>109</td>\n",
       "      <td>11.37</td>\n",
       "      <td>11.41</td>\n",
       "      <td>640</td>\n",
       "      <td>33.0</td>\n",
       "      <td>people</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5163/18515/0011/5163-18515-0011-0109.flac</td>\n",
       "      <td>5163/18515/0011/5163-18515-0011-0033.flac</td>\n",
       "      <td>5163</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11.48</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>5163-18515-0011-0033</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290102</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5163-18515-0018</td>\n",
       "      <td>51</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1120</td>\n",
       "      <td>14.0</td>\n",
       "      <td>along</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5163/18515/0018/5163-18515-0018-0051.flac</td>\n",
       "      <td>5163/18515/0018/5163-18515-0018-0014.flac</td>\n",
       "      <td>5163</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>5163-18515-0018-0014</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307573</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14133-0039</td>\n",
       "      <td>156</td>\n",
       "      <td>14.74</td>\n",
       "      <td>14.80</td>\n",
       "      <td>960</td>\n",
       "      <td>52.0</td>\n",
       "      <td>to</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14133/0039/5339-14133-0039-0156.flac</td>\n",
       "      <td>5339/14133/0039/5339-14133-0039-0052.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>14.67</td>\n",
       "      <td>14.80</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>5339-14133-0039-0052</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312485</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14134-0018</td>\n",
       "      <td>86</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.74</td>\n",
       "      <td>960</td>\n",
       "      <td>21.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14134/0018/5339-14134-0018-0086.flac</td>\n",
       "      <td>5339/14134/0018/5339-14134-0018-0021.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>5339-14134-0018-0021</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312905</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14134-0020</td>\n",
       "      <td>145</td>\n",
       "      <td>11.03</td>\n",
       "      <td>11.06</td>\n",
       "      <td>480</td>\n",
       "      <td>33.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14134/0020/5339-14134-0020-0145.flac</td>\n",
       "      <td>5339/14134/0020/5339-14134-0020-0033.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.06</td>\n",
       "      <td>960.0</td>\n",
       "      <td>5339-14134-0020-0033</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334776</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-368-0006</td>\n",
       "      <td>30</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.88</td>\n",
       "      <td>480</td>\n",
       "      <td>9.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/368/0006/78-368-0006-0030.flac</td>\n",
       "      <td>78/368/0006/78-368-0006-0009.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>78-368-0006-0009</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341830</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0018/78-369-0018-0002.flac</td>\n",
       "      <td>78/369/0018/78-369-0018-0000.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>78-369-0018-0000</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342377</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0022</td>\n",
       "      <td>117</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.04</td>\n",
       "      <td>640</td>\n",
       "      <td>31.0</td>\n",
       "      <td>alone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0022/78-369-0022-0117.flac</td>\n",
       "      <td>78/369/0022/78-369-0022-0031.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>78-369-0022-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343292</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0030</td>\n",
       "      <td>20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.80</td>\n",
       "      <td>800</td>\n",
       "      <td>6.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0030/78-369-0030-0020.flac</td>\n",
       "      <td>78/369/0030/78-369-0030-0006.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>78-369-0030-0006</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349117</th>\n",
       "      <td>AH0</td>\n",
       "      <td>8098-275181-0013</td>\n",
       "      <td>28</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1120</td>\n",
       "      <td>10.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>8098/275181/0013/8098-275181-0013-0028.flac</td>\n",
       "      <td>8098/275181/0013/8098-275181-0013-0010.flac</td>\n",
       "      <td>8098</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>8098-275181-0013-0010</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349948</th>\n",
       "      <td>AH0</td>\n",
       "      <td>8098-275181-0021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>8098/275181/0021/8098-275181-0021-0005.flac</td>\n",
       "      <td>8098/275181/0021/8098-275181-0021-0001.flac</td>\n",
       "      <td>8098</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>8098-275181-0021-0001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365811</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0032</td>\n",
       "      <td>73</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.67</td>\n",
       "      <td>800</td>\n",
       "      <td>21.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0032/887-123289-0032-0073.flac</td>\n",
       "      <td>887/123289/0032/887-123289-0032-0021.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>887-123289-0032-0021</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366475</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0038</td>\n",
       "      <td>138</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.17</td>\n",
       "      <td>480</td>\n",
       "      <td>38.0</td>\n",
       "      <td>examined</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0138.flac</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0038.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>12.78</td>\n",
       "      <td>13.26</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>887-123289-0038-0038</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366480</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0038</td>\n",
       "      <td>143</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.39</td>\n",
       "      <td>640</td>\n",
       "      <td>40.0</td>\n",
       "      <td>again</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0143.flac</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0040.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.82</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>887-123289-0038-0040</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment              file   id  startTime  endTime  nSample  word_id  \\\n",
       "5331       AH0  1069-133699-0040    4       0.50     0.57     1120      1.0   \n",
       "6502       AH0  1069-133699-0048  104       9.88     9.97     1440     26.0   \n",
       "19009      AH0   118-124588-0010  111       9.14     9.18      640     31.0   \n",
       "22314      AH0    118-47824-0009   42       4.46     4.49      480     11.0   \n",
       "24176      AH0    118-47824-0027   60       4.31     4.35      640     18.0   \n",
       "26904      AH1    118-47824-0050    3       0.71     0.75      640      1.0   \n",
       "26910      AH2    118-47824-0050    9       1.06     1.13     1120      1.0   \n",
       "44666      AH0   150-132655-0020   14       1.20     1.30     1600      3.0   \n",
       "51976      AH0  1502-122619-0006   50       4.16     4.20      640     12.0   \n",
       "56474      AH0  1502-122619-0046   33       2.62     2.70     1280      8.0   \n",
       "57607      AH1  1502-122619-0056   97       8.57     8.61      640     20.0   \n",
       "61616      AH0  1992-141719-0000   74       6.73     6.80     1120     18.0   \n",
       "63966      AH0  1992-141719-0017   47       5.05     5.10      800     10.0   \n",
       "69305      AH0  1992-141719-0055  134      12.16    12.21      800     39.0   \n",
       "82105      AH0  2092-145709-0016   87      10.31    10.34      480     26.0   \n",
       "86489      AH1  2159-179154-0027  118      10.07    10.12      800     30.0   \n",
       "92032      AH1  2159-179156-0026   81       6.93     6.96      480     20.0   \n",
       "93684      AH0  2159-179157-0003   57       4.89     4.95      960     11.0   \n",
       "102889     AH0    2836-5354-0031   24       2.19     2.24      800      6.0   \n",
       "120503     AH0   298-126790-0038   54       3.63     3.69      960     15.0   \n",
       "125414     AH0   298-126791-0021  107       7.86     7.91      800     27.0   \n",
       "146738     AH0   302-123523-0029   17       1.65     1.71      960      2.0   \n",
       "153279     AH0  3168-173564-0041   55       6.04     6.11     1120     15.0   \n",
       "162095     AH0   322-124146-0002   18       1.77     1.81      640      3.0   \n",
       "168418     AH0   322-124147-0022  117      12.88    12.94      960     28.0   \n",
       "178551     AH0  3240-131231-0023   11       0.99     1.06     1120      3.0   \n",
       "182196     AH0  3240-131231-0055    9       1.82     1.90     1280      2.0   \n",
       "183419     AH1  3240-131231-0065   87       7.32     7.36      640     24.0   \n",
       "194998     AH1  3440-171006-0020    3       0.25     0.31      960      0.0   \n",
       "206558     AH0  3440-171009-0070  100      10.02    10.05      480     28.0   \n",
       "209417     AH0    3807-4923-0009  100       8.49     8.55      960     25.0   \n",
       "213880     AH0    3807-4923-0040   91       8.04     8.07      480     26.0   \n",
       "216975     AH1    3807-4955-0002  111       9.46     9.57     1760     30.0   \n",
       "219823     AH1    3807-4955-0020   17       1.43     1.49      960      3.0   \n",
       "222669     AH1    3807-4955-0038   58       5.70     5.73      480     16.0   \n",
       "222672     AH0    3807-4955-0038   61       5.89     5.93      640     16.0   \n",
       "228370     AH0  4195-186236-0001   19       1.63     1.69      960      5.0   \n",
       "234828     AH0  4195-186237-0023   17       1.15     1.19      640      6.0   \n",
       "235992     AH0  4195-186237-0030  115      10.30    10.34      640     27.0   \n",
       "238732     AH1  4195-186238-0017   87       8.92     8.97      800     26.0   \n",
       "240265     AH0   4397-15666-0001   41       3.37     3.40      480     10.0   \n",
       "251966     AH0   4397-15678-0013   79       7.02     7.05      480     19.0   \n",
       "264094     AH0   446-123502-0000  107      11.20    11.25      800     31.0   \n",
       "270544     AH1   446-123502-0046   44       4.09     4.14      800     11.0   \n",
       "275088     AH0  4788-294466-0029   22       2.31     2.37      960      6.0   \n",
       "282021     AH0   4788-94904-0004  136      12.35    12.45     1600     33.0   \n",
       "289220     AH0   5163-18515-0011  109      11.37    11.41      640     33.0   \n",
       "290102     AH0   5163-18515-0018   51       5.60     5.67     1120     14.0   \n",
       "307573     AH0   5339-14133-0039  156      14.74    14.80      960     52.0   \n",
       "312485     AH0   5339-14134-0018   86       6.68     6.74      960     21.0   \n",
       "312905     AH0   5339-14134-0020  145      11.03    11.06      480     33.0   \n",
       "334776     AH0       78-368-0006   30       2.85     2.88      480      9.0   \n",
       "341830     AH0       78-369-0018    2       0.61     0.66      800      0.0   \n",
       "342377     AH0       78-369-0022  117      11.00    11.04      640     31.0   \n",
       "343292     AH0       78-369-0030   20       1.75     1.80      800      6.0   \n",
       "349117     AH0  8098-275181-0013   28       3.54     3.61     1120     10.0   \n",
       "349948     AH0  8098-275181-0021    5       0.64     0.73     1440      1.0   \n",
       "365811     AH0   887-123289-0032   73       6.62     6.67      800     21.0   \n",
       "366475     AH0   887-123289-0038  138      13.14    13.17      480     38.0   \n",
       "366480     AH0   887-123289-0038  143      13.35    13.39      640     40.0   \n",
       "\n",
       "              word  in_id segment_nostress stress_type  \\\n",
       "5331           was    2.0               AH           0   \n",
       "6502             a    1.0               AH           0   \n",
       "19009            a    1.0               AH           0   \n",
       "22314      lessens    4.0               AH           0   \n",
       "24176       openly    3.0               AH           0   \n",
       "26904   underbrush    1.0               AH           1   \n",
       "26910   underbrush    7.0               AH           2   \n",
       "44666      general    5.0               AH           0   \n",
       "51976           of    1.0               AH           0   \n",
       "56474            a    1.0               AH           0   \n",
       "57607           of    1.0               AH           1   \n",
       "61616          the    2.0               AH           0   \n",
       "63966          the    2.0               AH           0   \n",
       "69305            a    1.0               AH           0   \n",
       "82105          can    2.0               AH           0   \n",
       "86489      subject    2.0               AH           1   \n",
       "92032        pulse    2.0               AH           1   \n",
       "93684          the    2.0               AH           0   \n",
       "102889      isabel    3.0               AH           0   \n",
       "120503           a    1.0               AH           0   \n",
       "125414     noticed    4.0               AH           0   \n",
       "146738         the    2.0               AH           0   \n",
       "153279     wounded    5.0               AH           0   \n",
       "162095         and    1.0               AH           0   \n",
       "168418     dearest    4.0               AH           0   \n",
       "178551         the    2.0               AH           0   \n",
       "182196        july    2.0               AH           0   \n",
       "183419         the    2.0               AH           1   \n",
       "194998    blushing    3.0               AH           1   \n",
       "206558         and    1.0               AH           0   \n",
       "209417     pilot's    4.0               AH           0   \n",
       "213880      polite    2.0               AH           0   \n",
       "216975          of    1.0               AH           1   \n",
       "219823        plus    3.0               AH           1   \n",
       "222669    vulcan's    2.0               AH           1   \n",
       "222672    vulcan's    5.0               AH           0   \n",
       "228370    servants    4.0               AH           0   \n",
       "234828          of    1.0               AH           0   \n",
       "235992    truthful    6.0               AH           0   \n",
       "238732        come    2.0               AH           1   \n",
       "240265       local    4.0               AH           0   \n",
       "251966    terminus    4.0               AH           0   \n",
       "264094          of    1.0               AH           0   \n",
       "270544        from    3.0               AH           1   \n",
       "275088        that    2.0               AH           0   \n",
       "282021        than    2.0               AH           0   \n",
       "289220      people    4.0               AH           0   \n",
       "290102       along    1.0               AH           0   \n",
       "307573          to    2.0               AH           0   \n",
       "312485          of    1.0               AH           0   \n",
       "312905         the    2.0               AH           0   \n",
       "334776         and    1.0               AH           0   \n",
       "341830         the    2.0               AH           0   \n",
       "342377       alone    1.0               AH           0   \n",
       "343292          of    1.0               AH           0   \n",
       "349117           a    1.0               AH           0   \n",
       "349948         the    2.0               AH           0   \n",
       "365811         the    2.0               AH           0   \n",
       "366475    examined    6.0               AH           0   \n",
       "366480       again    1.0               AH           0   \n",
       "\n",
       "                                         phone_path  \\\n",
       "5331    1069/133699/0040/1069-133699-0040-0004.flac   \n",
       "6502    1069/133699/0048/1069-133699-0048-0104.flac   \n",
       "19009     118/124588/0010/118-124588-0010-0111.flac   \n",
       "22314       118/47824/0009/118-47824-0009-0042.flac   \n",
       "24176       118/47824/0027/118-47824-0027-0060.flac   \n",
       "26904       118/47824/0050/118-47824-0050-0003.flac   \n",
       "26910       118/47824/0050/118-47824-0050-0009.flac   \n",
       "44666     150/132655/0020/150-132655-0020-0014.flac   \n",
       "51976   1502/122619/0006/1502-122619-0006-0050.flac   \n",
       "56474   1502/122619/0046/1502-122619-0046-0033.flac   \n",
       "57607   1502/122619/0056/1502-122619-0056-0097.flac   \n",
       "61616   1992/141719/0000/1992-141719-0000-0074.flac   \n",
       "63966   1992/141719/0017/1992-141719-0017-0047.flac   \n",
       "69305   1992/141719/0055/1992-141719-0055-0134.flac   \n",
       "82105   2092/145709/0016/2092-145709-0016-0087.flac   \n",
       "86489   2159/179154/0027/2159-179154-0027-0118.flac   \n",
       "92032   2159/179156/0026/2159-179156-0026-0081.flac   \n",
       "93684   2159/179157/0003/2159-179157-0003-0057.flac   \n",
       "102889      2836/5354/0031/2836-5354-0031-0024.flac   \n",
       "120503    298/126790/0038/298-126790-0038-0054.flac   \n",
       "125414    298/126791/0021/298-126791-0021-0107.flac   \n",
       "146738    302/123523/0029/302-123523-0029-0017.flac   \n",
       "153279  3168/173564/0041/3168-173564-0041-0055.flac   \n",
       "162095    322/124146/0002/322-124146-0002-0018.flac   \n",
       "168418    322/124147/0022/322-124147-0022-0117.flac   \n",
       "178551  3240/131231/0023/3240-131231-0023-0011.flac   \n",
       "182196  3240/131231/0055/3240-131231-0055-0009.flac   \n",
       "183419  3240/131231/0065/3240-131231-0065-0087.flac   \n",
       "194998  3440/171006/0020/3440-171006-0020-0003.flac   \n",
       "206558  3440/171009/0070/3440-171009-0070-0100.flac   \n",
       "209417      3807/4923/0009/3807-4923-0009-0100.flac   \n",
       "213880      3807/4923/0040/3807-4923-0040-0091.flac   \n",
       "216975      3807/4955/0002/3807-4955-0002-0111.flac   \n",
       "219823      3807/4955/0020/3807-4955-0020-0017.flac   \n",
       "222669      3807/4955/0038/3807-4955-0038-0058.flac   \n",
       "222672      3807/4955/0038/3807-4955-0038-0061.flac   \n",
       "228370  4195/186236/0001/4195-186236-0001-0019.flac   \n",
       "234828  4195/186237/0023/4195-186237-0023-0017.flac   \n",
       "235992  4195/186237/0030/4195-186237-0030-0115.flac   \n",
       "238732  4195/186238/0017/4195-186238-0017-0087.flac   \n",
       "240265    4397/15666/0001/4397-15666-0001-0041.flac   \n",
       "251966    4397/15678/0013/4397-15678-0013-0079.flac   \n",
       "264094    446/123502/0000/446-123502-0000-0107.flac   \n",
       "270544    446/123502/0046/446-123502-0046-0044.flac   \n",
       "275088  4788/294466/0029/4788-294466-0029-0022.flac   \n",
       "282021    4788/94904/0004/4788-94904-0004-0136.flac   \n",
       "289220    5163/18515/0011/5163-18515-0011-0109.flac   \n",
       "290102    5163/18515/0018/5163-18515-0018-0051.flac   \n",
       "307573    5339/14133/0039/5339-14133-0039-0156.flac   \n",
       "312485    5339/14134/0018/5339-14134-0018-0086.flac   \n",
       "312905    5339/14134/0020/5339-14134-0020-0145.flac   \n",
       "334776            78/368/0006/78-368-0006-0030.flac   \n",
       "341830            78/369/0018/78-369-0018-0002.flac   \n",
       "342377            78/369/0022/78-369-0022-0117.flac   \n",
       "343292            78/369/0030/78-369-0030-0020.flac   \n",
       "349117  8098/275181/0013/8098-275181-0013-0028.flac   \n",
       "349948  8098/275181/0021/8098-275181-0021-0005.flac   \n",
       "365811    887/123289/0032/887-123289-0032-0073.flac   \n",
       "366475    887/123289/0038/887-123289-0038-0138.flac   \n",
       "366480    887/123289/0038/887-123289-0038-0143.flac   \n",
       "\n",
       "                                          word_path  speaker  word_startTime  \\\n",
       "5331    1069/133699/0040/1069-133699-0040-0001.flac     1069            0.44   \n",
       "6502    1069/133699/0048/1069-133699-0048-0026.flac     1069            9.88   \n",
       "19009     118/124588/0010/118-124588-0010-0031.flac      118            9.14   \n",
       "22314       118/47824/0009/118-47824-0009-0011.flac      118            4.19   \n",
       "24176       118/47824/0027/118-47824-0027-0018.flac      118            4.16   \n",
       "26904       118/47824/0050/118-47824-0050-0001.flac      118            0.71   \n",
       "26910       118/47824/0050/118-47824-0050-0001.flac      118            0.71   \n",
       "44666     150/132655/0020/150-132655-0020-0003.flac      150            0.94   \n",
       "51976   1502/122619/0006/1502-122619-0006-0012.flac     1502            4.16   \n",
       "56474   1502/122619/0046/1502-122619-0046-0008.flac     1502            2.62   \n",
       "57607   1502/122619/0056/1502-122619-0056-0020.flac     1502            8.57   \n",
       "61616   1992/141719/0000/1992-141719-0000-0018.flac     1992            6.68   \n",
       "63966   1992/141719/0017/1992-141719-0017-0010.flac     1992            4.99   \n",
       "69305   1992/141719/0055/1992-141719-0055-0039.flac     1992           12.16   \n",
       "82105   2092/145709/0016/2092-145709-0016-0026.flac     2092           10.19   \n",
       "86489   2159/179154/0027/2159-179154-0027-0030.flac     2159            9.96   \n",
       "92032   2159/179156/0026/2159-179156-0026-0020.flac     2159            6.79   \n",
       "93684   2159/179157/0003/2159-179157-0003-0011.flac     2159            4.83   \n",
       "102889      2836/5354/0031/2836-5354-0031-0006.flac     2836            2.03   \n",
       "120503    298/126790/0038/298-126790-0038-0015.flac      298            3.63   \n",
       "125414    298/126791/0021/298-126791-0021-0027.flac      298            7.65   \n",
       "146738    302/123523/0029/302-123523-0029-0002.flac      302            1.61   \n",
       "153279  3168/173564/0041/3168-173564-0041-0015.flac     3168            5.79   \n",
       "162095    322/124146/0002/322-124146-0002-0003.flac      322            1.77   \n",
       "168418    322/124147/0022/322-124147-0022-0028.flac      322           12.68   \n",
       "178551  3240/131231/0023/3240-131231-0023-0003.flac     3240            0.96   \n",
       "182196  3240/131231/0055/3240-131231-0055-0002.flac     3240            1.75   \n",
       "183419  3240/131231/0065/3240-131231-0065-0024.flac     3240            7.29   \n",
       "194998  3440/171006/0020/3440-171006-0020-0000.flac     3440            0.16   \n",
       "206558  3440/171009/0070/3440-171009-0070-0028.flac     3440           10.02   \n",
       "209417      3807/4923/0009/3807-4923-0009-0025.flac     3807            8.22   \n",
       "213880      3807/4923/0040/3807-4923-0040-0026.flac     3807            7.96   \n",
       "216975      3807/4955/0002/3807-4955-0002-0030.flac     3807            9.46   \n",
       "219823      3807/4955/0020/3807-4955-0020-0003.flac     3807            1.30   \n",
       "222669      3807/4955/0038/3807-4955-0038-0016.flac     3807            5.61   \n",
       "222672      3807/4955/0038/3807-4955-0038-0016.flac     3807            5.61   \n",
       "228370  4195/186236/0001/4195-186236-0001-0005.flac     4195            1.40   \n",
       "234828  4195/186237/0023/4195-186237-0023-0006.flac     4195            1.15   \n",
       "235992  4195/186237/0030/4195-186237-0030-0027.flac     4195            9.95   \n",
       "238732  4195/186238/0017/4195-186238-0017-0026.flac     4195            8.78   \n",
       "240265    4397/15666/0001/4397-15666-0001-0010.flac     4397            3.16   \n",
       "251966    4397/15678/0013/4397-15678-0013-0019.flac     4397            6.78   \n",
       "264094    446/123502/0000/446-123502-0000-0031.flac      446           11.20   \n",
       "270544    446/123502/0046/446-123502-0046-0011.flac      446            3.98   \n",
       "275088  4788/294466/0029/4788-294466-0029-0006.flac     4788            2.26   \n",
       "282021    4788/94904/0004/4788-94904-0004-0033.flac     4788           12.26   \n",
       "289220    5163/18515/0011/5163-18515-0011-0033.flac     5163           11.09   \n",
       "290102    5163/18515/0018/5163-18515-0018-0014.flac     5163            5.60   \n",
       "307573    5339/14133/0039/5339-14133-0039-0052.flac     5339           14.67   \n",
       "312485    5339/14134/0018/5339-14134-0018-0021.flac     5339            6.68   \n",
       "312905    5339/14134/0020/5339-14134-0020-0033.flac     5339           11.00   \n",
       "334776            78/368/0006/78-368-0006-0009.flac       78            2.85   \n",
       "341830            78/369/0018/78-369-0018-0000.flac       78            0.53   \n",
       "342377            78/369/0022/78-369-0022-0031.flac       78           11.00   \n",
       "343292            78/369/0030/78-369-0030-0006.flac       78            1.75   \n",
       "349117  8098/275181/0013/8098-275181-0013-0010.flac     8098            3.54   \n",
       "349948  8098/275181/0021/8098-275181-0021-0001.flac     8098            0.60   \n",
       "365811    887/123289/0032/887-123289-0032-0021.flac      887            6.59   \n",
       "366475    887/123289/0038/887-123289-0038-0038.flac      887           12.78   \n",
       "366480    887/123289/0038/887-123289-0038-0040.flac      887           13.35   \n",
       "\n",
       "        word_endTime  word_nSample                   wuid  startFrame  \\\n",
       "5331            0.64        3200.0  1069-133699-0040-0001           4   \n",
       "6502            9.97        1440.0  1069-133699-0048-0026           0   \n",
       "19009           9.18         640.0   118-124588-0010-0031           0   \n",
       "22314           4.58        6240.0    118-47824-0009-0011          21   \n",
       "24176           4.48        5120.0    118-47824-0027-0018          11   \n",
       "26904           1.20        7840.0    118-47824-0050-0001           0   \n",
       "26910           1.20        7840.0    118-47824-0050-0001          28   \n",
       "44666           1.38        7040.0   150-132655-0020-0003          20   \n",
       "51976           4.24        1280.0  1502-122619-0006-0012           0   \n",
       "56474           2.70        1280.0  1502-122619-0046-0008           0   \n",
       "57607           8.64        1120.0  1502-122619-0056-0020           0   \n",
       "61616           6.80        1920.0  1992-141719-0000-0018           4   \n",
       "63966           5.10        1760.0  1992-141719-0017-0010           4   \n",
       "69305          12.21         800.0  1992-141719-0055-0039           0   \n",
       "82105          10.41        3520.0  2092-145709-0016-0026           9   \n",
       "86489          10.41        7200.0  2159-179154-0027-0030           8   \n",
       "92032           7.21        6720.0  2159-179156-0026-0020          11   \n",
       "93684           4.95        1920.0  2159-179157-0003-0011           4   \n",
       "102889          2.48        7200.0    2836-5354-0031-0006          12   \n",
       "120503          3.69         960.0   298-126790-0038-0015           0   \n",
       "125414          8.04        6240.0   298-126791-0021-0027          16   \n",
       "146738          1.71        1600.0   302-123523-0029-0002           3   \n",
       "153279          6.17        6080.0  3168-173564-0041-0015          20   \n",
       "162095          1.88        1760.0   322-124146-0002-0003           0   \n",
       "168418         13.08        6400.0   322-124147-0022-0028          16   \n",
       "178551          1.06        1600.0  3240-131231-0023-0003           2   \n",
       "182196          2.10        5600.0  3240-131231-0055-0002           5   \n",
       "183419          7.36        1120.0  3240-131231-0065-0024           2   \n",
       "194998          0.57        6560.0  3440-171006-0020-0000           7   \n",
       "206558         10.13        1760.0  3440-171009-0070-0028           0   \n",
       "209417          8.65        6880.0    3807-4923-0009-0025          21   \n",
       "213880          8.35        6240.0    3807-4923-0040-0026           6   \n",
       "216975          9.66        3200.0    3807-4955-0002-0030           0   \n",
       "219823          1.61        4960.0    3807-4955-0020-0003          10   \n",
       "222669          6.06        7200.0    3807-4955-0038-0016           7   \n",
       "222672          6.06        7200.0    3807-4955-0038-0016          22   \n",
       "228370          1.85        7200.0  4195-186236-0001-0005          18   \n",
       "234828          1.26        1760.0  4195-186237-0023-0006           0   \n",
       "235992         10.42        7520.0  4195-186237-0030-0027          28   \n",
       "238732          9.04        4160.0  4195-186238-0017-0026          11   \n",
       "240265          3.47        4960.0   4397-15666-0001-0010          16   \n",
       "251966          7.26        7680.0   4397-15678-0013-0019          19   \n",
       "264094         11.35        2400.0   446-123502-0000-0031           0   \n",
       "270544          4.23        4000.0   446-123502-0046-0011           8   \n",
       "275088          2.45        3040.0  4788-294466-0029-0006           4   \n",
       "282021         12.52        4160.0   4788-94904-0004-0033           7   \n",
       "289220         11.48        6240.0   5163-18515-0011-0033          22   \n",
       "290102          6.00        6400.0   5163-18515-0018-0014           0   \n",
       "307573         14.80        2080.0   5339-14133-0039-0052           5   \n",
       "312485          6.82        2240.0   5339-14134-0018-0021           0   \n",
       "312905         11.06         960.0   5339-14134-0020-0033           2   \n",
       "334776          3.02        2720.0       78-368-0006-0009           0   \n",
       "341830          0.66        2080.0       78-369-0018-0000           6   \n",
       "342377         11.39        6240.0       78-369-0022-0031           0   \n",
       "343292          1.92        2720.0       78-369-0030-0006           0   \n",
       "349117          3.61        1120.0  8098-275181-0013-0010           0   \n",
       "349948          0.73        2080.0  8098-275181-0021-0001           3   \n",
       "365811          6.67        1280.0   887-123289-0032-0021           2   \n",
       "366475         13.26        7680.0   887-123289-0038-0038          28   \n",
       "366480         13.82        7520.0   887-123289-0038-0040           0   \n",
       "\n",
       "        endFrame  \n",
       "5331          10  \n",
       "6502           7  \n",
       "19009          3  \n",
       "22314         23  \n",
       "24176         15  \n",
       "26904          3  \n",
       "26910         33  \n",
       "44666         28  \n",
       "51976          3  \n",
       "56474          6  \n",
       "57607          3  \n",
       "61616          9  \n",
       "63966          8  \n",
       "69305          4  \n",
       "82105         12  \n",
       "86489         12  \n",
       "92032         13  \n",
       "93684          9  \n",
       "102889        16  \n",
       "120503         4  \n",
       "125414        20  \n",
       "146738         7  \n",
       "153279        25  \n",
       "162095         3  \n",
       "168418        20  \n",
       "178551         8  \n",
       "182196        11  \n",
       "183419         5  \n",
       "194998        12  \n",
       "206558         2  \n",
       "209417        26  \n",
       "213880         8  \n",
       "216975         8  \n",
       "219823        15  \n",
       "222669         9  \n",
       "222672        25  \n",
       "228370        23  \n",
       "234828         3  \n",
       "235992        31  \n",
       "238732        15  \n",
       "240265        19  \n",
       "251966        21  \n",
       "264094         4  \n",
       "270544        12  \n",
       "275088         8  \n",
       "282021        15  \n",
       "289220        25  \n",
       "290102         5  \n",
       "307573        10  \n",
       "312485         4  \n",
       "312905         4  \n",
       "334776         2  \n",
       "341830        10  \n",
       "342377         3  \n",
       "343292         4  \n",
       "349117         5  \n",
       "349948        10  \n",
       "365811         6  \n",
       "366475        31  \n",
       "366480         3  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_phone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "y = [1, 1, 1, 3, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [np.where(x == token)[0][0] for token in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 2, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1069/133699/0000/1069-133699-0000-0001.flac'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_dataset import Normalizer, DeNormalizer\n",
    "from model_dataset import MelSpecTransformDB as TheTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TheTransform(sample_rate=REC_SAMPLE_RATE, \n",
    "                       n_fft=N_FFT, n_mels=N_MELS, \n",
    "                       normalizer=Normalizer.norm_mvn, \n",
    "                       denormalizer=DeNormalizer.norm_mvn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.ceil(torch.tensor((guide_file[\"word_nSample\"] / 200).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.tensor((guide_file[\"word_nSample\"] // 200 + 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m data, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(file_name, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform:\n\u001b[0;32m---> 10\u001b[0m     tdata \u001b[38;5;241m=\u001b[39m transform(data)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m cwns[i]\u001b[38;5;241m.\u001b[39mitem(): \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], cwns[i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/wavln/script/model_dataset.py:419\u001b[0m, in \u001b[0;36mMelSpecTransformDB.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform): \n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# transform to mel_spectrogram\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(waveform)  \u001b[38;5;66;03m# (channel, n_mels, time)\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# mel_spec = F.amplitude_to_DB(mel_spec)\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamplitude_to_DB(mel_spec)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:619\u001b[0m, in \u001b[0;36mMelSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    612\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     specgram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspectrogram(waveform)\n\u001b[1;32m    620\u001b[0m     mel_specgram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmel_scale(specgram)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:110\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mspectrogram(\n\u001b[1;32m    111\u001b[0m         waveform,\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad,\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow,\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fft,\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhop_length,\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_length,\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpower,\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized,\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter,\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode,\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monesided,\n\u001b[1;32m    122\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/functional/functional.py:126\u001b[0m, in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[0m\n\u001b[1;32m    123\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m spec_f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstft(\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mwaveform,\n\u001b[1;32m    128\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[1;32m    129\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[1;32m    130\u001b[0m     win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[1;32m    131\u001b[0m     window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m    132\u001b[0m     center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[1;32m    133\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m    134\u001b[0m     normalized\u001b[38;5;241m=\u001b[39mframe_length_norm,\n\u001b[1;32m    135\u001b[0m     onesided\u001b[38;5;241m=\u001b[39monesided,\n\u001b[1;32m    136\u001b[0m     return_complex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# unpack batch\u001b[39;00m\n\u001b[1;32m    140\u001b[0m spec_f \u001b[38;5;241m=\u001b[39m spec_f\u001b[38;5;241m.\u001b[39mreshape(shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m spec_f\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/functional.py:650\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(extended_shape), [pad, pad], pad_mode)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39msignal_dim:])\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mstft(\u001b[38;5;28minput\u001b[39m, n_fft, hop_length, win_length, window,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    651\u001b[0m                 normalized, onesided, return_complex)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wpl = guide_file[\"word_path\"].tolist()\n",
    "for i in range(len(wpl)): \n",
    "    file_name = os.path.join(\n",
    "        train_cut_word_, \n",
    "        wpl[i]\n",
    "    )\n",
    "\n",
    "    data, sample_rate = torchaudio.load(file_name, normalize=True)\n",
    "    if transform:\n",
    "        tdata = transform(data)\n",
    "\n",
    "    if tdata.shape[0] != cwns[i].item(): \n",
    "        print(tdata.shape[0], cwns[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(\n",
    "    train_cut_word_, \n",
    "    guide_file[\"word_path\"][67]\n",
    ")\n",
    "\n",
    "data, sample_rate = torchaudio.load(file_name, normalize=True)\n",
    "if transform:\n",
    "    tdata = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2080]), torch.Size([11, 64]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.ceil(torch.tensor((guide_file[\"word_nSample\"] / 200).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([357399]), 357399)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwns.shape, len(guide_file[\"word_path\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth(length, boundaries, phonemes):\n",
    "    \"\"\"\n",
    "    Create a ground truth array for a single mel spectrogram given phoneme boundaries and identifiers,\n",
    "    ensuring the last phoneme extends to the real length of the spectrogram if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - length: The length of the mel spectrogram in frames (L).\n",
    "    - boundaries: A numpy array of ending frame indices for each phoneme (N, ).\n",
    "    - phonemes: A numpy array of phoneme identifiers corresponding to each boundary (N, ).\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of shape (L, ) where each item represents the phoneme identifier for each frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the ground truth array with zeros or a placeholder value\n",
    "    ground_truth = np.zeros(length, dtype=int)\n",
    "\n",
    "    # Start index for the first phoneme\n",
    "    start_idx = 0\n",
    "\n",
    "    # Process all but the last phoneme using the boundaries\n",
    "    for boundary, phoneme in zip(boundaries[:-1], phonemes[:-1]):\n",
    "        ground_truth[start_idx:boundary] = phoneme\n",
    "        start_idx = boundary\n",
    "\n",
    "    # Handle the last phoneme, ensuring it extends to the end of the mel spectrogram if necessary\n",
    "    ground_truth[start_idx:] = phonemes[-1]\n",
    "\n",
    "    return ground_truth.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaskedCrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')  # Use sum to manually control normalization\n",
    "\n",
    "    def get_loss(self, y_hat, y, mask):\n",
    "        # Ensure y_hat is of shape (B, C, L)\n",
    "        y_hat = y_hat.transpose(1, 2)  # Now y_hat is (B, C, L)\n",
    "        \n",
    "        # Mask should be applied to sequence lengths\n",
    "        # No need to expand mask as we are not selecting on the class dimension\n",
    "        \n",
    "        # Flatten outputs and targets to apply mask easily\n",
    "        B, C, L = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(B * L, C)\n",
    "        y_flat = y.reshape(-1)\n",
    "        mask_flat = mask.reshape(-1)\n",
    "        \n",
    "        # Filter out padded elements\n",
    "        y_hat_masked = y_hat_flat[mask_flat]\n",
    "        y_masked = y_flat[mask_flat]\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = self.loss_fn(y_hat_masked, y_masked)\n",
    "        \n",
    "        # Normalize the loss by the number of non-padded elements\n",
    "        loss = loss / mask_flat.sum()\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss: 1.469181776046753\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Loss is higher than expected, indicating padding might not be ignored correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is higher than expected, indicating padding might not be ignored correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Run the test case\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m test_masked_cross_entropy_loss()\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mtest_masked_cross_entropy_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Check if the loss is as expected (low, indicating padding was ignored)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is higher than expected, indicating padding might not be ignored correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Loss is higher than expected, indicating padding might not be ignored correctly."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def test_masked_cross_entropy_loss():\n",
    "    # Initialize the custom loss\n",
    "    masked_loss = MaskedCrossEntropyLoss()\n",
    "    \n",
    "    # Example parameters\n",
    "    batch_size = 2\n",
    "    seq_length = 3\n",
    "    num_classes = 4\n",
    "    \n",
    "    # Create synthetic predictions (y_hat)\n",
    "    # Let's assume all correct predictions for non-padded values are very confident\n",
    "    y_hat = torch.tensor([[[0.1, 0.2, 0.7, 0.0], [0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1]],  # 1st sample, with last one as padding\n",
    "                          [[0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.7]]]).float()  # 2nd sample, no padding\n",
    "    y_hat = y_hat.permute(0, 2, 1)  # Correct shape (B, C, L)\n",
    "    \n",
    "    # Create synthetic ground truth labels (y)\n",
    "    y = torch.tensor([[2, 1, 0],  # 0 is a dummy class for padding\n",
    "                      [1, 0, 3]])\n",
    "    \n",
    "    # Create mask (1 for valid, 0 for padding)\n",
    "    mask = torch.tensor([[1, 1, 0],  # Last element is padding\n",
    "                         [1, 1, 1]])  # No padding\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = masked_loss.get_loss(y_hat, y, mask)\n",
    "    \n",
    "    # Expected loss calculation\n",
    "    # Assuming cross-entropy loss for correctly classified with high confidence is close to 0\n",
    "    # The padded element should not contribute to the loss\n",
    "    # So, the expected loss should be very low as only non-padded elements are considered\n",
    "    print(f\"Computed loss: {loss.item()}\")\n",
    "    \n",
    "    # Check if the loss is as expected (low, indicating padding was ignored)\n",
    "    assert loss < 0.1, \"Loss is higher than expected, indicating padding might not be ignored correctly.\"\n",
    "\n",
    "# Run the test case\n",
    "test_masked_cross_entropy_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsfn = torch.nn.CrossEntropyLoss(reduction='none') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[[0.1, 0.2, 0.7, 0.0], [0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1]],  # 1st sample, with last one as padding\n",
    "                        [[0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.7]]]).float()  # 2nd sample, no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2, 3], [0, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lsfn(y_hat.permute(0, 2, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1, 1, 1], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4753, 1.5732, 1.5732],\n",
       "        [1.5732, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomness in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((10, )) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * x.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: [1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Enhanced tensor: [0. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def enhance_zeros(tensor, C):\n",
    "    \"\"\"\n",
    "    Enhances zeros in a tensor by changing the ones within C elements before and after zeros to zero.\n",
    "\n",
    "    Args:\n",
    "    - tensor (torch.Tensor): The input tensor with ones and zeros.\n",
    "    - C (int): The number of elements before and after zeros to be enhanced to zeros.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The enhanced tensor.\n",
    "    \"\"\"\n",
    "    # Ensure the tensor is 1D\n",
    "    if tensor.dim() != 1:\n",
    "        raise ValueError(\"Tensor must be 1D. Provided tensor is {}D\".format(tensor.dim()))\n",
    "    \n",
    "    # Create a convolution kernel\n",
    "    kernel_size = 2 * C + 1\n",
    "    kernel = torch.ones((1, 1, kernel_size), dtype=tensor.dtype, device=tensor.device)\n",
    "    \n",
    "    # Pad the tensor to handle boundary conditions\n",
    "    padded_tensor = F.pad(tensor.unsqueeze(0).unsqueeze(0), (C, C), mode='constant', value=1)\n",
    "    \n",
    "    # Convolve and threshold\n",
    "    conv_result = F.conv1d(padded_tensor, kernel)\n",
    "    enhanced_tensor = (conv_result == kernel_size).float().squeeze()\n",
    "    \n",
    "    # Invert to enhance zeros\n",
    "    enhanced_tensor = 1 - enhanced_tensor\n",
    "    \n",
    "    return enhanced_tensor\n",
    "\n",
    "# Example usage\n",
    "tensor = torch.tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.float32)\n",
    "C = 1  # Number of elements to change before and after zeros\n",
    "enhanced_tensor = enhance_zeros(tensor, C)\n",
    "\n",
    "print(\"Original tensor:\", tensor.numpy())\n",
    "print(\"Enhanced tensor:\", enhanced_tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20240217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the LSTM for each sequence at each timestep:\n",
      "tensor([[[-0.1249, -0.0517, -0.3828, -0.3499],\n",
      "         [-0.1708, -0.1220, -0.3867, -0.4097],\n",
      "         [-0.1557, -0.1547, -0.3054, -0.3126]],\n",
      "\n",
      "        [[-0.1249, -0.0517, -0.2234, -0.1138],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1249, -0.0517, -0.3500, -0.2470],\n",
      "         [-0.1708, -0.1220, -0.3123, -0.2289],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<IndexSelectBackward0>)\n",
      "Last hidden state for each sequence (forward and backward):\n",
      "tensor([[[-0.1557, -0.1547],\n",
      "         [-0.1249, -0.0517],\n",
      "         [-0.1708, -0.1220]],\n",
      "\n",
      "        [[-0.3828, -0.3499],\n",
      "         [-0.2234, -0.1138],\n",
      "         [-0.3500, -0.2470]]], grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample data: batch of 3 sequences with padding (0s are paddings)\n",
    "# Lengths need to be provided to pack_padded_sequence so it knows to skip the paddings\n",
    "data = torch.tensor([[1, 2, 3], [1, 0, 0], [1, 2, 0]]).float()\n",
    "lengths = torch.tensor([3, 1, 2])  # Actual lengths of sequences without padding\n",
    "\n",
    "# Define a bidirectional LSTM\n",
    "lstm = nn.LSTM(input_size=1, hidden_size=2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "# Process the data using the LSTM\n",
    "packed_input = pack_padded_sequence(data.unsqueeze(-1), lengths, batch_first=True, enforce_sorted=False)\n",
    "packed_output, (hidden, cell) = lstm(packed_input)\n",
    "output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "# The output tensor gives the output of the LSTM for each sequence at each timestep\n",
    "# Let's print the output for each sequence at each time step after unpacking\n",
    "print(\"Output of the LSTM for each sequence at each timestep:\")\n",
    "print(output)\n",
    "\n",
    "# Hidden state contains the last hidden state from the LSTM\n",
    "# For a bidirectional LSTM, it will return two vectors per layer per sequence\n",
    "# The first is from the forward pass and the second is from the backward pass\n",
    "print(\"Last hidden state for each sequence (forward and backward):\")\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.rand((2, 3, 4))\n",
    "logvar = torch.rand((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0737, 0.2247, 0.4689, 0.6838],\n",
       "          [0.5481, 0.5113, 0.4069, 0.1170],\n",
       "          [0.5956, 0.1688, 0.3862, 0.2856]],\n",
       " \n",
       "         [[0.9135, 0.9221, 0.6875, 0.4926],\n",
       "          [0.8215, 0.4295, 0.5575, 0.8243],\n",
       "          [0.8794, 0.0399, 0.9795, 0.6169]]]),\n",
       " tensor([[[0.2390, 0.4572, 0.0610, 0.9134],\n",
       "          [0.7273, 0.2384, 0.2816, 0.9394],\n",
       "          [0.7865, 0.0481, 0.3904, 0.9297]],\n",
       " \n",
       "         [[0.1654, 0.9366, 0.0739, 0.0950],\n",
       "          [0.4241, 0.6763, 0.5524, 0.5901],\n",
       "          [0.7201, 0.7235, 0.5182, 0.9740]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1366)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0364, 0.1729, 0.2217, 1.0470],\n",
       "         [0.6426, 0.2923, 0.2092, 0.6328],\n",
       "         [0.7640, 0.0297, 0.2364, 0.6855]],\n",
       "\n",
       "        [[0.8489, 1.4649, 0.4754, 0.2473],\n",
       "         [0.7790, 0.4748, 0.4958, 0.8936],\n",
       "         [1.1078, 0.3397, 1.1202, 1.0551]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.pow(2) + logvar.exp() - (1 + logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloss = -0.5 * torch.sum((1 + logvar - mu.pow(2) - logvar.exp()), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7390, 0.8884, 0.8578],\n",
       "        [1.5183, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfloss * torch.tensor([[1, 1, 1], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 1], [1, 1, 0], [1, 0, 0]]).bool()\n",
    "y = torch.tensor([[1, 0, 0], [1, 0, 0], [1, 0, 0]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7061, 0.2096, 0.4580],\n",
       "        [0.7048, 0.7277, 0.2524],\n",
       "        [0.2039, 0.6350, 0.1122]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7061, 0.2096, 0.4580, 0.7048, 0.7277, 0.2039]),\n",
       " tensor([1., 0., 0., 1., 0., 1.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = z.masked_select(x)\n",
    "b = y.masked_select(x)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5906)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.nn.MSELoss(reduction=\"none\")(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5906)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.nn.MSELoss(reduction=\"none\")(z, y) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((10, 3))\n",
    "ze = torch.rand((2, 5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, L, C = ze.shape\n",
    "K, _ = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_broadcast = embedding.reshape(1, 1, K, C)\n",
    "ze_broadcast = ze.reshape(B, L, 1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = torch.sum((embedding_broadcast - ze_broadcast)**2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = torch.argmin(distance, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, q_in, kv_in, qk_out, v_out):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.w_q = nn.Linear(q_in, qk_out)\n",
    "        self.w_k = nn.Linear(kv_in, qk_out)\n",
    "        self.w_v = nn.Linear(kv_in, v_out)\n",
    "        self.d_k = qk_out\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        q: Query tensor of shape (batch_size, num_queries, d_k)\n",
    "        k: Key tensor of shape (batch_size, num_keys, d_k)\n",
    "        v: Value tensor of shape (batch_size, num_values, d_v), num_keys = num_values\n",
    "        mask: Mask tensor of shape (batch_size, num_queries, num_keys)\n",
    "\n",
    "        Returns: Output tensor of shape (batch_size, num_queries, d_v)\n",
    "        \"\"\"\n",
    "        q = self.w_q(q)\n",
    "        k = self.w_k(k)\n",
    "        v = self.w_v(v)\n",
    "\n",
    "        # Step 1: Compute the dot product between queries and keys\n",
    "        attn_scores = torch.bmm(q, k.transpose(1, 2))  # (batch_size, num_queries, num_keys)\n",
    "\n",
    "        # Step 2: Scale the attention scores\n",
    "        attn_scores = attn_scores / (self.d_k ** 0.5)\n",
    "\n",
    "        # Step 3: Apply the mask (if any)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        # Step 4: Compute the softmax of the attention scores\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (batch_size, num_queries, num_keys)\n",
    "\n",
    "        # Step 5: Multiply the attention weights with the values\n",
    "        output = torch.bmm(attn_weights, v)  # (batch_size, num_queries, d_v)\n",
    "\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_padding import generate_mask_from_lengths_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3, 4, 5))\n",
    "b = torch.rand((3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = ScaledDotProductAttention(5, 5, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask = generate_mask_from_lengths_mat([2, 3, 4], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = attn(a, b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([3, 4, 4]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4752, -0.6958,  0.4442,  0.0080, -0.4331],\n",
       "         [-0.4717, -0.6864,  0.4356,  0.0099, -0.4285],\n",
       "         [-0.4733, -0.6913,  0.4403,  0.0092, -0.4320],\n",
       "         [-0.4741, -0.6913,  0.4402,  0.0093, -0.4315]],\n",
       "\n",
       "        [[-0.6807, -0.7565,  0.6334,  0.0301, -0.7380],\n",
       "         [-0.6827, -0.7599,  0.6362,  0.0303, -0.7418],\n",
       "         [-0.6793, -0.7551,  0.6322,  0.0298, -0.7364],\n",
       "         [-0.6759, -0.7555,  0.6323,  0.0285, -0.7371]],\n",
       "\n",
       "        [[-0.4857, -0.7882,  0.6660, -0.0513, -0.5572],\n",
       "         [-0.4922, -0.7798,  0.6610, -0.0470, -0.5570],\n",
       "         [-0.4834, -0.7906,  0.6673, -0.0526, -0.5570],\n",
       "         [-0.4850, -0.7890,  0.6665, -0.0517, -0.5572]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4774, 0.5495, 0.3095, 0.4692, 0.3498],\n",
       "         [0.4660, 0.5203, 0.3253, 0.4569, 0.3365],\n",
       "         [0.4549, 0.5480, 0.3197, 0.4356, 0.3377],\n",
       "         [0.4669, 0.5410, 0.3170, 0.4562, 0.3428]],\n",
       "\n",
       "        [[0.4735, 0.6425, 0.8228, 0.6482, 0.5196],\n",
       "         [0.4775, 0.6498, 0.8231, 0.6443, 0.5269],\n",
       "         [0.4730, 0.6402, 0.8223, 0.6422, 0.5118],\n",
       "         [0.4807, 0.6535, 0.8225, 0.6332, 0.5262]],\n",
       "\n",
       "        [[0.6013, 0.8321, 0.3478, 0.6847, 0.2792],\n",
       "         [0.5861, 0.8205, 0.3884, 0.6765, 0.2755],\n",
       "         [0.6131, 0.8372, 0.3385, 0.6878, 0.2838],\n",
       "         [0.6081, 0.8347, 0.3449, 0.6851, 0.2826]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.scaled_dot_product_attention(a, b, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
