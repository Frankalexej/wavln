{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from paths import *\n",
    "from misc_tools import AudioCut\n",
    "from misc_my_utils import time_to_frame\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_dataset import WordDatasetWordPath as ThisDataset\n",
    "from model_dataset import WordDictionary\n",
    "from C_0X_defs import *\n",
    "# from C_0D_run import load_data_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_guide_path = os.path.join(src_, \"guide_validation.csv\")\n",
    "word_rec_dir = train_cut_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_included_names(loader):\n",
    "    included_names = []\n",
    "    for (x, x_lens, word, name) in loader: \n",
    "        name = name[0]\n",
    "        included_names += [name]\n",
    "    return included_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_general(dataset, rec_dir, target_path, load=\"train\", select=0.3, sampled=True, batch_size=BATCH_SIZE):\n",
    "    # for general, path is easy, let's just load it\n",
    "    integrated = pd.read_csv(target_path)\n",
    "    integrated = integrated.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    mytrans = TheTransform(sample_rate=REC_SAMPLE_RATE, \n",
    "                        n_fft=N_FFT, n_mels=N_MELS, \n",
    "                        normalizer=Normalizer.norm_mvn, \n",
    "                        denormalizer=DeNormalizer.norm_mvn)\n",
    "    \n",
    "    mymap = WordDictionary(os.path.join(src_, \"unique_words_list.dict\"))\n",
    "\n",
    "    ds = dataset(rec_dir, \n",
    "                        integrated,  \n",
    "                        mapper=mymap, \n",
    "                        transform=mytrans)\n",
    "    \n",
    "    use_len = int(select * len(ds))\n",
    "    remain_len = len(ds) - use_len\n",
    "    use_ds, remain_ds = random_split(ds, [use_len, remain_len])\n",
    "\n",
    "    use_shuffle = True if load == \"train\" else False\n",
    "    loader = DataLoader(use_ds, batch_size=batch_size, shuffle=use_shuffle, num_workers=LOADER_WORKER, collate_fn=dataset.collate_fn)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_loader = load_data_general(ThisDataset, \n",
    "                                    word_rec_dir, valid_guide_path, load=\"valid\", select=0.3, sampled=False, \n",
    "                                    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_names = get_included_names(single_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7447-91187-0037-0041',\n",
       " '2989-138028-0026-0015',\n",
       " '8609-283227-0066-0038',\n",
       " '3830-12531-0023-0017',\n",
       " '8419-293469-0004-0039',\n",
       " '2182-181173-0029-0008',\n",
       " '5678-43303-0033-0016',\n",
       " '5867-48852-0076-0015',\n",
       " '1743-142913-0014-0035',\n",
       " '403-126855-0019-0009',\n",
       " '1116-132847-0013-0002',\n",
       " '8630-305212-0018-0002',\n",
       " '4481-17499-0042-0011',\n",
       " '1743-142913-0023-0008',\n",
       " '3259-158083-0098-0008',\n",
       " '2182-181183-0034-0006',\n",
       " '1743-142914-0013-0029',\n",
       " '229-130880-0066-0008',\n",
       " '8419-286667-0025-0048',\n",
       " '8630-305212-0020-0010',\n",
       " '3259-158083-0124-0014',\n",
       " '4481-17498-0042-0040',\n",
       " '103-1241-0001-0017',\n",
       " '2691-156750-0019-0010',\n",
       " '3830-12531-0001-0016',\n",
       " '1743-142912-0014-0009',\n",
       " '2691-156755-0012-0025',\n",
       " '1743-142913-0014-0041',\n",
       " '2007-132570-0006-0003',\n",
       " '5678-43303-0035-0006',\n",
       " '5678-43301-0003-0031',\n",
       " '2182-150130-0007-0024',\n",
       " '4297-13009-0006-0023',\n",
       " '1116-137572-0048-0025',\n",
       " '7447-91187-0050-0004',\n",
       " '8419-293469-0016-0031',\n",
       " '1116-137572-0037-0001',\n",
       " '3830-12530-0001-0001',\n",
       " '403-216-0026-0016',\n",
       " '1116-137572-0048-0032',\n",
       " '2007-149877-0059-0033',\n",
       " '8747-293952-0080-0035',\n",
       " '1116-137572-0049-0008',\n",
       " '441-128982-0033-0023',\n",
       " '412-126975-0060-0019',\n",
       " '8630-305213-0028-0022',\n",
       " '229-130880-0023-0002',\n",
       " '2182-181183-0001-0009',\n",
       " '412-126975-0051-0019',\n",
       " '5463-39173-0026-0031',\n",
       " '5463-39173-0016-0018',\n",
       " '2989-138028-0016-0023',\n",
       " '8324-286682-0009-0015',\n",
       " '5867-48852-0016-0028',\n",
       " '2182-181173-0002-0024',\n",
       " '4297-13009-0062-0002',\n",
       " '5463-39173-0039-0056',\n",
       " '1743-142914-0002-0039',\n",
       " '7447-91187-0055-0026',\n",
       " '4297-13006-0014-0016',\n",
       " '5867-48852-0046-0000',\n",
       " '8324-286683-0013-0017',\n",
       " '2007-132570-0055-0020',\n",
       " '8324-286683-0008-0030',\n",
       " '4481-17499-0037-0039',\n",
       " '8609-262281-0030-0006',\n",
       " '1743-142912-0020-0026',\n",
       " '2182-181173-0023-0017',\n",
       " '2691-156755-0022-0008',\n",
       " '2691-156755-0021-0000',\n",
       " '8747-293952-0092-0010',\n",
       " '8609-283227-0007-0050',\n",
       " '403-126855-0007-0008',\n",
       " '909-131044-0007-0020',\n",
       " '1116-137572-0002-0030',\n",
       " '7447-91187-0022-0011',\n",
       " '4481-17498-0019-0002',\n",
       " '8609-283227-0026-0013',\n",
       " '2989-138035-0052-0019',\n",
       " '1743-142914-0002-0045',\n",
       " '7447-91187-0061-0017',\n",
       " '2007-149877-0057-0000',\n",
       " '1743-142913-0023-0028',\n",
       " '8419-293469-0011-0032',\n",
       " '5678-43302-0009-0033',\n",
       " '103-1241-0002-0017',\n",
       " '1116-137572-0026-0034',\n",
       " '7447-91187-0037-0029',\n",
       " '403-128339-0037-0005',\n",
       " '2691-156755-0013-0032',\n",
       " '8747-293952-0062-0036',\n",
       " '229-130880-0086-0008',\n",
       " '2691-156745-0011-0002',\n",
       " '5678-43301-0020-0032',\n",
       " '8324-286683-0033-0030',\n",
       " '2691-156755-0013-0013',\n",
       " '1116-132847-0010-0022',\n",
       " '2182-181173-0004-0006',\n",
       " '103-1240-0033-0009',\n",
       " '5678-43302-0031-0010',\n",
       " '403-216-0008-0000',\n",
       " '3259-158083-0123-0046',\n",
       " '2989-138035-0052-0023',\n",
       " '2007-132570-0044-0002',\n",
       " '8747-293952-0077-0014',\n",
       " '3830-12535-0017-0004',\n",
       " '403-128339-0038-0030',\n",
       " '229-130880-0027-0012',\n",
       " '1116-132847-0019-0040',\n",
       " '3259-158083-0060-0035',\n",
       " '2182-150130-0034-0032',\n",
       " '2989-138035-0074-0031',\n",
       " '7447-91186-0009-0038',\n",
       " '5867-48852-0051-0026',\n",
       " '5463-39173-0035-0028',\n",
       " '3259-158083-0062-0013',\n",
       " '5867-48852-0013-0016',\n",
       " '8609-283227-0032-0042',\n",
       " '8747-293952-0007-0004',\n",
       " '2007-132570-0007-0005',\n",
       " '1743-142914-0009-0033',\n",
       " '8609-283227-0055-0017',\n",
       " '2989-138028-0052-0030',\n",
       " '7447-91186-0002-0033',\n",
       " '7447-91187-0041-0009',\n",
       " '5463-39173-0023-0043',\n",
       " '3830-12530-0038-0010',\n",
       " '8609-283227-0015-0009',\n",
       " '5463-39173-0000-0005',\n",
       " '4481-17499-0043-0016',\n",
       " '8419-286676-0002-0028',\n",
       " '1116-137572-0017-0022',\n",
       " '5463-39173-0044-0048',\n",
       " '2007-149877-0045-0011',\n",
       " '909-131044-0025-0007',\n",
       " '5867-48852-0062-0007',\n",
       " '8324-286681-0014-0017',\n",
       " '8324-286682-0025-0027',\n",
       " '3830-12529-0003-0003',\n",
       " '229-130880-0081-0011',\n",
       " '4297-13006-0006-0002',\n",
       " '8630-305213-0024-0026',\n",
       " '8324-286682-0046-0002',\n",
       " '3830-12530-0003-0037',\n",
       " '5678-43301-0020-0036',\n",
       " '441-128982-0019-0031',\n",
       " '2182-181183-0026-0029',\n",
       " '103-1240-0008-0004',\n",
       " '7447-91187-0034-0013',\n",
       " '4481-17498-0048-0013',\n",
       " '103-1240-0045-0012',\n",
       " '7447-91187-0060-0007',\n",
       " '7447-91187-0042-0020',\n",
       " '8324-286682-0048-0024',\n",
       " '8609-262281-0035-0002',\n",
       " '1743-142913-0006-0032',\n",
       " '8419-293469-0003-0042',\n",
       " '2989-138028-0028-0033',\n",
       " '5463-39173-0058-0036',\n",
       " '8419-286667-0014-0035',\n",
       " '1116-132847-0028-0040',\n",
       " '8419-286676-0018-0015',\n",
       " '2007-149877-0059-0023',\n",
       " '5867-48852-0036-0006',\n",
       " '3259-158083-0018-0001',\n",
       " '229-130880-0082-0012',\n",
       " '3259-158083-0047-0013',\n",
       " '103-1241-0009-0010',\n",
       " '5463-39174-0035-0062',\n",
       " '412-126975-0074-0004',\n",
       " '8609-283227-0055-0000',\n",
       " '1743-142912-0034-0013',\n",
       " '2691-156755-0024-0003',\n",
       " '1743-142912-0004-0017',\n",
       " '7447-91186-0029-0005',\n",
       " '3830-12530-0007-0016',\n",
       " '7447-91186-0041-0002',\n",
       " '2691-156755-0032-0009',\n",
       " '8747-293952-0052-0005',\n",
       " '8324-286683-0009-0026',\n",
       " '2989-138035-0052-0011',\n",
       " '2691-156755-0008-0023',\n",
       " '5678-43303-0013-0039',\n",
       " '5678-43303-0021-0003',\n",
       " '909-131045-0036-0022',\n",
       " '1116-137572-0055-0007',\n",
       " '5463-39174-0025-0038',\n",
       " '909-131041-0013-0043',\n",
       " '3830-12531-0000-0005',\n",
       " '1116-132847-0014-0002',\n",
       " '412-126975-0080-0007',\n",
       " '8419-286676-0033-0001',\n",
       " '103-1241-0004-0037',\n",
       " '441-128982-0022-0011',\n",
       " '3830-12530-0022-0004',\n",
       " '412-126975-0076-0000',\n",
       " '3830-12530-0034-0044',\n",
       " '2691-156755-0035-0025',\n",
       " '2989-138035-0058-0015',\n",
       " '7447-91186-0016-0013',\n",
       " '5867-48852-0053-0050',\n",
       " '103-1241-0010-0000',\n",
       " '5463-39174-0009-0026',\n",
       " '8747-293952-0084-0012',\n",
       " '2182-150130-0010-0032',\n",
       " '8630-305213-0006-0009',\n",
       " '2691-156755-0005-0013',\n",
       " '2989-138028-0008-0045',\n",
       " '441-130108-0005-0007',\n",
       " '1743-142912-0002-0014',\n",
       " '2989-138035-0059-0007',\n",
       " '403-128339-0020-0032',\n",
       " '5463-39174-0001-0007',\n",
       " '1116-137572-0049-0048',\n",
       " '8747-293952-0089-0031',\n",
       " '103-1241-0033-0046',\n",
       " '4481-17499-0024-0001',\n",
       " '2691-156745-0037-0029',\n",
       " '8324-286682-0020-0029',\n",
       " '229-130880-0052-0014',\n",
       " '8630-305213-0024-0024',\n",
       " '909-131044-0004-0007',\n",
       " '103-1241-0010-0042',\n",
       " '2989-138035-0056-0006',\n",
       " '909-131041-0013-0011',\n",
       " '441-128988-0003-0014',\n",
       " '8324-286683-0019-0025',\n",
       " '1743-142913-0010-0040',\n",
       " '4481-17498-0047-0047',\n",
       " '5867-48852-0052-0011',\n",
       " '8609-283227-0065-0001',\n",
       " '403-126855-0008-0015',\n",
       " '8324-286682-0001-0024',\n",
       " '441-128988-0033-0033',\n",
       " '103-1240-0003-0036',\n",
       " '8609-283227-0069-0011',\n",
       " '5463-39173-0059-0000',\n",
       " '5867-48852-0078-0002',\n",
       " '8609-262281-0004-0014',\n",
       " '1743-142913-0018-0028',\n",
       " '2989-138035-0036-0024',\n",
       " '412-126975-0046-0027',\n",
       " '1116-132851-0025-0007',\n",
       " '103-1240-0003-0031',\n",
       " '441-130108-0040-0022',\n",
       " '8747-293952-0025-0000',\n",
       " '2691-156755-0033-0005',\n",
       " '4297-13009-0002-0018',\n",
       " '441-128982-0027-0012',\n",
       " '1743-142913-0000-0037',\n",
       " '1116-137572-0028-0010',\n",
       " '2989-138028-0015-0010',\n",
       " '8324-286681-0001-0045',\n",
       " '403-128339-0015-0025',\n",
       " '403-128339-0004-0007',\n",
       " '8747-293952-0001-0035',\n",
       " '5867-48852-0097-0026',\n",
       " '403-126855-0010-0011',\n",
       " '229-130880-0059-0013',\n",
       " '2182-181183-0005-0044',\n",
       " '8324-286682-0031-0005',\n",
       " '403-128339-0028-0020',\n",
       " '5678-43302-0014-0034',\n",
       " '2691-156755-0012-0039',\n",
       " '1743-142914-0024-0030',\n",
       " '7447-91187-0005-0018',\n",
       " '441-130108-0037-0033',\n",
       " '8747-293952-0006-0011',\n",
       " '3259-158083-0064-0035',\n",
       " '2691-156755-0015-0004',\n",
       " '8324-286682-0009-0023',\n",
       " '8419-286676-0007-0048',\n",
       " '2989-138028-0007-0037',\n",
       " '8747-293952-0058-0047',\n",
       " '1743-142914-0001-0035',\n",
       " '5678-43301-0016-0021',\n",
       " '5867-48852-0074-0010',\n",
       " '5867-48852-0030-0000',\n",
       " '8609-283227-0028-0020',\n",
       " '441-128982-0014-0038',\n",
       " '8747-293952-0013-0017',\n",
       " '3830-12531-0022-0020',\n",
       " '3830-12531-0014-0006',\n",
       " '5678-43301-0018-0033',\n",
       " '103-1240-0013-0016',\n",
       " '229-130880-0066-0025',\n",
       " '103-1241-0027-0041',\n",
       " '8609-283227-0058-0003',\n",
       " '5463-39173-0061-0041',\n",
       " '2691-156750-0002-0013',\n",
       " '2182-150130-0021-0025',\n",
       " '8419-293469-0012-0003',\n",
       " '103-1241-0022-0003',\n",
       " '1116-137572-0018-0042',\n",
       " '412-126975-0094-0027',\n",
       " '8609-283227-0007-0013',\n",
       " '8324-286682-0038-0013',\n",
       " '412-126975-0066-0017',\n",
       " '412-126975-0080-0012',\n",
       " '3830-12530-0025-0013',\n",
       " '4297-13006-0001-0022',\n",
       " '8324-286682-0016-0024',\n",
       " '2007-132570-0047-0003',\n",
       " '3830-12531-0009-0053',\n",
       " '4297-13009-0034-0002',\n",
       " '229-130880-0077-0012',\n",
       " '3259-158083-0012-0015',\n",
       " '8324-286681-0011-0028',\n",
       " '909-131041-0010-0015',\n",
       " '3830-12531-0007-0042',\n",
       " '3830-12535-0011-0021',\n",
       " '441-128982-0030-0002',\n",
       " '412-126975-0058-0025',\n",
       " '2007-132570-0013-0016',\n",
       " '1743-142912-0032-0014',\n",
       " '412-126975-0085-0001',\n",
       " '8630-305213-0001-0020',\n",
       " '1116-137572-0007-0038',\n",
       " '8747-293952-0041-0034',\n",
       " '103-1240-0024-0033',\n",
       " '2691-156745-0002-0012',\n",
       " '8609-262281-0004-0010',\n",
       " '8609-283227-0015-0011',\n",
       " '8630-305213-0047-0020',\n",
       " '3830-12535-0024-0010',\n",
       " '909-131044-0023-0045',\n",
       " '7447-91187-0038-0009',\n",
       " '441-128988-0027-0034',\n",
       " '7447-91186-0009-0036',\n",
       " '7447-91186-0027-0023',\n",
       " '8609-283227-0015-0020',\n",
       " '3259-158083-0082-0028',\n",
       " '4297-13009-0022-0014',\n",
       " '4297-13009-0005-0039',\n",
       " '4481-17498-0010-0008',\n",
       " '5463-39174-0040-0010',\n",
       " '5867-48852-0104-0037',\n",
       " '8609-283227-0014-0012',\n",
       " '403-128339-0016-0014',\n",
       " '4481-17498-0035-0009',\n",
       " '5867-48852-0062-0035',\n",
       " '8609-262281-0033-0016',\n",
       " '1116-137572-0000-0035',\n",
       " '1743-142913-0030-0045',\n",
       " '4481-17499-0041-0000',\n",
       " '4297-13009-0030-0011',\n",
       " '4481-17498-0027-0010',\n",
       " '4481-17498-0022-0001',\n",
       " '2007-132570-0024-0031',\n",
       " '3830-12535-0028-0003',\n",
       " '1116-132851-0028-0039',\n",
       " '1743-142914-0020-0008',\n",
       " '2989-138035-0044-0024',\n",
       " '1743-142913-0008-0014',\n",
       " '909-131045-0018-0019',\n",
       " '5678-43302-0040-0024',\n",
       " '8609-283227-0064-0035',\n",
       " '1743-142913-0014-0001',\n",
       " '3259-158083-0008-0018',\n",
       " '5678-43302-0033-0026',\n",
       " '8419-286676-0004-0013',\n",
       " '8747-293952-0052-0018',\n",
       " '103-1241-0036-0065',\n",
       " '2182-150130-0021-0004',\n",
       " '909-131045-0033-0007',\n",
       " '2182-181183-0007-0026',\n",
       " '3259-158083-0108-0040',\n",
       " '8324-286683-0000-0033',\n",
       " '5678-43301-0017-0014',\n",
       " '403-216-0008-0011',\n",
       " '4297-13009-0000-0022',\n",
       " '2007-132570-0037-0048',\n",
       " '1116-132847-0014-0010',\n",
       " '2007-149877-0032-0022',\n",
       " '2182-150130-0018-0001',\n",
       " '2007-149877-0031-0005',\n",
       " '3830-12535-0021-0002',\n",
       " '2691-156755-0034-0027',\n",
       " '103-1240-0050-0020',\n",
       " '4297-13009-0061-0011',\n",
       " '7447-91186-0016-0007',\n",
       " '2182-150130-0033-0034',\n",
       " '3259-158083-0046-0004',\n",
       " '909-131041-0006-0011',\n",
       " '5463-39174-0047-0037',\n",
       " '909-131044-0006-0032',\n",
       " '4297-13009-0041-0022',\n",
       " '1743-142914-0024-0002',\n",
       " '2691-156755-0034-0032',\n",
       " '2182-181173-0012-0032',\n",
       " '2989-138028-0056-0030',\n",
       " '2007-132570-0053-0025',\n",
       " '909-131041-0031-0032',\n",
       " '3830-12531-0004-0045',\n",
       " '1116-137572-0051-0022',\n",
       " '412-126975-0068-0029',\n",
       " '7447-91186-0019-0002',\n",
       " '5867-48852-0096-0019',\n",
       " '7447-91186-0000-0023',\n",
       " '3259-158083-0111-0013',\n",
       " '4481-17498-0038-0048',\n",
       " '8419-293469-0000-0020',\n",
       " '8419-293473-0002-0029',\n",
       " '2182-181173-0018-0000',\n",
       " '1743-142913-0004-0006',\n",
       " '8609-283227-0028-0029',\n",
       " '3830-12530-0032-0025',\n",
       " '3830-12531-0024-0025',\n",
       " '8630-305212-0041-0028',\n",
       " '2182-181183-0014-0008',\n",
       " '103-1240-0010-0003',\n",
       " '1116-132847-0014-0004',\n",
       " '4297-13009-0033-0003',\n",
       " '2989-138035-0000-0009',\n",
       " '8324-286681-0023-0009',\n",
       " '909-131044-0029-0002',\n",
       " '2691-156755-0028-0028',\n",
       " '8609-283227-0064-0009',\n",
       " '5867-48852-0014-0000',\n",
       " '8747-293952-0042-0002',\n",
       " '4481-17498-0018-0028',\n",
       " '2182-150130-0026-0017',\n",
       " '5678-43302-0017-0011',\n",
       " '2182-181183-0033-0021',\n",
       " '909-131044-0016-0009',\n",
       " '412-126975-0086-0017',\n",
       " '909-131044-0005-0015',\n",
       " '1116-137572-0046-0028',\n",
       " '8630-305213-0017-0034',\n",
       " '2691-156750-0033-0002',\n",
       " '8609-262281-0038-0015',\n",
       " '1116-132847-0040-0042',\n",
       " '8630-305212-0023-0016',\n",
       " '103-1240-0007-0024',\n",
       " '4297-13006-0030-0006',\n",
       " '2691-156750-0026-0002',\n",
       " '1116-137572-0019-0023',\n",
       " '4297-13006-0035-0007',\n",
       " '8419-286667-0028-0025',\n",
       " '2007-132570-0050-0037',\n",
       " '5867-48852-0023-0007',\n",
       " '441-128988-0032-0008',\n",
       " '5463-39174-0041-0030',\n",
       " '8609-283227-0021-0000',\n",
       " '5678-43303-0020-0014',\n",
       " '4481-17499-0005-0009',\n",
       " '1743-142912-0000-0011',\n",
       " '3830-12535-0020-0009',\n",
       " '1743-142913-0011-0011',\n",
       " '412-126975-0056-0006',\n",
       " '229-130880-0084-0032',\n",
       " '4297-13006-0003-0021',\n",
       " '8419-293469-0003-0018',\n",
       " '8324-286683-0009-0027',\n",
       " '2691-156755-0027-0020',\n",
       " '103-1240-0045-0021',\n",
       " '103-1240-0002-0015',\n",
       " '5867-48852-0038-0044',\n",
       " '3259-158083-0096-0024',\n",
       " '1743-142912-0019-0000',\n",
       " '5867-48852-0060-0033',\n",
       " '909-131045-0030-0031',\n",
       " '4297-13006-0030-0026',\n",
       " '5678-43301-0025-0047',\n",
       " '441-128988-0022-0035',\n",
       " '5678-43302-0039-0021',\n",
       " '8747-293952-0017-0021',\n",
       " '1743-142914-0026-0015',\n",
       " '4297-13009-0010-0014',\n",
       " '5867-48852-0043-0027',\n",
       " '403-128339-0020-0010',\n",
       " '1116-132847-0030-0003',\n",
       " '5678-43303-0035-0035',\n",
       " '4297-13006-0015-0033',\n",
       " '909-131044-0025-0001',\n",
       " '1743-142914-0029-0002',\n",
       " '5867-48852-0035-0019',\n",
       " '8609-283227-0033-0059',\n",
       " '4297-13009-0010-0001',\n",
       " '7447-91186-0004-0018',\n",
       " '2691-156750-0004-0003',\n",
       " '8609-283227-0053-0035',\n",
       " '2182-181183-0004-0028',\n",
       " '412-126975-0043-0001',\n",
       " '412-126975-0012-0022',\n",
       " '103-1241-0029-0039',\n",
       " '3830-12531-0016-0024',\n",
       " '4481-17498-0042-0017',\n",
       " '8419-286676-0011-0046',\n",
       " '8609-283227-0014-0046',\n",
       " '5867-48852-0079-0024',\n",
       " '5678-43303-0038-0012',\n",
       " '1116-137572-0049-0039',\n",
       " '8609-283227-0021-0014',\n",
       " '8630-305212-0043-0027',\n",
       " '5463-39173-0045-0014',\n",
       " '909-131045-0011-0033',\n",
       " '5678-43302-0038-0037',\n",
       " '5463-39173-0013-0003',\n",
       " '4297-13009-0003-0031',\n",
       " '1116-132847-0027-0027',\n",
       " '3259-158083-0084-0006',\n",
       " '4481-17499-0002-0007',\n",
       " '8324-286682-0012-0019',\n",
       " '8609-262281-0026-0010',\n",
       " '8324-286682-0016-0018',\n",
       " '412-126975-0042-0010',\n",
       " '7447-91187-0025-0018',\n",
       " '4297-13009-0018-0006',\n",
       " '3830-12535-0022-0020',\n",
       " '1116-137572-0049-0045',\n",
       " '2691-156750-0011-0042',\n",
       " '441-130108-0012-0016',\n",
       " '7447-91186-0001-0007',\n",
       " '2691-156745-0027-0004',\n",
       " '441-130108-0007-0023',\n",
       " '3830-12535-0028-0009',\n",
       " '5678-43301-0002-0014',\n",
       " '2007-132570-0029-0045',\n",
       " '7447-91186-0000-0026',\n",
       " '8609-262281-0027-0006',\n",
       " '7447-91187-0036-0030',\n",
       " '2182-181183-0002-0040',\n",
       " '8609-283227-0037-0024',\n",
       " '8630-305212-0033-0025',\n",
       " '8419-286667-0013-0029',\n",
       " '8609-283227-0060-0008',\n",
       " '8630-305213-0002-0009',\n",
       " '2182-150130-0032-0011',\n",
       " '412-126975-0084-0010',\n",
       " '8630-305212-0006-0030',\n",
       " '8747-293952-0069-0003',\n",
       " '4481-17498-0009-0028',\n",
       " '4481-17499-0001-0040',\n",
       " '8324-286683-0011-0013',\n",
       " '8630-305212-0032-0010',\n",
       " '7447-91187-0024-0002',\n",
       " '5463-39173-0047-0051',\n",
       " '441-128982-0016-0010',\n",
       " '2691-156755-0001-0001',\n",
       " '3830-12530-0027-0033',\n",
       " '8747-293952-0050-0040',\n",
       " '8747-293952-0017-0005',\n",
       " '909-131041-0003-0024',\n",
       " '2182-181173-0023-0007',\n",
       " '7447-91187-0058-0007',\n",
       " '8747-293952-0027-0000',\n",
       " '7447-91187-0052-0036',\n",
       " '2989-138035-0020-0040',\n",
       " '2691-156755-0017-0035',\n",
       " '2182-181183-0030-0016',\n",
       " '403-128339-0040-0012',\n",
       " '3259-158083-0083-0046',\n",
       " '8324-286681-0015-0038',\n",
       " '3830-12535-0006-0008',\n",
       " '5867-48852-0081-0015',\n",
       " '229-130880-0068-0025',\n",
       " '412-126975-0069-0011',\n",
       " '5463-39174-0041-0005',\n",
       " '909-131041-0010-0028',\n",
       " '909-131045-0029-0032',\n",
       " '5678-43301-0027-0026',\n",
       " '8609-283227-0060-0047',\n",
       " '2691-156750-0033-0025',\n",
       " '1743-142912-0007-0026',\n",
       " '8609-283227-0035-0009',\n",
       " '5867-48852-0068-0027',\n",
       " '8324-286681-0017-0028',\n",
       " '103-1240-0037-0001',\n",
       " '412-126975-0085-0017',\n",
       " '2691-156745-0044-0017',\n",
       " '2182-181183-0001-0024',\n",
       " '1116-132847-0008-0044',\n",
       " '8630-305213-0020-0017',\n",
       " '8747-293952-0104-0019',\n",
       " '4297-13006-0011-0031',\n",
       " '403-216-0002-0004',\n",
       " '5678-43302-0016-0002',\n",
       " '8324-286681-0022-0001',\n",
       " '2182-150130-0028-0038',\n",
       " '8609-283227-0064-0004',\n",
       " '412-126975-0011-0007',\n",
       " '4297-13009-0064-0016',\n",
       " '2691-156755-0030-0036',\n",
       " '4297-13009-0013-0031',\n",
       " '2182-181173-0010-0009',\n",
       " '1743-142912-0006-0016',\n",
       " '5678-43301-0019-0003',\n",
       " '4297-13006-0027-0011',\n",
       " '4481-17499-0011-0022',\n",
       " '8419-293469-0024-0024',\n",
       " '2007-149877-0046-0029',\n",
       " '8324-286682-0033-0032',\n",
       " '2007-132570-0001-0021',\n",
       " '2182-181173-0003-0017',\n",
       " '5463-39174-0023-0037',\n",
       " '8609-283227-0010-0023',\n",
       " '5463-39173-0062-0046',\n",
       " '441-128988-0029-0018',\n",
       " '2691-156755-0020-0011',\n",
       " '229-130880-0077-0005',\n",
       " '3830-12531-0016-0019',\n",
       " '8630-305213-0020-0025',\n",
       " '3830-12535-0026-0037',\n",
       " '1116-132847-0025-0007',\n",
       " '3830-12529-0004-0039',\n",
       " '229-130880-0029-0006',\n",
       " '4481-17498-0020-0041',\n",
       " '2182-150130-0033-0000',\n",
       " '103-1241-0034-0017',\n",
       " '1116-132851-0024-0043',\n",
       " '2691-156755-0005-0004',\n",
       " '5678-43302-0005-0024',\n",
       " '5463-39173-0026-0015',\n",
       " '5463-39174-0038-0026',\n",
       " '2007-149877-0056-0021',\n",
       " '2182-181173-0024-0001',\n",
       " '8630-305213-0037-0030',\n",
       " '441-128988-0020-0000',\n",
       " '229-130880-0069-0006',\n",
       " '8419-286676-0000-0017',\n",
       " '1116-137572-0032-0033',\n",
       " '441-128982-0010-0020',\n",
       " '2182-150130-0034-0027',\n",
       " '8419-286667-0027-0005',\n",
       " '5463-39174-0006-0003',\n",
       " '8324-286682-0012-0004',\n",
       " '3259-158083-0088-0008',\n",
       " '3259-158083-0033-0004',\n",
       " '909-131045-0024-0041',\n",
       " '103-1241-0014-0021',\n",
       " '5678-43302-0010-0003',\n",
       " '8419-293473-0003-0016',\n",
       " '7447-91187-0015-0014',\n",
       " '441-128988-0032-0012',\n",
       " '4297-13009-0022-0037',\n",
       " '2007-132570-0015-0008',\n",
       " '441-128988-0032-0014',\n",
       " '8609-262281-0026-0012',\n",
       " '441-128988-0020-0015',\n",
       " '5463-39173-0001-0024',\n",
       " '1116-137572-0010-0023',\n",
       " '1743-142913-0018-0010',\n",
       " '412-126975-0007-0017',\n",
       " '4297-13006-0005-0026',\n",
       " '4297-13009-0061-0028',\n",
       " '2989-138028-0008-0022',\n",
       " '1116-137572-0028-0036',\n",
       " '5463-39174-0026-0028',\n",
       " '1743-142914-0029-0014',\n",
       " '5867-48852-0002-0000',\n",
       " '229-130880-0000-0030',\n",
       " '2007-149877-0032-0009',\n",
       " '103-1241-0042-0031',\n",
       " '3830-12531-0021-0005',\n",
       " '2691-156755-0014-0006',\n",
       " '8609-262281-0031-0043',\n",
       " '4481-17499-0011-0043',\n",
       " '5678-43303-0023-0037',\n",
       " '103-1241-0001-0027',\n",
       " '229-130880-0027-0028',\n",
       " '909-131041-0026-0006',\n",
       " '1743-142912-0015-0003',\n",
       " '8630-305212-0001-0026',\n",
       " '5463-39173-0037-0034',\n",
       " '229-130880-0068-0013',\n",
       " '103-1241-0026-0025',\n",
       " '103-1240-0028-0024',\n",
       " '8630-305212-0035-0013',\n",
       " '3259-158083-0068-0050',\n",
       " '909-131044-0028-0015',\n",
       " '4481-17498-0042-0006',\n",
       " '4297-13009-0007-0021',\n",
       " '103-1240-0046-0012',\n",
       " '3830-12535-0029-0028',\n",
       " '8630-305213-0045-0001',\n",
       " '3259-158083-0119-0016',\n",
       " '7447-91186-0033-0005',\n",
       " '8630-305212-0039-0020',\n",
       " '4297-13009-0032-0008',\n",
       " '8324-286682-0000-0020',\n",
       " '2007-132570-0020-0017',\n",
       " '1116-132847-0005-0046',\n",
       " '5678-43303-0029-0040',\n",
       " '1743-142912-0025-0037',\n",
       " '441-128982-0008-0009',\n",
       " '4297-13006-0005-0022',\n",
       " '8419-293473-0016-0042',\n",
       " '441-128982-0030-0012',\n",
       " '5867-48852-0038-0016',\n",
       " '2989-138035-0062-0021',\n",
       " '441-128982-0010-0014',\n",
       " '412-126975-0082-0030',\n",
       " '412-126975-0011-0033',\n",
       " '5678-43302-0026-0030',\n",
       " '4481-17499-0031-0010',\n",
       " '2989-138028-0020-0014',\n",
       " '909-131045-0003-0006',\n",
       " '229-130880-0026-0001',\n",
       " '2989-138028-0066-0003',\n",
       " '8419-286676-0017-0039',\n",
       " '909-131045-0039-0027',\n",
       " '8324-286682-0007-0017',\n",
       " '5867-48852-0037-0039',\n",
       " '8419-286676-0017-0027',\n",
       " '5463-39173-0035-0032',\n",
       " '229-130880-0002-0000',\n",
       " '2007-149877-0029-0037',\n",
       " '5678-43301-0025-0036',\n",
       " '5678-43302-0013-0025',\n",
       " '1743-142913-0001-0000',\n",
       " '2182-181183-0015-0008',\n",
       " '8609-283227-0030-0000',\n",
       " '2182-181173-0007-0018',\n",
       " '5867-48852-0109-0004',\n",
       " '8747-293952-0022-0007',\n",
       " '8747-293952-0089-0009',\n",
       " '5463-39173-0052-0049',\n",
       " '3259-158083-0067-0013',\n",
       " '3259-158083-0094-0029',\n",
       " '412-126975-0080-0002',\n",
       " '3259-158083-0125-0022',\n",
       " '441-128982-0006-0034',\n",
       " '8630-305213-0018-0030',\n",
       " '4297-13009-0018-0020',\n",
       " '1743-142912-0029-0027',\n",
       " '2989-138035-0052-0027',\n",
       " '2182-181173-0021-0017',\n",
       " '2007-132570-0034-0022',\n",
       " '5867-48852-0064-0015',\n",
       " '5463-39174-0049-0010',\n",
       " '103-1240-0008-0023',\n",
       " '103-1241-0039-0058',\n",
       " '1116-137572-0009-0016',\n",
       " '103-1241-0012-0017',\n",
       " '4481-17498-0046-0004',\n",
       " '5867-48852-0029-0007',\n",
       " '2989-138035-0004-0014',\n",
       " '2007-132570-0051-0027',\n",
       " '4297-13009-0028-0001',\n",
       " '4481-17499-0023-0021',\n",
       " '8609-262281-0002-0000',\n",
       " '2182-181173-0023-0018',\n",
       " '1743-142914-0022-0003',\n",
       " '441-128982-0008-0002',\n",
       " '8609-262281-0029-0002',\n",
       " '3830-12530-0003-0009',\n",
       " '2007-149877-0002-0006',\n",
       " '1743-142912-0012-0000',\n",
       " '229-130880-0084-0021',\n",
       " '5463-39173-0062-0033',\n",
       " '5678-43303-0022-0019',\n",
       " '3259-158083-0101-0041',\n",
       " '2989-138028-0012-0004',\n",
       " '3830-12531-0017-0020',\n",
       " '3259-158083-0054-0024',\n",
       " '7447-91187-0010-0001',\n",
       " '8630-305213-0003-0010',\n",
       " '3259-158083-0120-0015',\n",
       " '103-1241-0036-0036',\n",
       " '5678-43303-0028-0042',\n",
       " '7447-91187-0000-0001',\n",
       " '8324-286682-0017-0014',\n",
       " '1743-142912-0026-0030',\n",
       " '229-130880-0003-0002',\n",
       " '909-131045-0035-0032',\n",
       " '8747-293952-0098-0019',\n",
       " '5867-48852-0008-0004',\n",
       " '5463-39174-0007-0019',\n",
       " '2182-181183-0029-0011',\n",
       " '5867-48852-0067-0023',\n",
       " '2007-132570-0006-0013',\n",
       " '229-130880-0076-0015',\n",
       " '2691-156755-0035-0012',\n",
       " '7447-91186-0022-0016',\n",
       " '1743-142912-0027-0019',\n",
       " '8324-286682-0024-0005',\n",
       " '2989-138035-0004-0000',\n",
       " '8609-283227-0037-0004',\n",
       " '412-126975-0051-0002',\n",
       " '2691-156750-0022-0014',\n",
       " '909-131045-0018-0043',\n",
       " '8419-293473-0015-0013',\n",
       " '2989-138035-0075-0013',\n",
       " '3830-12530-0004-0013',\n",
       " '2989-138028-0050-0004',\n",
       " '5463-39174-0025-0001',\n",
       " '3830-12531-0010-0019',\n",
       " '5867-48852-0107-0025',\n",
       " '7447-91187-0012-0008',\n",
       " '2989-138035-0008-0007',\n",
       " '7447-91187-0045-0003',\n",
       " '5678-43302-0011-0026',\n",
       " '2007-132570-0015-0016',\n",
       " '403-126855-0001-0004',\n",
       " '5463-39173-0053-0021',\n",
       " '1116-132851-0017-0012',\n",
       " '441-128982-0018-0042',\n",
       " '3830-12530-0044-0018',\n",
       " '103-1241-0008-0045',\n",
       " '5867-48852-0074-0016',\n",
       " '2007-149877-0055-0013',\n",
       " '403-128339-0027-0014',\n",
       " '7447-91187-0011-0022',\n",
       " '8609-283227-0014-0006',\n",
       " '1116-137572-0013-0024',\n",
       " '4297-13009-0016-0039',\n",
       " '2007-132570-0033-0029',\n",
       " '8747-293952-0026-0023',\n",
       " '8609-283227-0013-0024',\n",
       " '4297-13009-0021-0043',\n",
       " '5463-39174-0028-0010',\n",
       " '2007-149877-0020-0030',\n",
       " '2691-156750-0002-0020',\n",
       " '8609-283227-0068-0001',\n",
       " '3830-12531-0000-0030',\n",
       " '403-126855-0002-0017',\n",
       " '909-131045-0009-0023',\n",
       " '103-1241-0024-0045',\n",
       " '3830-12530-0042-0027',\n",
       " '8324-286683-0007-0003',\n",
       " '103-1240-0054-0013',\n",
       " '2989-138035-0065-0010',\n",
       " '1116-137572-0003-0010',\n",
       " '8419-286667-0005-0023',\n",
       " '1116-132847-0005-0029',\n",
       " '909-131045-0028-0009',\n",
       " '2182-181183-0034-0038',\n",
       " '5463-39173-0016-0040',\n",
       " '5678-43302-0016-0025',\n",
       " '2007-149877-0058-0002',\n",
       " '2691-156755-0000-0022',\n",
       " '8609-262281-0035-0028',\n",
       " '8419-293473-0014-0043',\n",
       " '229-130880-0060-0022',\n",
       " '229-130880-0045-0015',\n",
       " '103-1241-0016-0029',\n",
       " '5678-43301-0025-0042',\n",
       " '5867-48852-0039-0007',\n",
       " '403-128339-0028-0018',\n",
       " '4297-13009-0032-0041',\n",
       " '412-126975-0034-0023',\n",
       " '2182-181173-0024-0026',\n",
       " '5463-39173-0058-0047',\n",
       " '403-128339-0018-0030',\n",
       " '3830-12535-0024-0022',\n",
       " '229-130880-0062-0008',\n",
       " '2989-138028-0003-0031',\n",
       " '3259-158083-0064-0036',\n",
       " '5678-43302-0011-0013',\n",
       " '441-128988-0028-0013',\n",
       " '8747-293952-0007-0023',\n",
       " '103-1240-0025-0018',\n",
       " '5867-48852-0058-0044',\n",
       " '229-130880-0020-0024',\n",
       " '5678-43303-0019-0013',\n",
       " '8609-262281-0007-0011',\n",
       " '5678-43301-0020-0035',\n",
       " '7447-91187-0049-0025',\n",
       " '8630-305213-0028-0033',\n",
       " '5678-43303-0010-0016',\n",
       " '3259-158083-0002-0008',\n",
       " '2182-181173-0023-0020',\n",
       " '2691-156755-0027-0032',\n",
       " '2007-149877-0052-0020',\n",
       " '441-130108-0041-0004',\n",
       " '1743-142914-0000-0013',\n",
       " '909-131044-0003-0039',\n",
       " '2007-149877-0043-0032',\n",
       " '403-126855-0006-0037',\n",
       " '4481-17498-0000-0017',\n",
       " '2691-156755-0034-0003',\n",
       " '3259-158083-0079-0008',\n",
       " '441-128988-0013-0024',\n",
       " '8324-286682-0023-0018',\n",
       " '1743-142913-0025-0027',\n",
       " '412-126975-0030-0022',\n",
       " '8609-283227-0019-0003',\n",
       " '403-216-0007-0021',\n",
       " '8747-293952-0004-0022',\n",
       " '3259-158083-0016-0041',\n",
       " '2691-156755-0028-0024',\n",
       " '1743-142912-0031-0030',\n",
       " '909-131044-0009-0017',\n",
       " '1743-142912-0008-0041',\n",
       " '8419-293473-0009-0052',\n",
       " '5678-43303-0036-0018',\n",
       " '2182-150130-0016-0003',\n",
       " '8609-283227-0044-0011',\n",
       " '1116-137572-0014-0021',\n",
       " '2989-138028-0019-0000',\n",
       " '2007-149877-0024-0016',\n",
       " '5867-48852-0012-0040',\n",
       " '4297-13009-0052-0016',\n",
       " '8747-293952-0074-0003',\n",
       " '8324-286682-0016-0035',\n",
       " '909-131045-0005-0039',\n",
       " '1743-142913-0020-0015',\n",
       " '5463-39174-0031-0020',\n",
       " '2691-156750-0010-0006',\n",
       " '441-128982-0034-0046',\n",
       " '2007-149877-0025-0003',\n",
       " '3830-12530-0041-0003',\n",
       " '403-126855-0022-0017',\n",
       " '909-131044-0006-0002',\n",
       " '8419-286676-0013-0035',\n",
       " '1116-132847-0002-0011',\n",
       " '2989-138028-0035-0005',\n",
       " '909-131045-0031-0021',\n",
       " '2989-138035-0023-0008',\n",
       " '403-128339-0037-0025',\n",
       " '2691-156755-0007-0015',\n",
       " '3830-12531-0024-0014',\n",
       " '8609-262281-0040-0027',\n",
       " '103-1240-0031-0020',\n",
       " '2989-138035-0041-0009',\n",
       " '1116-137572-0047-0007',\n",
       " '2007-132570-0014-0030',\n",
       " '8747-293952-0046-0015',\n",
       " '4481-17498-0009-0019',\n",
       " '7447-91186-0000-0006',\n",
       " '403-126855-0012-0008',\n",
       " '8630-305213-0050-0020',\n",
       " '1116-137572-0002-0000',\n",
       " '4297-13009-0020-0030',\n",
       " '2007-132570-0045-0014',\n",
       " '4297-13006-0017-0002',\n",
       " '2182-181183-0032-0000',\n",
       " '7447-91186-0038-0026',\n",
       " '8609-262281-0011-0010',\n",
       " '7447-91186-0042-0025',\n",
       " '909-131045-0021-0006',\n",
       " '1116-137572-0003-0004',\n",
       " '403-128339-0008-0016',\n",
       " '2691-156755-0032-0016',\n",
       " '8747-293952-0082-0023',\n",
       " '3830-12530-0012-0030',\n",
       " '4481-17498-0037-0002',\n",
       " '8324-286683-0006-0007',\n",
       " '5867-48852-0088-0017',\n",
       " '5463-39173-0048-0005',\n",
       " '103-1241-0000-0022',\n",
       " '8324-286683-0031-0010',\n",
       " '8419-286667-0027-0020',\n",
       " '4297-13009-0000-0014',\n",
       " '103-1241-0038-0044',\n",
       " '8747-293952-0006-0027',\n",
       " '2989-138028-0058-0041',\n",
       " '4297-13009-0024-0010',\n",
       " '1116-132847-0036-0012',\n",
       " '2007-132570-0012-0006',\n",
       " '8419-286667-0016-0034',\n",
       " '3259-158083-0053-0031',\n",
       " '5463-39173-0050-0019',\n",
       " '229-130880-0047-0001',\n",
       " '229-130880-0025-0029',\n",
       " '8419-293473-0005-0004',\n",
       " '1116-137572-0025-0007',\n",
       " '1743-142912-0006-0023',\n",
       " '2007-132570-0060-0009',\n",
       " '2182-181183-0034-0023',\n",
       " '3830-12531-0026-0024',\n",
       " '2989-138028-0010-0021',\n",
       " '2007-132570-0024-0024',\n",
       " '103-1240-0002-0037',\n",
       " '403-216-0008-0015',\n",
       " '441-128982-0035-0022',\n",
       " '5678-43301-0026-0019',\n",
       " '2691-156755-0030-0028',\n",
       " '4481-17499-0045-0015',\n",
       " '1116-132847-0015-0005',\n",
       " '3830-12531-0019-0045',\n",
       " '8747-293952-0008-0009',\n",
       " '3259-158083-0115-0029',\n",
       " '4297-13009-0060-0014',\n",
       " '8609-262281-0030-0018',\n",
       " '2691-156755-0012-0011',\n",
       " '5463-39174-0011-0028',\n",
       " '229-130880-0010-0030',\n",
       " '909-131044-0030-0015',\n",
       " '403-128339-0030-0025',\n",
       " '1116-137572-0008-0009',\n",
       " '1116-132851-0011-0019',\n",
       " '3259-158083-0071-0032',\n",
       " '8419-293473-0001-0029',\n",
       " '412-126975-0037-0030',\n",
       " '5463-39173-0039-0038',\n",
       " '8609-283227-0004-0046',\n",
       " '229-130880-0027-0031',\n",
       " '412-126975-0051-0014',\n",
       " '8419-293469-0008-0002',\n",
       " '8747-293952-0102-0004',\n",
       " '403-128339-0025-0005',\n",
       " '5463-39173-0001-0010',\n",
       " '5867-48852-0038-0042',\n",
       " '8419-286667-0029-0018',\n",
       " '2989-138035-0013-0023',\n",
       " '3259-158083-0016-0022',\n",
       " '5463-39174-0027-0014',\n",
       " '2182-150130-0016-0043',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in guide file\n",
    "guide_file = pd.read_csv(valid_guide_path)\n",
    "# filtering out is not necessary, since we only include wuid for encoded words\n",
    "guide_file = guide_file[~guide_file[\"segment_nostress\"].isin([\"sil\", \"sp\", \"spn\"])]\n",
    "filtered_df = guide_file[guide_file['wuid'].isin(included_names)].copy()\n",
    "\n",
    "filtered_df[\"startFrame\"] = filtered_df.apply(lambda x: time_to_frame(x['startTime'] - x['word_startTime']), axis=1)\n",
    "filtered_df[\"endFrame\"] = filtered_df.apply(lambda x: time_to_frame(x['endTime'] - x['word_startTime']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_file = pd.read_csv(os.path.join(src_, \"guide_train.csv\"))\n",
    "guide_file = guide_file[~guide_file[\"segment_nostress\"].isin([\"sil\", \"sp\", \"spn\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deshort = guide_file[guide_file['word_nSample'] > 400]\n",
    "delong = guide_file[guide_file['word_nSample'] <= 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deshort) / len(guide_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922523566098395"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(delong) / len(guide_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['segment', 'file', 'id', 'startTime', 'endTime', 'nSample', 'word_id',\n",
       "       'word', 'in_id', 'segment_nostress', 'stress_type', 'phone_path',\n",
       "       'word_path', 'speaker', 'word_startTime', 'word_endTime',\n",
       "       'word_nSample', 'wuid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth(length, bp_pair):\n",
    "    # Initialize the ground truth tensor with zeros or a placeholder value\n",
    "    ground_truth = torch.zeros(length, dtype=torch.int)\n",
    "\n",
    "    # Start index for the first phoneme\n",
    "    start_idx = 0\n",
    "\n",
    "    # Process all but the last phoneme using the boundaries\n",
    "    for (boundary, phoneme) in bp_pair[:-1]:\n",
    "        ground_truth[start_idx:boundary] = phoneme\n",
    "        start_idx = boundary\n",
    "\n",
    "    # Handle the last phoneme, ensuring it extends to the end of the mel spectrogram if necessary\n",
    "    ground_truth[start_idx:] = bp_pair[-1][0]\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenMap: \n",
    "    def __init__(self, token_list, starter=1):  \n",
    "        self.token2idx = {element: index + starter for index, element in enumerate(token_list)}\n",
    "        self.idx2token = {index + starter: element for index, element in enumerate(token_list)}\n",
    "    \n",
    "    def encode(self, token): \n",
    "        return self.token2idx[token]\n",
    "    \n",
    "    def decode(self, idx): \n",
    "        return self.idx2token[idx]\n",
    "    \n",
    "    def token_num(self): \n",
    "        return len(self.token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = guide_file.drop_duplicates(subset='wuid')\n",
    "word_nSamples_list = ((unique_df['word_nSample'] // 200).astype(int) + 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "    mylist = pickle.load(file)\n",
    "\n",
    "# Now you can use the loaded object\n",
    "mapper = TokenMap(mylist, starter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = guide_file.groupby('wuid').apply(lambda x: [(mapper.encode(row[\"segment_nostress\"]), time_to_frame(row['endTime'] - row['word_startTime'])) for index, row in x.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391018/3761935688.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  create_ground_truth(word_nSamples_list[i], grouped[i])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 30, 30, 30, 30, 35, 35, 35, 35, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "create_ground_truth(word_nSamples_list[i], grouped[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391018/587015168.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mappedgt = [create_ground_truth(word_nSamples_list[i], grouped[i]) for i in range(len(grouped))]\n"
     ]
    }
   ],
   "source": [
    "mappedgt = [create_ground_truth(word_nSamples_list[i], grouped[i]) for i in range(len(grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgf = guide_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgf[\"startFrame\"] = modgf.apply(lambda x: time_to_frame(x['startTime'] - x['word_startTime']), axis=1)\n",
    "modgf[\"endFrame\"] = modgf.apply(lambda x: time_to_frame(x['endTime'] - x['word_startTime']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>nSample</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>in_id</th>\n",
       "      <th>segment_nostress</th>\n",
       "      <th>stress_type</th>\n",
       "      <th>phone_path</th>\n",
       "      <th>word_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_startTime</th>\n",
       "      <th>word_endTime</th>\n",
       "      <th>word_nSample</th>\n",
       "      <th>wuid</th>\n",
       "      <th>startFrame</th>\n",
       "      <th>endFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>SNA</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0003.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UH1</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>2.0</td>\n",
       "      <td>UH</td>\n",
       "      <td>1</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0004.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>took</td>\n",
       "      <td>3.0</td>\n",
       "      <td>K</td>\n",
       "      <td>SNA</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0005.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1069-133699-0000-0001</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0007.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0002.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1069-133699-0000-0002</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AE1</td>\n",
       "      <td>1069-133699-0000</td>\n",
       "      <td>14</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1920</td>\n",
       "      <td>4.0</td>\n",
       "      <td>after</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AE</td>\n",
       "      <td>1</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0014.flac</td>\n",
       "      <td>1069/133699/0000/1069-133699-0000-0004.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>1069-133699-0000-0004</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376832</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>145</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.27</td>\n",
       "      <td>960</td>\n",
       "      <td>45.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0145.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0045.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.27</td>\n",
       "      <td>960.0</td>\n",
       "      <td>887-123291-0042-0045</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376833</th>\n",
       "      <td>F</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>146</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1920</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0146.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376834</th>\n",
       "      <td>AO1</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>147</td>\n",
       "      <td>14.39</td>\n",
       "      <td>14.48</td>\n",
       "      <td>1440</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AO</td>\n",
       "      <td>1</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0147.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376835</th>\n",
       "      <td>L</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>148</td>\n",
       "      <td>14.48</td>\n",
       "      <td>14.55</td>\n",
       "      <td>1120</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0148.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376836</th>\n",
       "      <td>S</td>\n",
       "      <td>887-123291-0042</td>\n",
       "      <td>149</td>\n",
       "      <td>14.55</td>\n",
       "      <td>14.58</td>\n",
       "      <td>480</td>\n",
       "      <td>46.0</td>\n",
       "      <td>false</td>\n",
       "      <td>4.0</td>\n",
       "      <td>S</td>\n",
       "      <td>SNA</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0149.flac</td>\n",
       "      <td>887/123291/0042/887-123291-0042-0046.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.58</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>887-123291-0042-0046</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261050 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment              file   id  startTime  endTime  nSample  word_id  \\\n",
       "3            T  1069-133699-0000    3       0.70     0.79     1440      1.0   \n",
       "4          UH1  1069-133699-0000    4       0.79     0.92     2080      1.0   \n",
       "5            K  1069-133699-0000    5       0.92     1.02     1600      1.0   \n",
       "7          AH0  1069-133699-0000    7       1.05     1.16     1760      2.0   \n",
       "14         AE1  1069-133699-0000   14       1.69     1.81     1920      4.0   \n",
       "...        ...               ...  ...        ...      ...      ...      ...   \n",
       "376832     AH0   887-123291-0042  145      14.21    14.27      960     45.0   \n",
       "376833       F   887-123291-0042  146      14.27    14.39     1920     46.0   \n",
       "376834     AO1   887-123291-0042  147      14.39    14.48     1440     46.0   \n",
       "376835       L   887-123291-0042  148      14.48    14.55     1120     46.0   \n",
       "376836       S   887-123291-0042  149      14.55    14.58      480     46.0   \n",
       "\n",
       "         word  in_id segment_nostress stress_type  \\\n",
       "3        took    1.0                T         SNA   \n",
       "4        took    2.0               UH           1   \n",
       "5        took    3.0                K         SNA   \n",
       "7           a    1.0               AH           0   \n",
       "14      after    1.0               AE           1   \n",
       "...       ...    ...              ...         ...   \n",
       "376832      a    1.0               AH           0   \n",
       "376833  false    1.0                F         SNA   \n",
       "376834  false    2.0               AO           1   \n",
       "376835  false    3.0                L         SNA   \n",
       "376836  false    4.0                S         SNA   \n",
       "\n",
       "                                         phone_path  \\\n",
       "3       1069/133699/0000/1069-133699-0000-0003.flac   \n",
       "4       1069/133699/0000/1069-133699-0000-0004.flac   \n",
       "5       1069/133699/0000/1069-133699-0000-0005.flac   \n",
       "7       1069/133699/0000/1069-133699-0000-0007.flac   \n",
       "14      1069/133699/0000/1069-133699-0000-0014.flac   \n",
       "...                                             ...   \n",
       "376832    887/123291/0042/887-123291-0042-0145.flac   \n",
       "376833    887/123291/0042/887-123291-0042-0146.flac   \n",
       "376834    887/123291/0042/887-123291-0042-0147.flac   \n",
       "376835    887/123291/0042/887-123291-0042-0148.flac   \n",
       "376836    887/123291/0042/887-123291-0042-0149.flac   \n",
       "\n",
       "                                          word_path  speaker  word_startTime  \\\n",
       "3       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "4       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "5       1069/133699/0000/1069-133699-0000-0001.flac     1069            0.70   \n",
       "7       1069/133699/0000/1069-133699-0000-0002.flac     1069            1.05   \n",
       "14      1069/133699/0000/1069-133699-0000-0004.flac     1069            1.69   \n",
       "...                                             ...      ...             ...   \n",
       "376832    887/123291/0042/887-123291-0042-0045.flac      887           14.21   \n",
       "376833    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376834    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376835    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "376836    887/123291/0042/887-123291-0042-0046.flac      887           14.27   \n",
       "\n",
       "        word_endTime  word_nSample                   wuid  startFrame  \\\n",
       "3               1.02        5120.0  1069-133699-0000-0001           0   \n",
       "4               1.02        5120.0  1069-133699-0000-0001           7   \n",
       "5               1.02        5120.0  1069-133699-0000-0001          17   \n",
       "7               1.16        1760.0  1069-133699-0000-0002           0   \n",
       "14              2.04        5600.0  1069-133699-0000-0004           0   \n",
       "...              ...           ...                    ...         ...   \n",
       "376832         14.27         960.0   887-123291-0042-0045           0   \n",
       "376833         14.58        4960.0   887-123291-0042-0046           0   \n",
       "376834         14.58        4960.0   887-123291-0042-0046           9   \n",
       "376835         14.58        4960.0   887-123291-0042-0046          16   \n",
       "376836         14.58        4960.0   887-123291-0042-0046          22   \n",
       "\n",
       "        endFrame  \n",
       "3              7  \n",
       "4             17  \n",
       "5             25  \n",
       "7              8  \n",
       "14             9  \n",
       "...          ...  \n",
       "376832         4  \n",
       "376833         9  \n",
       "376834        16  \n",
       "376835        22  \n",
       "376836        24  \n",
       "\n",
       "[261050 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selwuid = modgf[\"wuid\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "randlist = [np.random.choice(len(selwuid)) for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_phone_df = modgf[modgf[\"segment_nostress\"] == \"IY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "selwuid = modgf[\"wuid\"].unique()[randlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedgf = modgf[modgf[\"wuid\"].isin(selwuid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_phone_df = selectedgf[selectedgf[\"segment_nostress\"] == \"AH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>nSample</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>in_id</th>\n",
       "      <th>segment_nostress</th>\n",
       "      <th>stress_type</th>\n",
       "      <th>phone_path</th>\n",
       "      <th>word_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_startTime</th>\n",
       "      <th>word_endTime</th>\n",
       "      <th>word_nSample</th>\n",
       "      <th>wuid</th>\n",
       "      <th>startFrame</th>\n",
       "      <th>endFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0040</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>was</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0040/1069-133699-0040-0004.flac</td>\n",
       "      <td>1069/133699/0040/1069-133699-0040-0001.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>1069-133699-0040-0001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1069-133699-0048</td>\n",
       "      <td>104</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1440</td>\n",
       "      <td>26.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1069/133699/0048/1069-133699-0048-0104.flac</td>\n",
       "      <td>1069/133699/0048/1069-133699-0048-0026.flac</td>\n",
       "      <td>1069</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1069-133699-0048-0026</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19009</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-124588-0010</td>\n",
       "      <td>111</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.18</td>\n",
       "      <td>640</td>\n",
       "      <td>31.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/124588/0010/118-124588-0010-0111.flac</td>\n",
       "      <td>118/124588/0010/118-124588-0010-0031.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.18</td>\n",
       "      <td>640.0</td>\n",
       "      <td>118-124588-0010-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22314</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-47824-0009</td>\n",
       "      <td>42</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.49</td>\n",
       "      <td>480</td>\n",
       "      <td>11.0</td>\n",
       "      <td>lessens</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/47824/0009/118-47824-0009-0042.flac</td>\n",
       "      <td>118/47824/0009/118-47824-0009-0011.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.58</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>118-47824-0009-0011</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24176</th>\n",
       "      <td>AH0</td>\n",
       "      <td>118-47824-0027</td>\n",
       "      <td>60</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.35</td>\n",
       "      <td>640</td>\n",
       "      <td>18.0</td>\n",
       "      <td>openly</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>118/47824/0027/118-47824-0027-0060.flac</td>\n",
       "      <td>118/47824/0027/118-47824-0027-0018.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>118-47824-0027-0018</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26904</th>\n",
       "      <td>AH1</td>\n",
       "      <td>118-47824-0050</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>underbrush</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0003.flac</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0001.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>118-47824-0050-0001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26910</th>\n",
       "      <td>AH2</td>\n",
       "      <td>118-47824-0050</td>\n",
       "      <td>9</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>underbrush</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>2</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0009.flac</td>\n",
       "      <td>118/47824/0050/118-47824-0050-0001.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>118-47824-0050-0001</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44666</th>\n",
       "      <td>AH0</td>\n",
       "      <td>150-132655-0020</td>\n",
       "      <td>14</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>150/132655/0020/150-132655-0020-0014.flac</td>\n",
       "      <td>150/132655/0020/150-132655-0020-0003.flac</td>\n",
       "      <td>150</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.38</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>150-132655-0020-0003</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51976</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1502-122619-0006</td>\n",
       "      <td>50</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.20</td>\n",
       "      <td>640</td>\n",
       "      <td>12.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1502/122619/0006/1502-122619-0006-0050.flac</td>\n",
       "      <td>1502/122619/0006/1502-122619-0006-0012.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.24</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1502-122619-0006-0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56474</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1502-122619-0046</td>\n",
       "      <td>33</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1280</td>\n",
       "      <td>8.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1502/122619/0046/1502-122619-0046-0033.flac</td>\n",
       "      <td>1502/122619/0046/1502-122619-0046-0008.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1502-122619-0046-0008</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57607</th>\n",
       "      <td>AH1</td>\n",
       "      <td>1502-122619-0056</td>\n",
       "      <td>97</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.61</td>\n",
       "      <td>640</td>\n",
       "      <td>20.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>1502/122619/0056/1502-122619-0056-0097.flac</td>\n",
       "      <td>1502/122619/0056/1502-122619-0056-0020.flac</td>\n",
       "      <td>1502</td>\n",
       "      <td>8.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1502-122619-0056-0020</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61616</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0000</td>\n",
       "      <td>74</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1120</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0000/1992-141719-0000-0074.flac</td>\n",
       "      <td>1992/141719/0000/1992-141719-0000-0018.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1992-141719-0000-0018</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63966</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0017</td>\n",
       "      <td>47</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.10</td>\n",
       "      <td>800</td>\n",
       "      <td>10.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0017/1992-141719-0017-0047.flac</td>\n",
       "      <td>1992/141719/0017/1992-141719-0017-0010.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1992-141719-0017-0010</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69305</th>\n",
       "      <td>AH0</td>\n",
       "      <td>1992-141719-0055</td>\n",
       "      <td>134</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.21</td>\n",
       "      <td>800</td>\n",
       "      <td>39.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>1992/141719/0055/1992-141719-0055-0134.flac</td>\n",
       "      <td>1992/141719/0055/1992-141719-0055-0039.flac</td>\n",
       "      <td>1992</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.21</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1992-141719-0055-0039</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82105</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2092-145709-0016</td>\n",
       "      <td>87</td>\n",
       "      <td>10.31</td>\n",
       "      <td>10.34</td>\n",
       "      <td>480</td>\n",
       "      <td>26.0</td>\n",
       "      <td>can</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2092/145709/0016/2092-145709-0016-0087.flac</td>\n",
       "      <td>2092/145709/0016/2092-145709-0016-0026.flac</td>\n",
       "      <td>2092</td>\n",
       "      <td>10.19</td>\n",
       "      <td>10.41</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>2092-145709-0016-0026</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86489</th>\n",
       "      <td>AH1</td>\n",
       "      <td>2159-179154-0027</td>\n",
       "      <td>118</td>\n",
       "      <td>10.07</td>\n",
       "      <td>10.12</td>\n",
       "      <td>800</td>\n",
       "      <td>30.0</td>\n",
       "      <td>subject</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>2159/179154/0027/2159-179154-0027-0118.flac</td>\n",
       "      <td>2159/179154/0027/2159-179154-0027-0030.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>9.96</td>\n",
       "      <td>10.41</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>2159-179154-0027-0030</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92032</th>\n",
       "      <td>AH1</td>\n",
       "      <td>2159-179156-0026</td>\n",
       "      <td>81</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.96</td>\n",
       "      <td>480</td>\n",
       "      <td>20.0</td>\n",
       "      <td>pulse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>2159/179156/0026/2159-179156-0026-0081.flac</td>\n",
       "      <td>2159/179156/0026/2159-179156-0026-0020.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>6.79</td>\n",
       "      <td>7.21</td>\n",
       "      <td>6720.0</td>\n",
       "      <td>2159-179156-0026-0020</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93684</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2159-179157-0003</td>\n",
       "      <td>57</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.95</td>\n",
       "      <td>960</td>\n",
       "      <td>11.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2159/179157/0003/2159-179157-0003-0057.flac</td>\n",
       "      <td>2159/179157/0003/2159-179157-0003-0011.flac</td>\n",
       "      <td>2159</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>2159-179157-0003-0011</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102889</th>\n",
       "      <td>AH0</td>\n",
       "      <td>2836-5354-0031</td>\n",
       "      <td>24</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.24</td>\n",
       "      <td>800</td>\n",
       "      <td>6.0</td>\n",
       "      <td>isabel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>2836/5354/0031/2836-5354-0031-0024.flac</td>\n",
       "      <td>2836/5354/0031/2836-5354-0031-0006.flac</td>\n",
       "      <td>2836</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.48</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>2836-5354-0031-0006</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120503</th>\n",
       "      <td>AH0</td>\n",
       "      <td>298-126790-0038</td>\n",
       "      <td>54</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>960</td>\n",
       "      <td>15.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>298/126790/0038/298-126790-0038-0054.flac</td>\n",
       "      <td>298/126790/0038/298-126790-0038-0015.flac</td>\n",
       "      <td>298</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.69</td>\n",
       "      <td>960.0</td>\n",
       "      <td>298-126790-0038-0015</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125414</th>\n",
       "      <td>AH0</td>\n",
       "      <td>298-126791-0021</td>\n",
       "      <td>107</td>\n",
       "      <td>7.86</td>\n",
       "      <td>7.91</td>\n",
       "      <td>800</td>\n",
       "      <td>27.0</td>\n",
       "      <td>noticed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>298/126791/0021/298-126791-0021-0107.flac</td>\n",
       "      <td>298/126791/0021/298-126791-0021-0027.flac</td>\n",
       "      <td>298</td>\n",
       "      <td>7.65</td>\n",
       "      <td>8.04</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>298-126791-0021-0027</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146738</th>\n",
       "      <td>AH0</td>\n",
       "      <td>302-123523-0029</td>\n",
       "      <td>17</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.71</td>\n",
       "      <td>960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>302/123523/0029/302-123523-0029-0017.flac</td>\n",
       "      <td>302/123523/0029/302-123523-0029-0002.flac</td>\n",
       "      <td>302</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>302-123523-0029-0002</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153279</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3168-173564-0041</td>\n",
       "      <td>55</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.11</td>\n",
       "      <td>1120</td>\n",
       "      <td>15.0</td>\n",
       "      <td>wounded</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3168/173564/0041/3168-173564-0041-0055.flac</td>\n",
       "      <td>3168/173564/0041/3168-173564-0041-0015.flac</td>\n",
       "      <td>3168</td>\n",
       "      <td>5.79</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6080.0</td>\n",
       "      <td>3168-173564-0041-0015</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162095</th>\n",
       "      <td>AH0</td>\n",
       "      <td>322-124146-0002</td>\n",
       "      <td>18</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.81</td>\n",
       "      <td>640</td>\n",
       "      <td>3.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>322/124146/0002/322-124146-0002-0018.flac</td>\n",
       "      <td>322/124146/0002/322-124146-0002-0003.flac</td>\n",
       "      <td>322</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>322-124146-0002-0003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168418</th>\n",
       "      <td>AH0</td>\n",
       "      <td>322-124147-0022</td>\n",
       "      <td>117</td>\n",
       "      <td>12.88</td>\n",
       "      <td>12.94</td>\n",
       "      <td>960</td>\n",
       "      <td>28.0</td>\n",
       "      <td>dearest</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>322/124147/0022/322-124147-0022-0117.flac</td>\n",
       "      <td>322/124147/0022/322-124147-0022-0028.flac</td>\n",
       "      <td>322</td>\n",
       "      <td>12.68</td>\n",
       "      <td>13.08</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>322-124147-0022-0028</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178551</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3240-131231-0023</td>\n",
       "      <td>11</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3240/131231/0023/3240-131231-0023-0011.flac</td>\n",
       "      <td>3240/131231/0023/3240-131231-0023-0003.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3240-131231-0023-0003</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182196</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3240-131231-0055</td>\n",
       "      <td>9</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1280</td>\n",
       "      <td>2.0</td>\n",
       "      <td>july</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3240/131231/0055/3240-131231-0055-0009.flac</td>\n",
       "      <td>3240/131231/0055/3240-131231-0055-0002.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>3240-131231-0055-0002</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183419</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3240-131231-0065</td>\n",
       "      <td>87</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.36</td>\n",
       "      <td>640</td>\n",
       "      <td>24.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3240/131231/0065/3240-131231-0065-0087.flac</td>\n",
       "      <td>3240/131231/0065/3240-131231-0065-0024.flac</td>\n",
       "      <td>3240</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>3240-131231-0065-0024</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194998</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3440-171006-0020</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blushing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3440/171006/0020/3440-171006-0020-0003.flac</td>\n",
       "      <td>3440/171006/0020/3440-171006-0020-0000.flac</td>\n",
       "      <td>3440</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.57</td>\n",
       "      <td>6560.0</td>\n",
       "      <td>3440-171006-0020-0000</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206558</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3440-171009-0070</td>\n",
       "      <td>100</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.05</td>\n",
       "      <td>480</td>\n",
       "      <td>28.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3440/171009/0070/3440-171009-0070-0100.flac</td>\n",
       "      <td>3440/171009/0070/3440-171009-0070-0028.flac</td>\n",
       "      <td>3440</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>3440-171009-0070-0028</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209417</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4923-0009</td>\n",
       "      <td>100</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.55</td>\n",
       "      <td>960</td>\n",
       "      <td>25.0</td>\n",
       "      <td>pilot's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4923/0009/3807-4923-0009-0100.flac</td>\n",
       "      <td>3807/4923/0009/3807-4923-0009-0025.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.65</td>\n",
       "      <td>6880.0</td>\n",
       "      <td>3807-4923-0009-0025</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213880</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4923-0040</td>\n",
       "      <td>91</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.07</td>\n",
       "      <td>480</td>\n",
       "      <td>26.0</td>\n",
       "      <td>polite</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4923/0040/3807-4923-0040-0091.flac</td>\n",
       "      <td>3807/4923/0040/3807-4923-0040-0026.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>7.96</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>3807-4923-0040-0026</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216975</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0002</td>\n",
       "      <td>111</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1760</td>\n",
       "      <td>30.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0002/3807-4955-0002-0111.flac</td>\n",
       "      <td>3807/4955/0002/3807-4955-0002-0030.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.66</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3807-4955-0002-0030</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219823</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0020</td>\n",
       "      <td>17</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.49</td>\n",
       "      <td>960</td>\n",
       "      <td>3.0</td>\n",
       "      <td>plus</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0020/3807-4955-0020-0017.flac</td>\n",
       "      <td>3807/4955/0020/3807-4955-0020-0003.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>3807-4955-0020-0003</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222669</th>\n",
       "      <td>AH1</td>\n",
       "      <td>3807-4955-0038</td>\n",
       "      <td>58</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.73</td>\n",
       "      <td>480</td>\n",
       "      <td>16.0</td>\n",
       "      <td>vulcan's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0058.flac</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0016.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>3807-4955-0038-0016</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222672</th>\n",
       "      <td>AH0</td>\n",
       "      <td>3807-4955-0038</td>\n",
       "      <td>61</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.93</td>\n",
       "      <td>640</td>\n",
       "      <td>16.0</td>\n",
       "      <td>vulcan's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0061.flac</td>\n",
       "      <td>3807/4955/0038/3807-4955-0038-0016.flac</td>\n",
       "      <td>3807</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>3807-4955-0038-0016</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228370</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186236-0001</td>\n",
       "      <td>19</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.69</td>\n",
       "      <td>960</td>\n",
       "      <td>5.0</td>\n",
       "      <td>servants</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186236/0001/4195-186236-0001-0019.flac</td>\n",
       "      <td>4195/186236/0001/4195-186236-0001-0005.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>4195-186236-0001-0005</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234828</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186237-0023</td>\n",
       "      <td>17</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.19</td>\n",
       "      <td>640</td>\n",
       "      <td>6.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186237/0023/4195-186237-0023-0017.flac</td>\n",
       "      <td>4195/186237/0023/4195-186237-0023-0006.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>4195-186237-0023-0006</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235992</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4195-186237-0030</td>\n",
       "      <td>115</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.34</td>\n",
       "      <td>640</td>\n",
       "      <td>27.0</td>\n",
       "      <td>truthful</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4195/186237/0030/4195-186237-0030-0115.flac</td>\n",
       "      <td>4195/186237/0030/4195-186237-0030-0027.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>9.95</td>\n",
       "      <td>10.42</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>4195-186237-0030-0027</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238732</th>\n",
       "      <td>AH1</td>\n",
       "      <td>4195-186238-0017</td>\n",
       "      <td>87</td>\n",
       "      <td>8.92</td>\n",
       "      <td>8.97</td>\n",
       "      <td>800</td>\n",
       "      <td>26.0</td>\n",
       "      <td>come</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>4195/186238/0017/4195-186238-0017-0087.flac</td>\n",
       "      <td>4195/186238/0017/4195-186238-0017-0026.flac</td>\n",
       "      <td>4195</td>\n",
       "      <td>8.78</td>\n",
       "      <td>9.04</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>4195-186238-0017-0026</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240265</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4397-15666-0001</td>\n",
       "      <td>41</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.40</td>\n",
       "      <td>480</td>\n",
       "      <td>10.0</td>\n",
       "      <td>local</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4397/15666/0001/4397-15666-0001-0041.flac</td>\n",
       "      <td>4397/15666/0001/4397-15666-0001-0010.flac</td>\n",
       "      <td>4397</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.47</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>4397-15666-0001-0010</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251966</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4397-15678-0013</td>\n",
       "      <td>79</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.05</td>\n",
       "      <td>480</td>\n",
       "      <td>19.0</td>\n",
       "      <td>terminus</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4397/15678/0013/4397-15678-0013-0079.flac</td>\n",
       "      <td>4397/15678/0013/4397-15678-0013-0019.flac</td>\n",
       "      <td>4397</td>\n",
       "      <td>6.78</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>4397-15678-0013-0019</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264094</th>\n",
       "      <td>AH0</td>\n",
       "      <td>446-123502-0000</td>\n",
       "      <td>107</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>800</td>\n",
       "      <td>31.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>446/123502/0000/446-123502-0000-0107.flac</td>\n",
       "      <td>446/123502/0000/446-123502-0000-0031.flac</td>\n",
       "      <td>446</td>\n",
       "      <td>11.20</td>\n",
       "      <td>11.35</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>446-123502-0000-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270544</th>\n",
       "      <td>AH1</td>\n",
       "      <td>446-123502-0046</td>\n",
       "      <td>44</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.14</td>\n",
       "      <td>800</td>\n",
       "      <td>11.0</td>\n",
       "      <td>from</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>1</td>\n",
       "      <td>446/123502/0046/446-123502-0046-0044.flac</td>\n",
       "      <td>446/123502/0046/446-123502-0046-0011.flac</td>\n",
       "      <td>446</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>446-123502-0046-0011</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275088</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4788-294466-0029</td>\n",
       "      <td>22</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.37</td>\n",
       "      <td>960</td>\n",
       "      <td>6.0</td>\n",
       "      <td>that</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4788/294466/0029/4788-294466-0029-0022.flac</td>\n",
       "      <td>4788/294466/0029/4788-294466-0029-0006.flac</td>\n",
       "      <td>4788</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>4788-294466-0029-0006</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282021</th>\n",
       "      <td>AH0</td>\n",
       "      <td>4788-94904-0004</td>\n",
       "      <td>136</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.45</td>\n",
       "      <td>1600</td>\n",
       "      <td>33.0</td>\n",
       "      <td>than</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>4788/94904/0004/4788-94904-0004-0136.flac</td>\n",
       "      <td>4788/94904/0004/4788-94904-0004-0033.flac</td>\n",
       "      <td>4788</td>\n",
       "      <td>12.26</td>\n",
       "      <td>12.52</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>4788-94904-0004-0033</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289220</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5163-18515-0011</td>\n",
       "      <td>109</td>\n",
       "      <td>11.37</td>\n",
       "      <td>11.41</td>\n",
       "      <td>640</td>\n",
       "      <td>33.0</td>\n",
       "      <td>people</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5163/18515/0011/5163-18515-0011-0109.flac</td>\n",
       "      <td>5163/18515/0011/5163-18515-0011-0033.flac</td>\n",
       "      <td>5163</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11.48</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>5163-18515-0011-0033</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290102</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5163-18515-0018</td>\n",
       "      <td>51</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1120</td>\n",
       "      <td>14.0</td>\n",
       "      <td>along</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5163/18515/0018/5163-18515-0018-0051.flac</td>\n",
       "      <td>5163/18515/0018/5163-18515-0018-0014.flac</td>\n",
       "      <td>5163</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>5163-18515-0018-0014</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307573</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14133-0039</td>\n",
       "      <td>156</td>\n",
       "      <td>14.74</td>\n",
       "      <td>14.80</td>\n",
       "      <td>960</td>\n",
       "      <td>52.0</td>\n",
       "      <td>to</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14133/0039/5339-14133-0039-0156.flac</td>\n",
       "      <td>5339/14133/0039/5339-14133-0039-0052.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>14.67</td>\n",
       "      <td>14.80</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>5339-14133-0039-0052</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312485</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14134-0018</td>\n",
       "      <td>86</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.74</td>\n",
       "      <td>960</td>\n",
       "      <td>21.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14134/0018/5339-14134-0018-0086.flac</td>\n",
       "      <td>5339/14134/0018/5339-14134-0018-0021.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>5339-14134-0018-0021</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312905</th>\n",
       "      <td>AH0</td>\n",
       "      <td>5339-14134-0020</td>\n",
       "      <td>145</td>\n",
       "      <td>11.03</td>\n",
       "      <td>11.06</td>\n",
       "      <td>480</td>\n",
       "      <td>33.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>5339/14134/0020/5339-14134-0020-0145.flac</td>\n",
       "      <td>5339/14134/0020/5339-14134-0020-0033.flac</td>\n",
       "      <td>5339</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.06</td>\n",
       "      <td>960.0</td>\n",
       "      <td>5339-14134-0020-0033</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334776</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-368-0006</td>\n",
       "      <td>30</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.88</td>\n",
       "      <td>480</td>\n",
       "      <td>9.0</td>\n",
       "      <td>and</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/368/0006/78-368-0006-0030.flac</td>\n",
       "      <td>78/368/0006/78-368-0006-0009.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>78-368-0006-0009</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341830</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0018/78-369-0018-0002.flac</td>\n",
       "      <td>78/369/0018/78-369-0018-0000.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>78-369-0018-0000</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342377</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0022</td>\n",
       "      <td>117</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.04</td>\n",
       "      <td>640</td>\n",
       "      <td>31.0</td>\n",
       "      <td>alone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0022/78-369-0022-0117.flac</td>\n",
       "      <td>78/369/0022/78-369-0022-0031.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>78-369-0022-0031</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343292</th>\n",
       "      <td>AH0</td>\n",
       "      <td>78-369-0030</td>\n",
       "      <td>20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.80</td>\n",
       "      <td>800</td>\n",
       "      <td>6.0</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>78/369/0030/78-369-0030-0020.flac</td>\n",
       "      <td>78/369/0030/78-369-0030-0006.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>78-369-0030-0006</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349117</th>\n",
       "      <td>AH0</td>\n",
       "      <td>8098-275181-0013</td>\n",
       "      <td>28</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1120</td>\n",
       "      <td>10.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>8098/275181/0013/8098-275181-0013-0028.flac</td>\n",
       "      <td>8098/275181/0013/8098-275181-0013-0010.flac</td>\n",
       "      <td>8098</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>8098-275181-0013-0010</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349948</th>\n",
       "      <td>AH0</td>\n",
       "      <td>8098-275181-0021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>8098/275181/0021/8098-275181-0021-0005.flac</td>\n",
       "      <td>8098/275181/0021/8098-275181-0021-0001.flac</td>\n",
       "      <td>8098</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>8098-275181-0021-0001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365811</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0032</td>\n",
       "      <td>73</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.67</td>\n",
       "      <td>800</td>\n",
       "      <td>21.0</td>\n",
       "      <td>the</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0032/887-123289-0032-0073.flac</td>\n",
       "      <td>887/123289/0032/887-123289-0032-0021.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>887-123289-0032-0021</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366475</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0038</td>\n",
       "      <td>138</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.17</td>\n",
       "      <td>480</td>\n",
       "      <td>38.0</td>\n",
       "      <td>examined</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0138.flac</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0038.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>12.78</td>\n",
       "      <td>13.26</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>887-123289-0038-0038</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366480</th>\n",
       "      <td>AH0</td>\n",
       "      <td>887-123289-0038</td>\n",
       "      <td>143</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.39</td>\n",
       "      <td>640</td>\n",
       "      <td>40.0</td>\n",
       "      <td>again</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0143.flac</td>\n",
       "      <td>887/123289/0038/887-123289-0038-0040.flac</td>\n",
       "      <td>887</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.82</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>887-123289-0038-0040</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment              file   id  startTime  endTime  nSample  word_id  \\\n",
       "5331       AH0  1069-133699-0040    4       0.50     0.57     1120      1.0   \n",
       "6502       AH0  1069-133699-0048  104       9.88     9.97     1440     26.0   \n",
       "19009      AH0   118-124588-0010  111       9.14     9.18      640     31.0   \n",
       "22314      AH0    118-47824-0009   42       4.46     4.49      480     11.0   \n",
       "24176      AH0    118-47824-0027   60       4.31     4.35      640     18.0   \n",
       "26904      AH1    118-47824-0050    3       0.71     0.75      640      1.0   \n",
       "26910      AH2    118-47824-0050    9       1.06     1.13     1120      1.0   \n",
       "44666      AH0   150-132655-0020   14       1.20     1.30     1600      3.0   \n",
       "51976      AH0  1502-122619-0006   50       4.16     4.20      640     12.0   \n",
       "56474      AH0  1502-122619-0046   33       2.62     2.70     1280      8.0   \n",
       "57607      AH1  1502-122619-0056   97       8.57     8.61      640     20.0   \n",
       "61616      AH0  1992-141719-0000   74       6.73     6.80     1120     18.0   \n",
       "63966      AH0  1992-141719-0017   47       5.05     5.10      800     10.0   \n",
       "69305      AH0  1992-141719-0055  134      12.16    12.21      800     39.0   \n",
       "82105      AH0  2092-145709-0016   87      10.31    10.34      480     26.0   \n",
       "86489      AH1  2159-179154-0027  118      10.07    10.12      800     30.0   \n",
       "92032      AH1  2159-179156-0026   81       6.93     6.96      480     20.0   \n",
       "93684      AH0  2159-179157-0003   57       4.89     4.95      960     11.0   \n",
       "102889     AH0    2836-5354-0031   24       2.19     2.24      800      6.0   \n",
       "120503     AH0   298-126790-0038   54       3.63     3.69      960     15.0   \n",
       "125414     AH0   298-126791-0021  107       7.86     7.91      800     27.0   \n",
       "146738     AH0   302-123523-0029   17       1.65     1.71      960      2.0   \n",
       "153279     AH0  3168-173564-0041   55       6.04     6.11     1120     15.0   \n",
       "162095     AH0   322-124146-0002   18       1.77     1.81      640      3.0   \n",
       "168418     AH0   322-124147-0022  117      12.88    12.94      960     28.0   \n",
       "178551     AH0  3240-131231-0023   11       0.99     1.06     1120      3.0   \n",
       "182196     AH0  3240-131231-0055    9       1.82     1.90     1280      2.0   \n",
       "183419     AH1  3240-131231-0065   87       7.32     7.36      640     24.0   \n",
       "194998     AH1  3440-171006-0020    3       0.25     0.31      960      0.0   \n",
       "206558     AH0  3440-171009-0070  100      10.02    10.05      480     28.0   \n",
       "209417     AH0    3807-4923-0009  100       8.49     8.55      960     25.0   \n",
       "213880     AH0    3807-4923-0040   91       8.04     8.07      480     26.0   \n",
       "216975     AH1    3807-4955-0002  111       9.46     9.57     1760     30.0   \n",
       "219823     AH1    3807-4955-0020   17       1.43     1.49      960      3.0   \n",
       "222669     AH1    3807-4955-0038   58       5.70     5.73      480     16.0   \n",
       "222672     AH0    3807-4955-0038   61       5.89     5.93      640     16.0   \n",
       "228370     AH0  4195-186236-0001   19       1.63     1.69      960      5.0   \n",
       "234828     AH0  4195-186237-0023   17       1.15     1.19      640      6.0   \n",
       "235992     AH0  4195-186237-0030  115      10.30    10.34      640     27.0   \n",
       "238732     AH1  4195-186238-0017   87       8.92     8.97      800     26.0   \n",
       "240265     AH0   4397-15666-0001   41       3.37     3.40      480     10.0   \n",
       "251966     AH0   4397-15678-0013   79       7.02     7.05      480     19.0   \n",
       "264094     AH0   446-123502-0000  107      11.20    11.25      800     31.0   \n",
       "270544     AH1   446-123502-0046   44       4.09     4.14      800     11.0   \n",
       "275088     AH0  4788-294466-0029   22       2.31     2.37      960      6.0   \n",
       "282021     AH0   4788-94904-0004  136      12.35    12.45     1600     33.0   \n",
       "289220     AH0   5163-18515-0011  109      11.37    11.41      640     33.0   \n",
       "290102     AH0   5163-18515-0018   51       5.60     5.67     1120     14.0   \n",
       "307573     AH0   5339-14133-0039  156      14.74    14.80      960     52.0   \n",
       "312485     AH0   5339-14134-0018   86       6.68     6.74      960     21.0   \n",
       "312905     AH0   5339-14134-0020  145      11.03    11.06      480     33.0   \n",
       "334776     AH0       78-368-0006   30       2.85     2.88      480      9.0   \n",
       "341830     AH0       78-369-0018    2       0.61     0.66      800      0.0   \n",
       "342377     AH0       78-369-0022  117      11.00    11.04      640     31.0   \n",
       "343292     AH0       78-369-0030   20       1.75     1.80      800      6.0   \n",
       "349117     AH0  8098-275181-0013   28       3.54     3.61     1120     10.0   \n",
       "349948     AH0  8098-275181-0021    5       0.64     0.73     1440      1.0   \n",
       "365811     AH0   887-123289-0032   73       6.62     6.67      800     21.0   \n",
       "366475     AH0   887-123289-0038  138      13.14    13.17      480     38.0   \n",
       "366480     AH0   887-123289-0038  143      13.35    13.39      640     40.0   \n",
       "\n",
       "              word  in_id segment_nostress stress_type  \\\n",
       "5331           was    2.0               AH           0   \n",
       "6502             a    1.0               AH           0   \n",
       "19009            a    1.0               AH           0   \n",
       "22314      lessens    4.0               AH           0   \n",
       "24176       openly    3.0               AH           0   \n",
       "26904   underbrush    1.0               AH           1   \n",
       "26910   underbrush    7.0               AH           2   \n",
       "44666      general    5.0               AH           0   \n",
       "51976           of    1.0               AH           0   \n",
       "56474            a    1.0               AH           0   \n",
       "57607           of    1.0               AH           1   \n",
       "61616          the    2.0               AH           0   \n",
       "63966          the    2.0               AH           0   \n",
       "69305            a    1.0               AH           0   \n",
       "82105          can    2.0               AH           0   \n",
       "86489      subject    2.0               AH           1   \n",
       "92032        pulse    2.0               AH           1   \n",
       "93684          the    2.0               AH           0   \n",
       "102889      isabel    3.0               AH           0   \n",
       "120503           a    1.0               AH           0   \n",
       "125414     noticed    4.0               AH           0   \n",
       "146738         the    2.0               AH           0   \n",
       "153279     wounded    5.0               AH           0   \n",
       "162095         and    1.0               AH           0   \n",
       "168418     dearest    4.0               AH           0   \n",
       "178551         the    2.0               AH           0   \n",
       "182196        july    2.0               AH           0   \n",
       "183419         the    2.0               AH           1   \n",
       "194998    blushing    3.0               AH           1   \n",
       "206558         and    1.0               AH           0   \n",
       "209417     pilot's    4.0               AH           0   \n",
       "213880      polite    2.0               AH           0   \n",
       "216975          of    1.0               AH           1   \n",
       "219823        plus    3.0               AH           1   \n",
       "222669    vulcan's    2.0               AH           1   \n",
       "222672    vulcan's    5.0               AH           0   \n",
       "228370    servants    4.0               AH           0   \n",
       "234828          of    1.0               AH           0   \n",
       "235992    truthful    6.0               AH           0   \n",
       "238732        come    2.0               AH           1   \n",
       "240265       local    4.0               AH           0   \n",
       "251966    terminus    4.0               AH           0   \n",
       "264094          of    1.0               AH           0   \n",
       "270544        from    3.0               AH           1   \n",
       "275088        that    2.0               AH           0   \n",
       "282021        than    2.0               AH           0   \n",
       "289220      people    4.0               AH           0   \n",
       "290102       along    1.0               AH           0   \n",
       "307573          to    2.0               AH           0   \n",
       "312485          of    1.0               AH           0   \n",
       "312905         the    2.0               AH           0   \n",
       "334776         and    1.0               AH           0   \n",
       "341830         the    2.0               AH           0   \n",
       "342377       alone    1.0               AH           0   \n",
       "343292          of    1.0               AH           0   \n",
       "349117           a    1.0               AH           0   \n",
       "349948         the    2.0               AH           0   \n",
       "365811         the    2.0               AH           0   \n",
       "366475    examined    6.0               AH           0   \n",
       "366480       again    1.0               AH           0   \n",
       "\n",
       "                                         phone_path  \\\n",
       "5331    1069/133699/0040/1069-133699-0040-0004.flac   \n",
       "6502    1069/133699/0048/1069-133699-0048-0104.flac   \n",
       "19009     118/124588/0010/118-124588-0010-0111.flac   \n",
       "22314       118/47824/0009/118-47824-0009-0042.flac   \n",
       "24176       118/47824/0027/118-47824-0027-0060.flac   \n",
       "26904       118/47824/0050/118-47824-0050-0003.flac   \n",
       "26910       118/47824/0050/118-47824-0050-0009.flac   \n",
       "44666     150/132655/0020/150-132655-0020-0014.flac   \n",
       "51976   1502/122619/0006/1502-122619-0006-0050.flac   \n",
       "56474   1502/122619/0046/1502-122619-0046-0033.flac   \n",
       "57607   1502/122619/0056/1502-122619-0056-0097.flac   \n",
       "61616   1992/141719/0000/1992-141719-0000-0074.flac   \n",
       "63966   1992/141719/0017/1992-141719-0017-0047.flac   \n",
       "69305   1992/141719/0055/1992-141719-0055-0134.flac   \n",
       "82105   2092/145709/0016/2092-145709-0016-0087.flac   \n",
       "86489   2159/179154/0027/2159-179154-0027-0118.flac   \n",
       "92032   2159/179156/0026/2159-179156-0026-0081.flac   \n",
       "93684   2159/179157/0003/2159-179157-0003-0057.flac   \n",
       "102889      2836/5354/0031/2836-5354-0031-0024.flac   \n",
       "120503    298/126790/0038/298-126790-0038-0054.flac   \n",
       "125414    298/126791/0021/298-126791-0021-0107.flac   \n",
       "146738    302/123523/0029/302-123523-0029-0017.flac   \n",
       "153279  3168/173564/0041/3168-173564-0041-0055.flac   \n",
       "162095    322/124146/0002/322-124146-0002-0018.flac   \n",
       "168418    322/124147/0022/322-124147-0022-0117.flac   \n",
       "178551  3240/131231/0023/3240-131231-0023-0011.flac   \n",
       "182196  3240/131231/0055/3240-131231-0055-0009.flac   \n",
       "183419  3240/131231/0065/3240-131231-0065-0087.flac   \n",
       "194998  3440/171006/0020/3440-171006-0020-0003.flac   \n",
       "206558  3440/171009/0070/3440-171009-0070-0100.flac   \n",
       "209417      3807/4923/0009/3807-4923-0009-0100.flac   \n",
       "213880      3807/4923/0040/3807-4923-0040-0091.flac   \n",
       "216975      3807/4955/0002/3807-4955-0002-0111.flac   \n",
       "219823      3807/4955/0020/3807-4955-0020-0017.flac   \n",
       "222669      3807/4955/0038/3807-4955-0038-0058.flac   \n",
       "222672      3807/4955/0038/3807-4955-0038-0061.flac   \n",
       "228370  4195/186236/0001/4195-186236-0001-0019.flac   \n",
       "234828  4195/186237/0023/4195-186237-0023-0017.flac   \n",
       "235992  4195/186237/0030/4195-186237-0030-0115.flac   \n",
       "238732  4195/186238/0017/4195-186238-0017-0087.flac   \n",
       "240265    4397/15666/0001/4397-15666-0001-0041.flac   \n",
       "251966    4397/15678/0013/4397-15678-0013-0079.flac   \n",
       "264094    446/123502/0000/446-123502-0000-0107.flac   \n",
       "270544    446/123502/0046/446-123502-0046-0044.flac   \n",
       "275088  4788/294466/0029/4788-294466-0029-0022.flac   \n",
       "282021    4788/94904/0004/4788-94904-0004-0136.flac   \n",
       "289220    5163/18515/0011/5163-18515-0011-0109.flac   \n",
       "290102    5163/18515/0018/5163-18515-0018-0051.flac   \n",
       "307573    5339/14133/0039/5339-14133-0039-0156.flac   \n",
       "312485    5339/14134/0018/5339-14134-0018-0086.flac   \n",
       "312905    5339/14134/0020/5339-14134-0020-0145.flac   \n",
       "334776            78/368/0006/78-368-0006-0030.flac   \n",
       "341830            78/369/0018/78-369-0018-0002.flac   \n",
       "342377            78/369/0022/78-369-0022-0117.flac   \n",
       "343292            78/369/0030/78-369-0030-0020.flac   \n",
       "349117  8098/275181/0013/8098-275181-0013-0028.flac   \n",
       "349948  8098/275181/0021/8098-275181-0021-0005.flac   \n",
       "365811    887/123289/0032/887-123289-0032-0073.flac   \n",
       "366475    887/123289/0038/887-123289-0038-0138.flac   \n",
       "366480    887/123289/0038/887-123289-0038-0143.flac   \n",
       "\n",
       "                                          word_path  speaker  word_startTime  \\\n",
       "5331    1069/133699/0040/1069-133699-0040-0001.flac     1069            0.44   \n",
       "6502    1069/133699/0048/1069-133699-0048-0026.flac     1069            9.88   \n",
       "19009     118/124588/0010/118-124588-0010-0031.flac      118            9.14   \n",
       "22314       118/47824/0009/118-47824-0009-0011.flac      118            4.19   \n",
       "24176       118/47824/0027/118-47824-0027-0018.flac      118            4.16   \n",
       "26904       118/47824/0050/118-47824-0050-0001.flac      118            0.71   \n",
       "26910       118/47824/0050/118-47824-0050-0001.flac      118            0.71   \n",
       "44666     150/132655/0020/150-132655-0020-0003.flac      150            0.94   \n",
       "51976   1502/122619/0006/1502-122619-0006-0012.flac     1502            4.16   \n",
       "56474   1502/122619/0046/1502-122619-0046-0008.flac     1502            2.62   \n",
       "57607   1502/122619/0056/1502-122619-0056-0020.flac     1502            8.57   \n",
       "61616   1992/141719/0000/1992-141719-0000-0018.flac     1992            6.68   \n",
       "63966   1992/141719/0017/1992-141719-0017-0010.flac     1992            4.99   \n",
       "69305   1992/141719/0055/1992-141719-0055-0039.flac     1992           12.16   \n",
       "82105   2092/145709/0016/2092-145709-0016-0026.flac     2092           10.19   \n",
       "86489   2159/179154/0027/2159-179154-0027-0030.flac     2159            9.96   \n",
       "92032   2159/179156/0026/2159-179156-0026-0020.flac     2159            6.79   \n",
       "93684   2159/179157/0003/2159-179157-0003-0011.flac     2159            4.83   \n",
       "102889      2836/5354/0031/2836-5354-0031-0006.flac     2836            2.03   \n",
       "120503    298/126790/0038/298-126790-0038-0015.flac      298            3.63   \n",
       "125414    298/126791/0021/298-126791-0021-0027.flac      298            7.65   \n",
       "146738    302/123523/0029/302-123523-0029-0002.flac      302            1.61   \n",
       "153279  3168/173564/0041/3168-173564-0041-0015.flac     3168            5.79   \n",
       "162095    322/124146/0002/322-124146-0002-0003.flac      322            1.77   \n",
       "168418    322/124147/0022/322-124147-0022-0028.flac      322           12.68   \n",
       "178551  3240/131231/0023/3240-131231-0023-0003.flac     3240            0.96   \n",
       "182196  3240/131231/0055/3240-131231-0055-0002.flac     3240            1.75   \n",
       "183419  3240/131231/0065/3240-131231-0065-0024.flac     3240            7.29   \n",
       "194998  3440/171006/0020/3440-171006-0020-0000.flac     3440            0.16   \n",
       "206558  3440/171009/0070/3440-171009-0070-0028.flac     3440           10.02   \n",
       "209417      3807/4923/0009/3807-4923-0009-0025.flac     3807            8.22   \n",
       "213880      3807/4923/0040/3807-4923-0040-0026.flac     3807            7.96   \n",
       "216975      3807/4955/0002/3807-4955-0002-0030.flac     3807            9.46   \n",
       "219823      3807/4955/0020/3807-4955-0020-0003.flac     3807            1.30   \n",
       "222669      3807/4955/0038/3807-4955-0038-0016.flac     3807            5.61   \n",
       "222672      3807/4955/0038/3807-4955-0038-0016.flac     3807            5.61   \n",
       "228370  4195/186236/0001/4195-186236-0001-0005.flac     4195            1.40   \n",
       "234828  4195/186237/0023/4195-186237-0023-0006.flac     4195            1.15   \n",
       "235992  4195/186237/0030/4195-186237-0030-0027.flac     4195            9.95   \n",
       "238732  4195/186238/0017/4195-186238-0017-0026.flac     4195            8.78   \n",
       "240265    4397/15666/0001/4397-15666-0001-0010.flac     4397            3.16   \n",
       "251966    4397/15678/0013/4397-15678-0013-0019.flac     4397            6.78   \n",
       "264094    446/123502/0000/446-123502-0000-0031.flac      446           11.20   \n",
       "270544    446/123502/0046/446-123502-0046-0011.flac      446            3.98   \n",
       "275088  4788/294466/0029/4788-294466-0029-0006.flac     4788            2.26   \n",
       "282021    4788/94904/0004/4788-94904-0004-0033.flac     4788           12.26   \n",
       "289220    5163/18515/0011/5163-18515-0011-0033.flac     5163           11.09   \n",
       "290102    5163/18515/0018/5163-18515-0018-0014.flac     5163            5.60   \n",
       "307573    5339/14133/0039/5339-14133-0039-0052.flac     5339           14.67   \n",
       "312485    5339/14134/0018/5339-14134-0018-0021.flac     5339            6.68   \n",
       "312905    5339/14134/0020/5339-14134-0020-0033.flac     5339           11.00   \n",
       "334776            78/368/0006/78-368-0006-0009.flac       78            2.85   \n",
       "341830            78/369/0018/78-369-0018-0000.flac       78            0.53   \n",
       "342377            78/369/0022/78-369-0022-0031.flac       78           11.00   \n",
       "343292            78/369/0030/78-369-0030-0006.flac       78            1.75   \n",
       "349117  8098/275181/0013/8098-275181-0013-0010.flac     8098            3.54   \n",
       "349948  8098/275181/0021/8098-275181-0021-0001.flac     8098            0.60   \n",
       "365811    887/123289/0032/887-123289-0032-0021.flac      887            6.59   \n",
       "366475    887/123289/0038/887-123289-0038-0038.flac      887           12.78   \n",
       "366480    887/123289/0038/887-123289-0038-0040.flac      887           13.35   \n",
       "\n",
       "        word_endTime  word_nSample                   wuid  startFrame  \\\n",
       "5331            0.64        3200.0  1069-133699-0040-0001           4   \n",
       "6502            9.97        1440.0  1069-133699-0048-0026           0   \n",
       "19009           9.18         640.0   118-124588-0010-0031           0   \n",
       "22314           4.58        6240.0    118-47824-0009-0011          21   \n",
       "24176           4.48        5120.0    118-47824-0027-0018          11   \n",
       "26904           1.20        7840.0    118-47824-0050-0001           0   \n",
       "26910           1.20        7840.0    118-47824-0050-0001          28   \n",
       "44666           1.38        7040.0   150-132655-0020-0003          20   \n",
       "51976           4.24        1280.0  1502-122619-0006-0012           0   \n",
       "56474           2.70        1280.0  1502-122619-0046-0008           0   \n",
       "57607           8.64        1120.0  1502-122619-0056-0020           0   \n",
       "61616           6.80        1920.0  1992-141719-0000-0018           4   \n",
       "63966           5.10        1760.0  1992-141719-0017-0010           4   \n",
       "69305          12.21         800.0  1992-141719-0055-0039           0   \n",
       "82105          10.41        3520.0  2092-145709-0016-0026           9   \n",
       "86489          10.41        7200.0  2159-179154-0027-0030           8   \n",
       "92032           7.21        6720.0  2159-179156-0026-0020          11   \n",
       "93684           4.95        1920.0  2159-179157-0003-0011           4   \n",
       "102889          2.48        7200.0    2836-5354-0031-0006          12   \n",
       "120503          3.69         960.0   298-126790-0038-0015           0   \n",
       "125414          8.04        6240.0   298-126791-0021-0027          16   \n",
       "146738          1.71        1600.0   302-123523-0029-0002           3   \n",
       "153279          6.17        6080.0  3168-173564-0041-0015          20   \n",
       "162095          1.88        1760.0   322-124146-0002-0003           0   \n",
       "168418         13.08        6400.0   322-124147-0022-0028          16   \n",
       "178551          1.06        1600.0  3240-131231-0023-0003           2   \n",
       "182196          2.10        5600.0  3240-131231-0055-0002           5   \n",
       "183419          7.36        1120.0  3240-131231-0065-0024           2   \n",
       "194998          0.57        6560.0  3440-171006-0020-0000           7   \n",
       "206558         10.13        1760.0  3440-171009-0070-0028           0   \n",
       "209417          8.65        6880.0    3807-4923-0009-0025          21   \n",
       "213880          8.35        6240.0    3807-4923-0040-0026           6   \n",
       "216975          9.66        3200.0    3807-4955-0002-0030           0   \n",
       "219823          1.61        4960.0    3807-4955-0020-0003          10   \n",
       "222669          6.06        7200.0    3807-4955-0038-0016           7   \n",
       "222672          6.06        7200.0    3807-4955-0038-0016          22   \n",
       "228370          1.85        7200.0  4195-186236-0001-0005          18   \n",
       "234828          1.26        1760.0  4195-186237-0023-0006           0   \n",
       "235992         10.42        7520.0  4195-186237-0030-0027          28   \n",
       "238732          9.04        4160.0  4195-186238-0017-0026          11   \n",
       "240265          3.47        4960.0   4397-15666-0001-0010          16   \n",
       "251966          7.26        7680.0   4397-15678-0013-0019          19   \n",
       "264094         11.35        2400.0   446-123502-0000-0031           0   \n",
       "270544          4.23        4000.0   446-123502-0046-0011           8   \n",
       "275088          2.45        3040.0  4788-294466-0029-0006           4   \n",
       "282021         12.52        4160.0   4788-94904-0004-0033           7   \n",
       "289220         11.48        6240.0   5163-18515-0011-0033          22   \n",
       "290102          6.00        6400.0   5163-18515-0018-0014           0   \n",
       "307573         14.80        2080.0   5339-14133-0039-0052           5   \n",
       "312485          6.82        2240.0   5339-14134-0018-0021           0   \n",
       "312905         11.06         960.0   5339-14134-0020-0033           2   \n",
       "334776          3.02        2720.0       78-368-0006-0009           0   \n",
       "341830          0.66        2080.0       78-369-0018-0000           6   \n",
       "342377         11.39        6240.0       78-369-0022-0031           0   \n",
       "343292          1.92        2720.0       78-369-0030-0006           0   \n",
       "349117          3.61        1120.0  8098-275181-0013-0010           0   \n",
       "349948          0.73        2080.0  8098-275181-0021-0001           3   \n",
       "365811          6.67        1280.0   887-123289-0032-0021           2   \n",
       "366475         13.26        7680.0   887-123289-0038-0038          28   \n",
       "366480         13.82        7520.0   887-123289-0038-0040           0   \n",
       "\n",
       "        endFrame  \n",
       "5331          10  \n",
       "6502           7  \n",
       "19009          3  \n",
       "22314         23  \n",
       "24176         15  \n",
       "26904          3  \n",
       "26910         33  \n",
       "44666         28  \n",
       "51976          3  \n",
       "56474          6  \n",
       "57607          3  \n",
       "61616          9  \n",
       "63966          8  \n",
       "69305          4  \n",
       "82105         12  \n",
       "86489         12  \n",
       "92032         13  \n",
       "93684          9  \n",
       "102889        16  \n",
       "120503         4  \n",
       "125414        20  \n",
       "146738         7  \n",
       "153279        25  \n",
       "162095         3  \n",
       "168418        20  \n",
       "178551         8  \n",
       "182196        11  \n",
       "183419         5  \n",
       "194998        12  \n",
       "206558         2  \n",
       "209417        26  \n",
       "213880         8  \n",
       "216975         8  \n",
       "219823        15  \n",
       "222669         9  \n",
       "222672        25  \n",
       "228370        23  \n",
       "234828         3  \n",
       "235992        31  \n",
       "238732        15  \n",
       "240265        19  \n",
       "251966        21  \n",
       "264094         4  \n",
       "270544        12  \n",
       "275088         8  \n",
       "282021        15  \n",
       "289220        25  \n",
       "290102         5  \n",
       "307573        10  \n",
       "312485         4  \n",
       "312905         4  \n",
       "334776         2  \n",
       "341830        10  \n",
       "342377         3  \n",
       "343292         4  \n",
       "349117         5  \n",
       "349948        10  \n",
       "365811         6  \n",
       "366475        31  \n",
       "366480         3  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_phone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "y = [1, 1, 1, 3, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [np.where(x == token)[0][0] for token in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 2, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1069/133699/0000/1069-133699-0000-0001.flac'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_dataset import Normalizer, DeNormalizer\n",
    "from model_dataset import MelSpecTransformDB as TheTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TheTransform(sample_rate=REC_SAMPLE_RATE, \n",
    "                       n_fft=N_FFT, n_mels=N_MELS, \n",
    "                       normalizer=Normalizer.norm_mvn, \n",
    "                       denormalizer=DeNormalizer.norm_mvn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.ceil(torch.tensor((guide_file[\"word_nSample\"] / 200).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.tensor((guide_file[\"word_nSample\"] // 200 + 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m data, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(file_name, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform:\n\u001b[0;32m---> 10\u001b[0m     tdata \u001b[38;5;241m=\u001b[39m transform(data)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m cwns[i]\u001b[38;5;241m.\u001b[39mitem(): \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], cwns[i]\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/wavln/script/model_dataset.py:419\u001b[0m, in \u001b[0;36mMelSpecTransformDB.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform): \n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# transform to mel_spectrogram\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(waveform)  \u001b[38;5;66;03m# (channel, n_mels, time)\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# mel_spec = F.amplitude_to_DB(mel_spec)\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamplitude_to_DB(mel_spec)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:619\u001b[0m, in \u001b[0;36mMelSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    612\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     specgram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspectrogram(waveform)\n\u001b[1;32m    620\u001b[0m     mel_specgram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmel_scale(specgram)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py:110\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mspectrogram(\n\u001b[1;32m    111\u001b[0m         waveform,\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad,\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow,\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fft,\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhop_length,\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_length,\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpower,\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized,\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter,\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode,\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monesided,\n\u001b[1;32m    122\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torchaudio/functional/functional.py:126\u001b[0m, in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[0m\n\u001b[1;32m    123\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m spec_f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstft(\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mwaveform,\n\u001b[1;32m    128\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[1;32m    129\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[1;32m    130\u001b[0m     win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[1;32m    131\u001b[0m     window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[1;32m    132\u001b[0m     center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[1;32m    133\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m    134\u001b[0m     normalized\u001b[38;5;241m=\u001b[39mframe_length_norm,\n\u001b[1;32m    135\u001b[0m     onesided\u001b[38;5;241m=\u001b[39monesided,\n\u001b[1;32m    136\u001b[0m     return_complex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# unpack batch\u001b[39;00m\n\u001b[1;32m    140\u001b[0m spec_f \u001b[38;5;241m=\u001b[39m spec_f\u001b[38;5;241m.\u001b[39mreshape(shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m spec_f\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/functional.py:650\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(extended_shape), [pad, pad], pad_mode)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39msignal_dim:])\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mstft(\u001b[38;5;28minput\u001b[39m, n_fft, hop_length, win_length, window,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    651\u001b[0m                 normalized, onesided, return_complex)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wpl = guide_file[\"word_path\"].tolist()\n",
    "for i in range(len(wpl)): \n",
    "    file_name = os.path.join(\n",
    "        train_cut_word_, \n",
    "        wpl[i]\n",
    "    )\n",
    "\n",
    "    data, sample_rate = torchaudio.load(file_name, normalize=True)\n",
    "    if transform:\n",
    "        tdata = transform(data)\n",
    "\n",
    "    if tdata.shape[0] != cwns[i].item(): \n",
    "        print(tdata.shape[0], cwns[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(\n",
    "    train_cut_word_, \n",
    "    guide_file[\"word_path\"][67]\n",
    ")\n",
    "\n",
    "data, sample_rate = torchaudio.load(file_name, normalize=True)\n",
    "if transform:\n",
    "    tdata = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2080]), torch.Size([11, 64]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwns = torch.ceil(torch.tensor((guide_file[\"word_nSample\"] / 200).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([357399]), 357399)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwns.shape, len(guide_file[\"word_path\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth(length, boundaries, phonemes):\n",
    "    \"\"\"\n",
    "    Create a ground truth array for a single mel spectrogram given phoneme boundaries and identifiers,\n",
    "    ensuring the last phoneme extends to the real length of the spectrogram if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - length: The length of the mel spectrogram in frames (L).\n",
    "    - boundaries: A numpy array of ending frame indices for each phoneme (N, ).\n",
    "    - phonemes: A numpy array of phoneme identifiers corresponding to each boundary (N, ).\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of shape (L, ) where each item represents the phoneme identifier for each frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the ground truth array with zeros or a placeholder value\n",
    "    ground_truth = np.zeros(length, dtype=int)\n",
    "\n",
    "    # Start index for the first phoneme\n",
    "    start_idx = 0\n",
    "\n",
    "    # Process all but the last phoneme using the boundaries\n",
    "    for boundary, phoneme in zip(boundaries[:-1], phonemes[:-1]):\n",
    "        ground_truth[start_idx:boundary] = phoneme\n",
    "        start_idx = boundary\n",
    "\n",
    "    # Handle the last phoneme, ensuring it extends to the end of the mel spectrogram if necessary\n",
    "    ground_truth[start_idx:] = phonemes[-1]\n",
    "\n",
    "    return ground_truth.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaskedCrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')  # Use sum to manually control normalization\n",
    "\n",
    "    def get_loss(self, y_hat, y, mask):\n",
    "        # Ensure y_hat is of shape (B, C, L)\n",
    "        y_hat = y_hat.transpose(1, 2)  # Now y_hat is (B, C, L)\n",
    "        \n",
    "        # Mask should be applied to sequence lengths\n",
    "        # No need to expand mask as we are not selecting on the class dimension\n",
    "        \n",
    "        # Flatten outputs and targets to apply mask easily\n",
    "        B, C, L = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(B * L, C)\n",
    "        y_flat = y.reshape(-1)\n",
    "        mask_flat = mask.reshape(-1)\n",
    "        \n",
    "        # Filter out padded elements\n",
    "        y_hat_masked = y_hat_flat[mask_flat]\n",
    "        y_masked = y_flat[mask_flat]\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = self.loss_fn(y_hat_masked, y_masked)\n",
    "        \n",
    "        # Normalize the loss by the number of non-padded elements\n",
    "        loss = loss / mask_flat.sum()\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss: 1.469181776046753\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Loss is higher than expected, indicating padding might not be ignored correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is higher than expected, indicating padding might not be ignored correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Run the test case\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m test_masked_cross_entropy_loss()\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mtest_masked_cross_entropy_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Check if the loss is as expected (low, indicating padding was ignored)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is higher than expected, indicating padding might not be ignored correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Loss is higher than expected, indicating padding might not be ignored correctly."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def test_masked_cross_entropy_loss():\n",
    "    # Initialize the custom loss\n",
    "    masked_loss = MaskedCrossEntropyLoss()\n",
    "    \n",
    "    # Example parameters\n",
    "    batch_size = 2\n",
    "    seq_length = 3\n",
    "    num_classes = 4\n",
    "    \n",
    "    # Create synthetic predictions (y_hat)\n",
    "    # Let's assume all correct predictions for non-padded values are very confident\n",
    "    y_hat = torch.tensor([[[0.1, 0.2, 0.7, 0.0], [0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1]],  # 1st sample, with last one as padding\n",
    "                          [[0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.7]]]).float()  # 2nd sample, no padding\n",
    "    y_hat = y_hat.permute(0, 2, 1)  # Correct shape (B, C, L)\n",
    "    \n",
    "    # Create synthetic ground truth labels (y)\n",
    "    y = torch.tensor([[2, 1, 0],  # 0 is a dummy class for padding\n",
    "                      [1, 0, 3]])\n",
    "    \n",
    "    # Create mask (1 for valid, 0 for padding)\n",
    "    mask = torch.tensor([[1, 1, 0],  # Last element is padding\n",
    "                         [1, 1, 1]])  # No padding\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = masked_loss.get_loss(y_hat, y, mask)\n",
    "    \n",
    "    # Expected loss calculation\n",
    "    # Assuming cross-entropy loss for correctly classified with high confidence is close to 0\n",
    "    # The padded element should not contribute to the loss\n",
    "    # So, the expected loss should be very low as only non-padded elements are considered\n",
    "    print(f\"Computed loss: {loss.item()}\")\n",
    "    \n",
    "    # Check if the loss is as expected (low, indicating padding was ignored)\n",
    "    assert loss < 0.1, \"Loss is higher than expected, indicating padding might not be ignored correctly.\"\n",
    "\n",
    "# Run the test case\n",
    "test_masked_cross_entropy_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsfn = torch.nn.CrossEntropyLoss(reduction='none') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[[0.1, 0.2, 0.7, 0.0], [0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1]],  # 1st sample, with last one as padding\n",
    "                        [[0.1, 0.7, 0.1, 0.1], [0.7, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.7]]]).float()  # 2nd sample, no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2, 3], [0, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lsfn(y_hat.permute(0, 2, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1, 1, 1], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4753, 1.5732, 1.5732],\n",
       "        [1.5732, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomness in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((10, )) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * x.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: [1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Enhanced tensor: [0. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def enhance_zeros(tensor, C):\n",
    "    \"\"\"\n",
    "    Enhances zeros in a tensor by changing the ones within C elements before and after zeros to zero.\n",
    "\n",
    "    Args:\n",
    "    - tensor (torch.Tensor): The input tensor with ones and zeros.\n",
    "    - C (int): The number of elements before and after zeros to be enhanced to zeros.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The enhanced tensor.\n",
    "    \"\"\"\n",
    "    # Ensure the tensor is 1D\n",
    "    if tensor.dim() != 1:\n",
    "        raise ValueError(\"Tensor must be 1D. Provided tensor is {}D\".format(tensor.dim()))\n",
    "    \n",
    "    # Create a convolution kernel\n",
    "    kernel_size = 2 * C + 1\n",
    "    kernel = torch.ones((1, 1, kernel_size), dtype=tensor.dtype, device=tensor.device)\n",
    "    \n",
    "    # Pad the tensor to handle boundary conditions\n",
    "    padded_tensor = F.pad(tensor.unsqueeze(0).unsqueeze(0), (C, C), mode='constant', value=1)\n",
    "    \n",
    "    # Convolve and threshold\n",
    "    conv_result = F.conv1d(padded_tensor, kernel)\n",
    "    enhanced_tensor = (conv_result == kernel_size).float().squeeze()\n",
    "    \n",
    "    # Invert to enhance zeros\n",
    "    enhanced_tensor = 1 - enhanced_tensor\n",
    "    \n",
    "    return enhanced_tensor\n",
    "\n",
    "# Example usage\n",
    "tensor = torch.tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.float32)\n",
    "C = 1  # Number of elements to change before and after zeros\n",
    "enhanced_tensor = enhance_zeros(tensor, C)\n",
    "\n",
    "print(\"Original tensor:\", tensor.numpy())\n",
    "print(\"Enhanced tensor:\", enhanced_tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20240217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the LSTM for each sequence at each timestep:\n",
      "tensor([[[-0.1249, -0.0517, -0.3828, -0.3499],\n",
      "         [-0.1708, -0.1220, -0.3867, -0.4097],\n",
      "         [-0.1557, -0.1547, -0.3054, -0.3126]],\n",
      "\n",
      "        [[-0.1249, -0.0517, -0.2234, -0.1138],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1249, -0.0517, -0.3500, -0.2470],\n",
      "         [-0.1708, -0.1220, -0.3123, -0.2289],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<IndexSelectBackward0>)\n",
      "Last hidden state for each sequence (forward and backward):\n",
      "tensor([[[-0.1557, -0.1547],\n",
      "         [-0.1249, -0.0517],\n",
      "         [-0.1708, -0.1220]],\n",
      "\n",
      "        [[-0.3828, -0.3499],\n",
      "         [-0.2234, -0.1138],\n",
      "         [-0.3500, -0.2470]]], grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample data: batch of 3 sequences with padding (0s are paddings)\n",
    "# Lengths need to be provided to pack_padded_sequence so it knows to skip the paddings\n",
    "data = torch.tensor([[1, 2, 3], [1, 0, 0], [1, 2, 0]]).float()\n",
    "lengths = torch.tensor([3, 1, 2])  # Actual lengths of sequences without padding\n",
    "\n",
    "# Define a bidirectional LSTM\n",
    "lstm = nn.LSTM(input_size=1, hidden_size=2, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "# Process the data using the LSTM\n",
    "packed_input = pack_padded_sequence(data.unsqueeze(-1), lengths, batch_first=True, enforce_sorted=False)\n",
    "packed_output, (hidden, cell) = lstm(packed_input)\n",
    "output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "# The output tensor gives the output of the LSTM for each sequence at each timestep\n",
    "# Let's print the output for each sequence at each time step after unpacking\n",
    "print(\"Output of the LSTM for each sequence at each timestep:\")\n",
    "print(output)\n",
    "\n",
    "# Hidden state contains the last hidden state from the LSTM\n",
    "# For a bidirectional LSTM, it will return two vectors per layer per sequence\n",
    "# The first is from the forward pass and the second is from the backward pass\n",
    "print(\"Last hidden state for each sequence (forward and backward):\")\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.rand((2, 3, 4))\n",
    "logvar = torch.rand((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0737, 0.2247, 0.4689, 0.6838],\n",
       "          [0.5481, 0.5113, 0.4069, 0.1170],\n",
       "          [0.5956, 0.1688, 0.3862, 0.2856]],\n",
       " \n",
       "         [[0.9135, 0.9221, 0.6875, 0.4926],\n",
       "          [0.8215, 0.4295, 0.5575, 0.8243],\n",
       "          [0.8794, 0.0399, 0.9795, 0.6169]]]),\n",
       " tensor([[[0.2390, 0.4572, 0.0610, 0.9134],\n",
       "          [0.7273, 0.2384, 0.2816, 0.9394],\n",
       "          [0.7865, 0.0481, 0.3904, 0.9297]],\n",
       " \n",
       "         [[0.1654, 0.9366, 0.0739, 0.0950],\n",
       "          [0.4241, 0.6763, 0.5524, 0.5901],\n",
       "          [0.7201, 0.7235, 0.5182, 0.9740]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1366)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0364, 0.1729, 0.2217, 1.0470],\n",
       "         [0.6426, 0.2923, 0.2092, 0.6328],\n",
       "         [0.7640, 0.0297, 0.2364, 0.6855]],\n",
       "\n",
       "        [[0.8489, 1.4649, 0.4754, 0.2473],\n",
       "         [0.7790, 0.4748, 0.4958, 0.8936],\n",
       "         [1.1078, 0.3397, 1.1202, 1.0551]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.pow(2) + logvar.exp() - (1 + logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloss = -0.5 * torch.sum((1 + logvar - mu.pow(2) - logvar.exp()), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7390, 0.8884, 0.8578],\n",
       "        [1.5183, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfloss * torch.tensor([[1, 1, 1], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 1], [1, 1, 0], [1, 0, 0]]).bool()\n",
    "y = torch.tensor([[1, 0, 0], [1, 0, 0], [1, 0, 0]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7061, 0.2096, 0.4580],\n",
       "        [0.7048, 0.7277, 0.2524],\n",
       "        [0.2039, 0.6350, 0.1122]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7061, 0.2096, 0.4580, 0.7048, 0.7277, 0.2039]),\n",
       " tensor([1., 0., 0., 1., 0., 1.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = z.masked_select(x)\n",
    "b = y.masked_select(x)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5906)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.nn.MSELoss(reduction=\"none\")(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5906)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.nn.MSELoss(reduction=\"none\")(z, y) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.rand((10, 3))\n",
    "ze = torch.rand((2, 5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, L, C = ze.shape\n",
    "K, _ = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_broadcast = embedding.reshape(1, 1, K, C)\n",
    "ze_broadcast = ze.reshape(B, L, 1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = torch.sum((embedding_broadcast - ze_broadcast)**2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = torch.argmin(distance, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, q_in, kv_in, qk_out, v_out):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.w_q = nn.Linear(q_in, qk_out)\n",
    "        self.w_k = nn.Linear(kv_in, qk_out)\n",
    "        self.w_v = nn.Linear(kv_in, v_out)\n",
    "        self.d_k = qk_out\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        q: Query tensor of shape (batch_size, num_queries, d_k)\n",
    "        k: Key tensor of shape (batch_size, num_keys, d_k)\n",
    "        v: Value tensor of shape (batch_size, num_values, d_v), num_keys = num_values\n",
    "        mask: Mask tensor of shape (batch_size, num_queries, num_keys)\n",
    "\n",
    "        Returns: Output tensor of shape (batch_size, num_queries, d_v)\n",
    "        \"\"\"\n",
    "        q = self.w_q(q)\n",
    "        k = self.w_k(k)\n",
    "        v = self.w_v(v)\n",
    "\n",
    "        # Step 1: Compute the dot product between queries and keys\n",
    "        attn_scores = torch.bmm(q, k.transpose(1, 2))  # (batch_size, num_queries, num_keys)\n",
    "\n",
    "        # Step 2: Scale the attention scores\n",
    "        attn_scores = attn_scores / (self.d_k ** 0.5)\n",
    "\n",
    "        # Step 3: Apply the mask (if any)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        # Step 4: Compute the softmax of the attention scores\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (batch_size, num_queries, num_keys)\n",
    "\n",
    "        # Step 5: Multiply the attention weights with the values\n",
    "        output = torch.bmm(attn_weights, v)  # (batch_size, num_queries, d_v)\n",
    "\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_padding import generate_mask_from_lengths_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3, 4, 5))\n",
    "b = torch.rand((3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = ScaledDotProductAttention(5, 5, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask = generate_mask_from_lengths_mat([2, 3, 4], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = attn(a, b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([3, 4, 4]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4752, -0.6958,  0.4442,  0.0080, -0.4331],\n",
       "         [-0.4717, -0.6864,  0.4356,  0.0099, -0.4285],\n",
       "         [-0.4733, -0.6913,  0.4403,  0.0092, -0.4320],\n",
       "         [-0.4741, -0.6913,  0.4402,  0.0093, -0.4315]],\n",
       "\n",
       "        [[-0.6807, -0.7565,  0.6334,  0.0301, -0.7380],\n",
       "         [-0.6827, -0.7599,  0.6362,  0.0303, -0.7418],\n",
       "         [-0.6793, -0.7551,  0.6322,  0.0298, -0.7364],\n",
       "         [-0.6759, -0.7555,  0.6323,  0.0285, -0.7371]],\n",
       "\n",
       "        [[-0.4857, -0.7882,  0.6660, -0.0513, -0.5572],\n",
       "         [-0.4922, -0.7798,  0.6610, -0.0470, -0.5570],\n",
       "         [-0.4834, -0.7906,  0.6673, -0.0526, -0.5570],\n",
       "         [-0.4850, -0.7890,  0.6665, -0.0517, -0.5572]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4774, 0.5495, 0.3095, 0.4692, 0.3498],\n",
       "         [0.4660, 0.5203, 0.3253, 0.4569, 0.3365],\n",
       "         [0.4549, 0.5480, 0.3197, 0.4356, 0.3377],\n",
       "         [0.4669, 0.5410, 0.3170, 0.4562, 0.3428]],\n",
       "\n",
       "        [[0.4735, 0.6425, 0.8228, 0.6482, 0.5196],\n",
       "         [0.4775, 0.6498, 0.8231, 0.6443, 0.5269],\n",
       "         [0.4730, 0.6402, 0.8223, 0.6422, 0.5118],\n",
       "         [0.4807, 0.6535, 0.8225, 0.6332, 0.5262]],\n",
       "\n",
       "        [[0.6013, 0.8321, 0.3478, 0.6847, 0.2792],\n",
       "         [0.5861, 0.8205, 0.3884, 0.6765, 0.2755],\n",
       "         [0.6131, 0.8372, 0.3385, 0.6878, 0.2838],\n",
       "         [0.6081, 0.8347, 0.3449, 0.6851, 0.2826]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.scaled_dot_product_attention(a, b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample means and standard deviations for demonstration purposes\n",
    "means = [20, 15]  # Replace with your actual data\n",
    "stddevs = [5, 3]  # Replace with your actual data\n",
    "labels = ['P->V', 'V->P']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Drawing the bars\n",
    "bars = ax.bar(labels, means, yerr=stddevs, capsize=5, color=['blue', 'orange'])\n",
    "\n",
    "# Coordinates for the significance line\n",
    "x1, x2 = 0, 1  # Bar positions on the x-axis\n",
    "y, h, col = max(means) + 2, 2, 'black'  # Line height, line width, and color\n",
    "\n",
    "# Drawing the significance line\n",
    "ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "# Adding the significance stars\n",
    "ax.text((x1+x2)*.5, y+h, \"*\", ha='center', va='bottom', color=col, fontsize=12)\n",
    "\n",
    "# Add other plot details\n",
    "ax.set_ylabel('Average Attention')\n",
    "ax.set_title('Comparison of Attention Averages with Significance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming means and SEMs are already calculated and p_values contain the p-values for the comparisons\n",
    "use_labels = ['S->P', 'P->S', 'P->V', 'V->P']\n",
    "means = [np.random.rand() for _ in range(4)]  # Replace with actual means\n",
    "sems = [np.random.rand() for _ in range(4)]  # Replace with actual SEMs\n",
    "use_colors = ['blue', 'green', 'red', 'orange']\n",
    "p_values = [0.04, 0.03, 0.04]  # Example p-values, replace with actual p-values\n",
    "significance_threshold = 0.05\n",
    "signif_positions_pairs = [(0, 1), (1, 2), (2, 3)]  # Pairs of positions for each comparison\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Drawing the bars\n",
    "x = np.arange(len(use_labels))  # Label locations\n",
    "bars = ax.bar(x, means, yerr=1.96*np.array(sems), capsize=5, color=use_colors)\n",
    "\n",
    "# Adding significance annotations\n",
    "for (pos1, pos2), p_val in zip(signif_positions_pairs, p_values):\n",
    "    if p_val < significance_threshold:\n",
    "        # Draw lines\n",
    "        y_max = max(means[pos1] + 1.96*sems[pos1], means[pos2] + 1.96*sems[pos2])\n",
    "        h = y_max * 0.05  # 5% above the max for drawing the line\n",
    "        ax.plot([pos1, pos1, pos2, pos2], [y_max + h, y_max + 2*h, y_max + 2*h, y_max + h], lw=1.5, c='black')\n",
    "        \n",
    "        # Annotate significance\n",
    "        ax.text((pos1 + pos2) / 2, y_max + 2.5*h, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "# Add other plot details\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(use_labels)\n",
    "ax.set_ylabel('Average Attention')\n",
    "ax.set_title('Comparison of Attention Averages with Significance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'134'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_runs = [1, 3, 4]\n",
    "learned_runs = [str(num) for num in learned_runs]\n",
    "string_learned_runs = \"\".join(learned_runs)\n",
    "string_learned_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bob', 'Bob', 'Bob', 'Carol', 'Carol', 'Eve']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Carol', 'David', 'Eve']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Your list of IDs, with duplicates\n",
    "ids_of_interest = [2, 2, 2, 3, 3, 5]\n",
    "\n",
    "# Create a DataFrame from your list of IDs\n",
    "ids_df = pd.DataFrame(ids_of_interest, columns=['id'])[\"id\"]\n",
    "\n",
    "id_to_name = pd.Series(df['name'].values, index=df[\"id\"])\n",
    "names = list(map(id_to_name.get, ids_df))\n",
    "ids_df.map(id_to_name).tolist()\n",
    "# print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the resulting tensor: torch.Size([3, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create example tensors\n",
    "tensor_a = torch.randn(3, 4)  # Tensor A with shape (B, D) where B=3 and D=4\n",
    "tensor_b = torch.randn(3, 2, 4)  # Tensor B with shape (B, L, D) where B=3, L=2, D=4\n",
    "\n",
    "# Reshape tensor A from (B, D) to (B, 1, D)\n",
    "tensor_a_reshaped = tensor_a.unsqueeze(1).repeat_interleave(2, dim=-2)\n",
    "\n",
    "# Concatenate tensor_a_reshaped with tensor_b along the second dimension (dim=1)\n",
    "result_tensor = torch.cat((tensor_a_reshaped, tensor_b), dim=-1)\n",
    "\n",
    "# Check the shape of the resulting tensor\n",
    "print(\"Shape of the resulting tensor:\", result_tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
