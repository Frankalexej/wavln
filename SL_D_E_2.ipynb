{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English\n",
    "Version 1: In this version we make the model \"simple\": make the encoder RNN into normal RNN first and try to see the result.  \n",
    "Version 2: Learning is not very much. Following Dr Coupe's advice we try simpler model structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PhxLearner, SimplerPhxLearner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范用语；规定两种方式：全加载；按rec加载（舍弃了按chunk加载，处理起来更简单）\n",
    "# RandomPhoneDataset; AnnoPhoneDataset; AnnoSeqDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset that loads cutted wave files from disk and returns input-output pairs for\n",
    "    training autoencoder. \n",
    "    \n",
    "    Version 3: wav -> mel\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, load_dir, load_control_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the class by reading a CSV file and merging the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        The function reads the CSV file from the provided control path, extracts the \"rec\" and \"idx\" columns,\n",
    "        and concatenates the values from these columns using an underscore. It then appends the \".wav\" extension\n",
    "        to each of the merged strings and converts the merged pandas Series to a list, which is assigned to\n",
    "        the 'dataset' attribute of the class.\n",
    "\n",
    "        Args:\n",
    "        load_dir (str): The directory containing the files to load.\n",
    "        load_control_path (str): The path to the CSV file containing the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        Attributes:\n",
    "        dataset (list): A list of merged strings from the \"rec\" and \"idx\" columns, with the \".wav\" extension.\n",
    "        \"\"\"\n",
    "        control_file = pd.read_csv(load_control_path)\n",
    "        control_file = control_file[control_file['n_frames'] > 400]\n",
    "        control_file = control_file[control_file['duration'] <= 2.0]\n",
    "        \n",
    "        # Extract the \"rec\" and \"idx\" columns\n",
    "        rec_col = control_file['rec'].astype(str)\n",
    "        idx_col = control_file['idx'].astype(str).str.zfill(8)\n",
    "        \n",
    "        # Merge the two columns by concatenating the strings with '_' and append extension name\n",
    "        merged_col = rec_col + '_' + idx_col + \".wav\"\n",
    "        \n",
    "        self.dataset = merged_col.tolist()\n",
    "        self.load_dir = load_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: The number of input-output pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input_data, output_data) for the given index.\n",
    "\n",
    "        The function first checks if the provided index is a tensor, and if so, converts it to a list.\n",
    "        It then constructs the file path for the .wav file using the dataset attribute and the provided index.\n",
    "        The .wav file is loaded using torchaudio, and its data is normalized. If a transform is provided,\n",
    "        the data is transformed using the specified transform. Finally, the input_data and output_data are\n",
    "        set to the same data (creating a tuple), and the tuple is returned.\n",
    "\n",
    "        Args:\n",
    "        idx (int or torch.Tensor): The index of the desired data.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing input_data and output_data, both of which are the audio data\n",
    "               from the .wav file at the specified index.\n",
    "\n",
    "        Note: \n",
    "        This function assumes that the class has the following attributes:\n",
    "        - self.load_dir (str): The directory containing the .wav files.\n",
    "        - self.dataset (list): A list of .wav file names.\n",
    "        - self.transform (callable, optional): An optional transform to apply to the audio data.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        wav_name = os.path.join(self.load_dir,\n",
    "                                self.dataset[idx])\n",
    "        \n",
    "        data, sample_rate = torchaudio.load(wav_name, normalize=True)\n",
    "        if self.transform:\n",
    "            data = self.transform(data, sr=sample_rate)\n",
    "        \n",
    "        # # Prepare for possible in-out discrepencies in the future\n",
    "        # input_data = data\n",
    "        # output_data = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "def collate_fn(xx):\n",
    "    # only working for one data at the moment\n",
    "    batch_first = True\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=batch_first, padding_value=0)\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "\n",
    "class MyTransform(nn.Module): \n",
    "    def __init__(self, sample_rate, n_fft): \n",
    "        super().__init__()\n",
    "        # self.transform = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, n_mels=64)\n",
    "        # self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        # self.transform = torchaudio.transforms.MFCC(n_mfcc=13)\n",
    "    \n",
    "    def forward(self, waveform, sr=16000): \n",
    "        # extract mfcc\n",
    "        feature = torchaudio.compliance.kaldi.mfcc(waveform, sample_frequency=sr)\n",
    "\n",
    "        # add deltas\n",
    "        d1 = torchaudio.functional.compute_deltas(feature)\n",
    "        d2 = torchaudio.functional.compute_deltas(d1)\n",
    "        feature = torch.cat([feature, d1, d2], dim=-1)\n",
    "\n",
    "        # Apply normalization (CMVN)\n",
    "        eps = 1e-9\n",
    "        mean = feature.mean(0, keepdim=True)\n",
    "        std = feature.std(0, keepdim=True, unbiased=False)\n",
    "        # print(feature.shape)\n",
    "        # print(mean, std)\n",
    "        feature = (feature - mean) / (std + eps)\n",
    "\n",
    "        # mel_spec = self.transform(waveform)\n",
    "        # # mel_spec = self.to_db(mel_spec)\n",
    "        # mel_spec = mel_spec.squeeze()\n",
    "        # mel_spec = mel_spec.permute(1, 0) # (F, L) -> (L, F)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_DIM = 39\n",
    "OUTPUT_DIM = 13\n",
    "\n",
    "INTER_DIM_0 = 16\n",
    "INTER_DIM_1 = 8\n",
    "INTER_DIM_2 = 3\n",
    "# INTER_DIM_3 = 3\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "# model = PhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): OnlyRNNEncoder(\n",
       "    (rnn): LSTM(39, 3, batch_first=True)\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (act): Tanh()\n",
       "    (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): SimperRNNDecoder(\n",
       "    (rnn): LSTM(13, 3, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=13, bias=True)\n",
       "    )\n",
       "    (act): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "ts = str(get_timestamp())\n",
    "# ts = \"0623152604\"\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "# save_train1hist_name = \"train_hist_recon{}.hst\".format(ts)\n",
    "# save_train2hist_name = \"train_hist_reg{}.hst\".format(ts)\n",
    "\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)\n",
    "# save_val1hist_name = \"val_hist_recon{}.hst\".format(ts)\n",
    "# save_val2hist_name = \"val_hist_reg{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "# train_recon_losses = LossRecorder(model_save_dir + save_train1hist_name)\n",
    "# train_reg_losses = LossRecorder(model_save_dir + save_train2hist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "# valid_recon_losses = LossRecorder(model_save_dir + save_val1hist_name)\n",
    "# valid_reg_losses = LossRecorder(model_save_dir + save_val2hist_name)\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    # model_name = last_model_namec\n",
    "    model_name = \"PT_0623152604_29_full.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model = PhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "    \n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = PhoneDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "# this is to reduce the size of the dataset when the training power is not sufficient\n",
    "small_len = int(0.1 * len(ds))\n",
    "other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "valid_len = len(ds) - train_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss  1.073 in Step 0\n",
      "Training loss  1.068 in Step 10\n",
      "Training loss  1.049 in Step 20\n",
      "Training loss  1.042 in Step 30\n",
      "Training loss  1.036 in Step 40\n",
      "Training loss  1.029 in Step 50\n",
      "Training loss  1.025 in Step 60\n",
      "Training loss  1.019 in Step 70\n",
      "Training loss  1.013 in Step 80\n",
      "Training loss  1.011 in Step 90\n",
      "Training loss  1.007 in Step 100\n",
      "Training loss  1.006 in Step 110\n",
      "Training loss  1.004 in Step 120\n",
      "Training loss  1.003 in Step 130\n",
      "Training loss  1.003 in Step 140\n",
      "Training loss  1.002 in Step 150\n",
      "Training loss  1.004 in Step 160\n",
      "Training loss  1.002 in Step 170\n",
      "※※※Training loss  1.020※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.002 in Step 0\n",
      "※※※Valid loss  1.001※※※\n",
      "Epoch 1\n",
      "Training loss  1.002 in Step 0\n",
      "Training loss  1.001 in Step 10\n",
      "Training loss  1.001 in Step 20\n",
      "Training loss  1.001 in Step 30\n",
      "Training loss  1.001 in Step 40\n",
      "Training loss  1.001 in Step 50\n",
      "Training loss  1.001 in Step 60\n",
      "Training loss  1.001 in Step 70\n",
      "Training loss  1.001 in Step 80\n",
      "Training loss  1.001 in Step 90\n",
      "Training loss  1.001 in Step 100\n",
      "Training loss  1.001 in Step 110\n",
      "Training loss  1.000 in Step 120\n",
      "Training loss  1.001 in Step 130\n",
      "Training loss  1.000 in Step 140\n",
      "Training loss  1.000 in Step 150\n",
      "Training loss  1.000 in Step 160\n",
      "Training loss  1.000 in Step 170\n",
      "※※※Training loss  1.001※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.000 in Step 0\n",
      "※※※Valid loss  1.000※※※\n",
      "Epoch 2\n",
      "Training loss  1.000 in Step 0\n",
      "Training loss  1.000 in Step 10\n",
      "Training loss  1.000 in Step 20\n",
      "Training loss  1.000 in Step 30\n",
      "Training loss  1.000 in Step 40\n",
      "Training loss  1.000 in Step 50\n",
      "Training loss  1.000 in Step 60\n",
      "Training loss  1.000 in Step 70\n",
      "Training loss  1.000 in Step 80\n",
      "Training loss  1.000 in Step 90\n",
      "Training loss  1.000 in Step 100\n",
      "Training loss  1.000 in Step 110\n",
      "Training loss  1.000 in Step 120\n",
      "Training loss  1.000 in Step 130\n",
      "Training loss  1.000 in Step 140\n",
      "Training loss  1.000 in Step 150\n",
      "Training loss  0.999 in Step 160\n",
      "Training loss  1.000 in Step 170\n",
      "※※※Training loss  1.000※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.000 in Step 0\n",
      "※※※Valid loss  1.000※※※\n",
      "Epoch 3\n",
      "Training loss  1.000 in Step 0\n",
      "Training loss  0.999 in Step 10\n",
      "Training loss  0.999 in Step 20\n",
      "Training loss  1.000 in Step 30\n",
      "Training loss  0.999 in Step 40\n",
      "Training loss  1.000 in Step 50\n",
      "Training loss  1.000 in Step 60\n",
      "Training loss  1.000 in Step 70\n",
      "Training loss  1.000 in Step 80\n",
      "Training loss  1.000 in Step 90\n",
      "Training loss  1.000 in Step 100\n",
      "Training loss  1.000 in Step 110\n",
      "Training loss  1.000 in Step 120\n",
      "Training loss  1.000 in Step 130\n",
      "Training loss  1.000 in Step 140\n",
      "Training loss  0.999 in Step 150\n",
      "Training loss  1.000 in Step 160\n",
      "Training loss  1.000 in Step 170\n",
      "※※※Training loss  1.000※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.000 in Step 0\n",
      "※※※Valid loss  1.000※※※\n",
      "Epoch 4\n",
      "Training loss  0.999 in Step 0\n",
      "Training loss  1.000 in Step 10\n",
      "Training loss  1.000 in Step 20\n",
      "Training loss  1.000 in Step 30\n",
      "Training loss  1.000 in Step 40\n",
      "Training loss  1.000 in Step 50\n",
      "Training loss  1.000 in Step 60\n",
      "Training loss  1.000 in Step 70\n",
      "Training loss  1.000 in Step 80\n",
      "Training loss  0.999 in Step 90\n",
      "Training loss  1.000 in Step 100\n",
      "Training loss  1.000 in Step 110\n",
      "Training loss  0.999 in Step 120\n",
      "Training loss  1.000 in Step 130\n",
      "Training loss  0.999 in Step 140\n",
      "Training loss  1.000 in Step 150\n",
      "Training loss  0.999 in Step 160\n",
      "Training loss  0.999 in Step 170\n",
      "※※※Training loss  1.000※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.000 in Step 0\n",
      "※※※Valid loss  1.000※※※\n",
      "Epoch 5\n",
      "Training loss  0.999 in Step 0\n",
      "Training loss  1.000 in Step 10\n",
      "Training loss  1.000 in Step 20\n",
      "Training loss  1.000 in Step 30\n",
      "Training loss  1.000 in Step 40\n",
      "Training loss  0.999 in Step 50\n",
      "Training loss  1.000 in Step 60\n",
      "Training loss  1.000 in Step 70\n",
      "Training loss  1.000 in Step 80\n",
      "Training loss  1.000 in Step 90\n",
      "Training loss  1.000 in Step 100\n",
      "Training loss  1.000 in Step 110\n",
      "Training loss  1.000 in Step 120\n",
      "Training loss  0.999 in Step 130\n",
      "Training loss  1.000 in Step 140\n",
      "Training loss  1.000 in Step 150\n",
      "Training loss  0.999 in Step 160\n",
      "Training loss  0.999 in Step 170\n",
      "※※※Training loss  1.000※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.000 in Step 0\n",
      "※※※Valid loss  1.000※※※\n",
      "Epoch 6\n",
      "Training loss  0.999 in Step 0\n",
      "Training loss  1.000 in Step 10\n",
      "Training loss  0.998 in Step 20\n",
      "Training loss  1.000 in Step 30\n",
      "Training loss  0.999 in Step 40\n",
      "Training loss  0.999 in Step 50\n",
      "Training loss  0.999 in Step 60\n",
      "Training loss  0.999 in Step 70\n",
      "Training loss  0.999 in Step 80\n",
      "Training loss  0.999 in Step 90\n",
      "Training loss  0.998 in Step 100\n",
      "Training loss  0.998 in Step 110\n",
      "Training loss  0.998 in Step 120\n",
      "Training loss  0.998 in Step 130\n",
      "Training loss  1.000 in Step 140\n",
      "Training loss  0.999 in Step 150\n",
      "Training loss  0.997 in Step 160\n",
      "Training loss  1.000 in Step 170\n",
      "※※※Training loss  0.999※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.999 in Step 0\n",
      "※※※Valid loss  0.998※※※\n",
      "Epoch 7\n",
      "Training loss  0.999 in Step 0\n",
      "Training loss  0.998 in Step 10\n",
      "Training loss  0.997 in Step 20\n",
      "Training loss  0.997 in Step 30\n",
      "Training loss  0.999 in Step 40\n",
      "Training loss  0.997 in Step 50\n",
      "Training loss  0.997 in Step 60\n",
      "Training loss  0.995 in Step 70\n",
      "Training loss  0.996 in Step 80\n",
      "Training loss  0.997 in Step 90\n",
      "Training loss  0.992 in Step 100\n",
      "Training loss  0.998 in Step 110\n",
      "Training loss  0.995 in Step 120\n",
      "Training loss  0.993 in Step 130\n",
      "Training loss  0.995 in Step 140\n",
      "Training loss  0.994 in Step 150\n",
      "Training loss  0.998 in Step 160\n",
      "Training loss  0.993 in Step 170\n",
      "※※※Training loss  0.995※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.996 in Step 0\n",
      "※※※Valid loss  0.994※※※\n",
      "Epoch 8\n",
      "Training loss  0.995 in Step 0\n",
      "Training loss  0.993 in Step 10\n",
      "Training loss  0.994 in Step 20\n",
      "Training loss  0.994 in Step 30\n",
      "Training loss  0.992 in Step 40\n",
      "Training loss  0.994 in Step 50\n",
      "Training loss  0.994 in Step 60\n",
      "Training loss  0.990 in Step 70\n",
      "Training loss  0.995 in Step 80\n",
      "Training loss  0.990 in Step 90\n",
      "Training loss  0.996 in Step 100\n",
      "Training loss  0.993 in Step 110\n",
      "Training loss  0.993 in Step 120\n",
      "Training loss  0.991 in Step 130\n",
      "Training loss  0.993 in Step 140\n",
      "Training loss  0.986 in Step 150\n",
      "Training loss  0.989 in Step 160\n",
      "Training loss  0.992 in Step 170\n",
      "※※※Training loss  0.993※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.994 in Step 0\n",
      "※※※Valid loss  0.992※※※\n",
      "Epoch 9\n",
      "Training loss  0.992 in Step 0\n",
      "Training loss  0.990 in Step 10\n",
      "Training loss  0.995 in Step 20\n",
      "Training loss  0.992 in Step 30\n",
      "Training loss  0.992 in Step 40\n",
      "Training loss  0.990 in Step 50\n",
      "Training loss  0.994 in Step 60\n",
      "Training loss  0.988 in Step 70\n",
      "Training loss  0.992 in Step 80\n",
      "Training loss  0.992 in Step 90\n",
      "Training loss  0.988 in Step 100\n",
      "Training loss  0.994 in Step 110\n",
      "Training loss  0.987 in Step 120\n",
      "Training loss  0.989 in Step 130\n",
      "Training loss  0.995 in Step 140\n",
      "Training loss  0.990 in Step 150\n",
      "Training loss  0.991 in Step 160\n",
      "Training loss  0.990 in Step 170\n",
      "※※※Training loss  0.991※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.993 in Step 0\n",
      "※※※Valid loss  0.991※※※\n",
      "Epoch 10\n",
      "Training loss  0.989 in Step 0\n",
      "Training loss  0.996 in Step 10\n",
      "Training loss  0.991 in Step 20\n",
      "Training loss  0.987 in Step 30\n",
      "Training loss  0.993 in Step 40\n",
      "Training loss  0.989 in Step 50\n",
      "Training loss  0.990 in Step 60\n",
      "Training loss  0.993 in Step 70\n",
      "Training loss  0.987 in Step 80\n",
      "Training loss  0.991 in Step 90\n",
      "Training loss  0.992 in Step 100\n",
      "Training loss  0.990 in Step 110\n",
      "Training loss  0.997 in Step 120\n",
      "Training loss  0.989 in Step 130\n",
      "Training loss  0.990 in Step 140\n",
      "Training loss  0.985 in Step 150\n",
      "Training loss  0.987 in Step 160\n",
      "Training loss  0.988 in Step 170\n",
      "※※※Training loss  0.990※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.992 in Step 0\n",
      "※※※Valid loss  0.990※※※\n",
      "Epoch 11\n",
      "Training loss  0.991 in Step 0\n",
      "Training loss  0.989 in Step 10\n",
      "Training loss  0.987 in Step 20\n",
      "Training loss  0.992 in Step 30\n",
      "Training loss  0.987 in Step 40\n",
      "Training loss  0.991 in Step 50\n",
      "Training loss  0.986 in Step 60\n",
      "Training loss  0.988 in Step 70\n",
      "Training loss  0.997 in Step 80\n",
      "Training loss  0.986 in Step 90\n",
      "Training loss  0.989 in Step 100\n",
      "Training loss  0.986 in Step 110\n",
      "Training loss  0.981 in Step 120\n",
      "Training loss  0.984 in Step 130\n",
      "Training loss  0.989 in Step 140\n",
      "Training loss  0.977 in Step 150\n",
      "Training loss  0.982 in Step 160\n",
      "Training loss  0.981 in Step 170\n",
      "※※※Training loss  0.987※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.984 in Step 0\n",
      "※※※Valid loss  0.984※※※\n",
      "Epoch 12\n",
      "Training loss  0.983 in Step 0\n",
      "Training loss  0.979 in Step 10\n",
      "Training loss  0.983 in Step 20\n",
      "Training loss  0.974 in Step 30\n",
      "Training loss  0.982 in Step 40\n",
      "Training loss  0.983 in Step 50\n",
      "Training loss  0.977 in Step 60\n",
      "Training loss  0.981 in Step 70\n",
      "Training loss  0.984 in Step 80\n",
      "Training loss  0.976 in Step 90\n",
      "Training loss  0.978 in Step 100\n",
      "Training loss  0.986 in Step 110\n",
      "Training loss  0.974 in Step 120\n",
      "Training loss  0.972 in Step 130\n",
      "Training loss  0.981 in Step 140\n",
      "Training loss  0.975 in Step 150\n",
      "Training loss  0.985 in Step 160\n",
      "Training loss  0.975 in Step 170\n",
      "※※※Training loss  0.980※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.975 in Step 0\n",
      "※※※Valid loss  0.978※※※\n",
      "Epoch 13\n",
      "Training loss  0.983 in Step 0\n",
      "Training loss  0.975 in Step 10\n",
      "Training loss  0.979 in Step 20\n",
      "Training loss  0.980 in Step 30\n",
      "Training loss  0.977 in Step 40\n",
      "Training loss  0.977 in Step 50\n",
      "Training loss  0.980 in Step 60\n",
      "Training loss  0.979 in Step 70\n",
      "Training loss  0.978 in Step 80\n",
      "Training loss  0.975 in Step 90\n",
      "Training loss  0.977 in Step 100\n",
      "Training loss  0.975 in Step 110\n",
      "Training loss  0.976 in Step 120\n",
      "Training loss  0.973 in Step 130\n",
      "Training loss  0.968 in Step 140\n",
      "Training loss  0.974 in Step 150\n",
      "Training loss  0.973 in Step 160\n",
      "Training loss  0.966 in Step 170\n",
      "※※※Training loss  0.977※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.971 in Step 0\n",
      "※※※Valid loss  0.976※※※\n",
      "Epoch 14\n",
      "Training loss  0.981 in Step 0\n",
      "Training loss  0.976 in Step 10\n",
      "Training loss  0.977 in Step 20\n",
      "Training loss  0.976 in Step 30\n",
      "Training loss  0.976 in Step 40\n",
      "Training loss  0.970 in Step 50\n",
      "Training loss  0.971 in Step 60\n",
      "Training loss  0.969 in Step 70\n",
      "Training loss  0.978 in Step 80\n",
      "Training loss  0.970 in Step 90\n",
      "Training loss  0.967 in Step 100\n",
      "Training loss  0.970 in Step 110\n",
      "Training loss  0.968 in Step 120\n",
      "Training loss  0.971 in Step 130\n",
      "Training loss  0.975 in Step 140\n",
      "Training loss  0.970 in Step 150\n",
      "Training loss  0.970 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.974※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.966 in Step 0\n",
      "※※※Valid loss  0.975※※※\n",
      "Epoch 15\n",
      "Training loss  0.972 in Step 0\n",
      "Training loss  0.975 in Step 10\n",
      "Training loss  0.975 in Step 20\n",
      "Training loss  0.977 in Step 30\n",
      "Training loss  0.971 in Step 40\n",
      "Training loss  0.977 in Step 50\n",
      "Training loss  0.977 in Step 60\n",
      "Training loss  0.969 in Step 70\n",
      "Training loss  0.972 in Step 80\n",
      "Training loss  0.982 in Step 90\n",
      "Training loss  0.973 in Step 100\n",
      "Training loss  0.965 in Step 110\n",
      "Training loss  0.973 in Step 120\n",
      "Training loss  0.972 in Step 130\n",
      "Training loss  0.969 in Step 140\n",
      "Training loss  0.974 in Step 150\n",
      "Training loss  0.977 in Step 160\n",
      "Training loss  0.976 in Step 170\n",
      "※※※Training loss  0.974※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.965 in Step 0\n",
      "※※※Valid loss  0.972※※※\n",
      "Epoch 16\n",
      "Training loss  0.972 in Step 0\n",
      "Training loss  0.971 in Step 10\n",
      "Training loss  0.970 in Step 20\n",
      "Training loss  0.973 in Step 30\n",
      "Training loss  0.972 in Step 40\n",
      "Training loss  0.969 in Step 50\n",
      "Training loss  0.964 in Step 60\n",
      "Training loss  0.970 in Step 70\n",
      "Training loss  0.963 in Step 80\n",
      "Training loss  0.975 in Step 90\n",
      "Training loss  0.972 in Step 100\n",
      "Training loss  0.962 in Step 110\n",
      "Training loss  0.975 in Step 120\n",
      "Training loss  0.969 in Step 130\n",
      "Training loss  0.974 in Step 140\n",
      "Training loss  0.971 in Step 150\n",
      "Training loss  0.970 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.972※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.962 in Step 0\n",
      "※※※Valid loss  0.971※※※\n",
      "Epoch 17\n",
      "Training loss  0.971 in Step 0\n",
      "Training loss  0.973 in Step 10\n",
      "Training loss  0.973 in Step 20\n",
      "Training loss  0.969 in Step 30\n",
      "Training loss  0.967 in Step 40\n",
      "Training loss  0.972 in Step 50\n",
      "Training loss  0.973 in Step 60\n",
      "Training loss  0.975 in Step 70\n",
      "Training loss  0.971 in Step 80\n",
      "Training loss  0.976 in Step 90\n",
      "Training loss  0.973 in Step 100\n",
      "Training loss  0.971 in Step 110\n",
      "Training loss  0.974 in Step 120\n",
      "Training loss  0.971 in Step 130\n",
      "Training loss  0.969 in Step 140\n",
      "Training loss  0.968 in Step 150\n",
      "Training loss  0.971 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.971※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.963 in Step 0\n",
      "※※※Valid loss  0.972※※※\n",
      "Epoch 18\n",
      "Training loss  0.963 in Step 0\n",
      "Training loss  0.971 in Step 10\n",
      "Training loss  0.971 in Step 20\n",
      "Training loss  0.974 in Step 30\n",
      "Training loss  0.970 in Step 40\n",
      "Training loss  0.970 in Step 50\n",
      "Training loss  0.971 in Step 60\n",
      "Training loss  0.964 in Step 70\n",
      "Training loss  0.963 in Step 80\n",
      "Training loss  0.977 in Step 90\n",
      "Training loss  0.970 in Step 100\n",
      "Training loss  0.975 in Step 110\n",
      "Training loss  0.975 in Step 120\n",
      "Training loss  0.983 in Step 130\n",
      "Training loss  0.972 in Step 140\n",
      "Training loss  0.972 in Step 150\n",
      "Training loss  0.979 in Step 160\n",
      "Training loss  0.970 in Step 170\n",
      "※※※Training loss  0.971※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.961 in Step 0\n",
      "※※※Valid loss  0.971※※※\n",
      "Epoch 19\n",
      "Training loss  0.975 in Step 0\n",
      "Training loss  0.969 in Step 10\n",
      "Training loss  0.972 in Step 20\n",
      "Training loss  0.969 in Step 30\n",
      "Training loss  0.972 in Step 40\n",
      "Training loss  0.973 in Step 50\n",
      "Training loss  0.969 in Step 60\n",
      "Training loss  0.975 in Step 70\n",
      "Training loss  0.966 in Step 80\n",
      "Training loss  0.971 in Step 90\n",
      "Training loss  0.968 in Step 100\n",
      "Training loss  0.969 in Step 110\n",
      "Training loss  0.966 in Step 120\n",
      "Training loss  0.967 in Step 130\n",
      "Training loss  0.968 in Step 140\n",
      "Training loss  0.969 in Step 150\n",
      "Training loss  0.971 in Step 160\n",
      "Training loss  0.977 in Step 170\n",
      "※※※Training loss  0.970※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.961 in Step 0\n",
      "※※※Valid loss  0.970※※※\n",
      "Epoch 20\n",
      "Training loss  0.978 in Step 0\n",
      "Training loss  0.968 in Step 10\n",
      "Training loss  0.970 in Step 20\n",
      "Training loss  0.972 in Step 30\n",
      "Training loss  0.964 in Step 40\n",
      "Training loss  0.971 in Step 50\n",
      "Training loss  0.973 in Step 60\n",
      "Training loss  0.969 in Step 70\n",
      "Training loss  0.971 in Step 80\n",
      "Training loss  0.965 in Step 90\n",
      "Training loss  0.971 in Step 100\n",
      "Training loss  0.976 in Step 110\n",
      "Training loss  0.972 in Step 120\n",
      "Training loss  0.977 in Step 130\n",
      "Training loss  0.972 in Step 140\n",
      "Training loss  0.972 in Step 150\n",
      "Training loss  0.972 in Step 160\n",
      "Training loss  0.968 in Step 170\n",
      "※※※Training loss  0.970※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.960 in Step 0\n",
      "※※※Valid loss  0.969※※※\n",
      "Epoch 21\n",
      "Training loss  0.963 in Step 0\n",
      "Training loss  0.970 in Step 10\n",
      "Training loss  0.970 in Step 20\n",
      "Training loss  0.967 in Step 30\n",
      "Training loss  0.974 in Step 40\n",
      "Training loss  0.972 in Step 50\n",
      "Training loss  0.967 in Step 60\n",
      "Training loss  0.969 in Step 70\n",
      "Training loss  0.965 in Step 80\n",
      "Training loss  0.964 in Step 90\n",
      "Training loss  0.967 in Step 100\n",
      "Training loss  0.966 in Step 110\n",
      "Training loss  0.968 in Step 120\n",
      "Training loss  0.968 in Step 130\n",
      "Training loss  0.968 in Step 140\n",
      "Training loss  0.966 in Step 150\n",
      "Training loss  0.970 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.969※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.959 in Step 0\n",
      "※※※Valid loss  0.969※※※\n",
      "Epoch 22\n",
      "Training loss  0.969 in Step 0\n",
      "Training loss  0.965 in Step 10\n",
      "Training loss  0.966 in Step 20\n",
      "Training loss  0.965 in Step 30\n",
      "Training loss  0.965 in Step 40\n",
      "Training loss  0.968 in Step 50\n",
      "Training loss  0.970 in Step 60\n",
      "Training loss  0.968 in Step 70\n",
      "Training loss  0.965 in Step 80\n",
      "Training loss  0.964 in Step 90\n",
      "Training loss  0.966 in Step 100\n",
      "Training loss  0.972 in Step 110\n",
      "Training loss  0.969 in Step 120\n",
      "Training loss  0.969 in Step 130\n",
      "Training loss  0.958 in Step 140\n",
      "Training loss  0.963 in Step 150\n",
      "Training loss  0.971 in Step 160\n",
      "Training loss  0.977 in Step 170\n",
      "※※※Training loss  0.969※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.958 in Step 0\n",
      "※※※Valid loss  0.968※※※\n",
      "Epoch 23\n",
      "Training loss  0.971 in Step 0\n",
      "Training loss  0.965 in Step 10\n",
      "Training loss  0.969 in Step 20\n",
      "Training loss  0.969 in Step 30\n",
      "Training loss  0.972 in Step 40\n",
      "Training loss  0.979 in Step 50\n",
      "Training loss  0.964 in Step 60\n",
      "Training loss  0.968 in Step 70\n",
      "Training loss  0.969 in Step 80\n",
      "Training loss  0.973 in Step 90\n",
      "Training loss  0.976 in Step 100\n",
      "Training loss  0.965 in Step 110\n",
      "Training loss  0.971 in Step 120\n",
      "Training loss  0.971 in Step 130\n",
      "Training loss  0.977 in Step 140\n",
      "Training loss  0.968 in Step 150\n",
      "Training loss  0.963 in Step 160\n",
      "Training loss  0.977 in Step 170\n",
      "※※※Training loss  0.969※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.959 in Step 0\n",
      "※※※Valid loss  0.968※※※\n",
      "Epoch 24\n",
      "Training loss  0.970 in Step 0\n",
      "Training loss  0.973 in Step 10\n",
      "Training loss  0.971 in Step 20\n",
      "Training loss  0.965 in Step 30\n",
      "Training loss  0.964 in Step 40\n",
      "Training loss  0.974 in Step 50\n",
      "Training loss  0.962 in Step 60\n",
      "Training loss  0.962 in Step 70\n",
      "Training loss  0.973 in Step 80\n",
      "Training loss  0.961 in Step 90\n",
      "Training loss  0.968 in Step 100\n",
      "Training loss  0.972 in Step 110\n",
      "Training loss  0.968 in Step 120\n",
      "Training loss  0.970 in Step 130\n",
      "Training loss  0.966 in Step 140\n",
      "Training loss  0.964 in Step 150\n",
      "Training loss  0.972 in Step 160\n",
      "Training loss  0.971 in Step 170\n",
      "※※※Training loss  0.968※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.957 in Step 0\n",
      "※※※Valid loss  0.968※※※\n",
      "Epoch 25\n",
      "Training loss  0.967 in Step 0\n",
      "Training loss  0.972 in Step 10\n",
      "Training loss  0.961 in Step 20\n",
      "Training loss  0.965 in Step 30\n",
      "Training loss  0.974 in Step 40\n",
      "Training loss  0.959 in Step 50\n",
      "Training loss  0.969 in Step 60\n",
      "Training loss  0.963 in Step 70\n",
      "Training loss  0.963 in Step 80\n",
      "Training loss  0.965 in Step 90\n",
      "Training loss  0.962 in Step 100\n",
      "Training loss  0.963 in Step 110\n",
      "Training loss  0.973 in Step 120\n",
      "Training loss  0.961 in Step 130\n",
      "Training loss  0.973 in Step 140\n",
      "Training loss  0.975 in Step 150\n",
      "Training loss  0.966 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.967※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.956 in Step 0\n",
      "※※※Valid loss  0.967※※※\n",
      "Epoch 26\n",
      "Training loss  0.973 in Step 0\n",
      "Training loss  0.962 in Step 10\n",
      "Training loss  0.973 in Step 20\n",
      "Training loss  0.965 in Step 30\n",
      "Training loss  0.963 in Step 40\n",
      "Training loss  0.968 in Step 50\n",
      "Training loss  0.971 in Step 60\n",
      "Training loss  0.979 in Step 70\n",
      "Training loss  0.964 in Step 80\n",
      "Training loss  0.965 in Step 90\n",
      "Training loss  0.972 in Step 100\n",
      "Training loss  0.968 in Step 110\n",
      "Training loss  0.969 in Step 120\n",
      "Training loss  0.963 in Step 130\n",
      "Training loss  0.968 in Step 140\n",
      "Training loss  0.968 in Step 150\n",
      "Training loss  0.966 in Step 160\n",
      "Training loss  0.969 in Step 170\n",
      "※※※Training loss  0.967※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.956 in Step 0\n",
      "※※※Valid loss  0.967※※※\n",
      "Epoch 27\n",
      "Training loss  0.964 in Step 0\n",
      "Training loss  0.965 in Step 10\n",
      "Training loss  0.964 in Step 20\n",
      "Training loss  0.966 in Step 30\n",
      "Training loss  0.965 in Step 40\n",
      "Training loss  0.965 in Step 50\n",
      "Training loss  0.964 in Step 60\n",
      "Training loss  0.970 in Step 70\n",
      "Training loss  0.964 in Step 80\n",
      "Training loss  0.961 in Step 90\n",
      "Training loss  0.970 in Step 100\n",
      "Training loss  0.964 in Step 110\n",
      "Training loss  0.970 in Step 120\n",
      "Training loss  0.964 in Step 130\n",
      "Training loss  0.970 in Step 140\n",
      "Training loss  0.974 in Step 150\n",
      "Training loss  0.965 in Step 160\n",
      "Training loss  0.965 in Step 170\n",
      "※※※Training loss  0.966※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.956 in Step 0\n",
      "※※※Valid loss  0.966※※※\n",
      "Epoch 28\n",
      "Training loss  0.965 in Step 0\n",
      "Training loss  0.969 in Step 10\n",
      "Training loss  0.964 in Step 20\n",
      "Training loss  0.961 in Step 30\n",
      "Training loss  0.966 in Step 40\n",
      "Training loss  0.970 in Step 50\n",
      "Training loss  0.966 in Step 60\n",
      "Training loss  0.967 in Step 70\n",
      "Training loss  0.963 in Step 80\n",
      "Training loss  0.961 in Step 90\n",
      "Training loss  0.971 in Step 100\n",
      "Training loss  0.965 in Step 110\n",
      "Training loss  0.966 in Step 120\n",
      "Training loss  0.966 in Step 130\n",
      "Training loss  0.966 in Step 140\n",
      "Training loss  0.971 in Step 150\n",
      "Training loss  0.963 in Step 160\n",
      "Training loss  0.964 in Step 170\n",
      "※※※Training loss  0.966※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.956 in Step 0\n",
      "※※※Valid loss  0.967※※※\n",
      "Epoch 29\n",
      "Training loss  0.970 in Step 0\n",
      "Training loss  0.967 in Step 10\n",
      "Training loss  0.965 in Step 20\n",
      "Training loss  0.966 in Step 30\n",
      "Training loss  0.967 in Step 40\n",
      "Training loss  0.966 in Step 50\n",
      "Training loss  0.964 in Step 60\n",
      "Training loss  0.967 in Step 70\n",
      "Training loss  0.969 in Step 80\n",
      "Training loss  0.969 in Step 90\n",
      "Training loss  0.968 in Step 100\n",
      "Training loss  0.968 in Step 110\n",
      "Training loss  0.968 in Step 120\n",
      "Training loss  0.976 in Step 130\n",
      "Training loss  0.971 in Step 140\n",
      "Training loss  0.978 in Step 150\n",
      "Training loss  0.963 in Step 160\n",
      "Training loss  0.962 in Step 170\n",
      "※※※Training loss  0.966※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.955 in Step 0\n",
      "※※※Valid loss  0.966※※※\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "train_losses.save()\n",
    "\n",
    "valid_losses.save()\n",
    "\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f04390911d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPWgjpid7PR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
