{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melify\n",
    "At the moment, because it is rather complecated, we shall first take the test set and get the mean \n",
    "and variance. In this way we can proceed without conducting any preprocessing. The only change is that we will fix the normalization here and pass in the data for all trainings and testings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, because at the moment I haven't found a good way to preserve good variance if using online methods, I will use the mean and variance as a whole, but from test set here to get all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_dataset import TargetVowelDatasetManualNorm\n",
    "from model_dataset import MelSpecTransformDBNoNorm as TheTransform\n",
    "from paths import *\n",
    "from model_dataset import Normalizer, DeNormalizer, TokenMap\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "LOADER_WORKER = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set = pd.read_csv(os.path.join(src_, \"phi-T-guide.csv\"))\n",
    "st_set = pd.read_csv(os.path.join(src_, \"phi-ST-guide.csv\"))\n",
    "integrated = pd.concat([t_set, st_set], ignore_index=True, sort=False)\n",
    "integrated = integrated.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrans = TheTransform(sample_rate=REC_SAMPLE_RATE, \n",
    "                    n_fft=N_FFT, n_mels=N_MELS)\n",
    "\n",
    "with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "    # Load the object from the file\n",
    "    mylist = pickle.load(file)\n",
    "    mylist = [\"BLANK\"] + mylist\n",
    "    mylist = mylist + [\"SIL\"]\n",
    "\n",
    "# Now you can use the loaded object\n",
    "mymap = TokenMap(mylist)\n",
    "\n",
    "mynorm = Normalizer(Normalizer.norm_mvn_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TargetVowelDatasetManualNorm(\n",
    "    src_dir=train_cut_phone_, guide_=integrated, \n",
    "    mapper=mymap, transform=mytrans, normalizer=mynorm, \n",
    "    noise_fixlength=False, noise_amplitude_scale=0.004, mv_config=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
