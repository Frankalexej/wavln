{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English - Testing Session -Plots\n",
    "In this session, we will look into the working status of our LSTM AE and plot:   \n",
    "- the progression plot (how hid_rs are progressing along the timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from loss import *\n",
    "from model import SimplerPhxLearner\n",
    "from seqinfo_dataset import SeqDatasetInfo, collate_fn, MyTransform\n",
    "from my_dataset import DS_Tools\n",
    "from reshandler import EncoderResHandler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "INPUT_DIM = 39\n",
    "OUTPUT_DIM = 13\n",
    "\n",
    "INTER_DIM_0 = 64\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 3\n",
    "# INTER_DIM_3 = 3\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ts = \"0908015948\"\n",
    "stop_epoch = \"248\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): RLEncoder(\n",
       "    (rnn): LSTM(39, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RALDecoder(\n",
       "    (rnn): LSTM(13, 3, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=13, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw_name = \"PT_{}_{}_full\".format(load_ts, stop_epoch)\n",
    "model_name = model_raw_name + \".pt\"\n",
    "model_path = os.path.join(model_save_dir, model_name)\n",
    "state = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): RLEncoder(\n",
       "    (rnn): LSTM(39, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RALDecoder(\n",
       "    (rnn): LSTM(13, 3, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=13, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = SeqDatasetInfo(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(load_ts)))\n",
    "\n",
    "valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "\n",
    "# # this is to reduce the size of the dataset when the training power is not sufficient\n",
    "# small_len = int(0.002 * len(valid_ds))\n",
    "# other_len = len(valid_ds) - small_len\n",
    "\n",
    "# # # Randomly split the dataset into train and validation sets\n",
    "# valid_ds, other_ds = random_split(valid_ds, [small_len, other_len])\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneOut2ProgFrame(oneOut): \n",
    "    # oneOut is of tensor of shape (L, D)\n",
    "    df = pd.DataFrame(oneOut, columns=[\"dim_0\", \"dim_1\", \"dim_2\"])\n",
    "    df[\"timestep\"] = df.index\n",
    "    df = df[[\"timestep\", \"dim_0\", \"dim_1\", \"dim_2\"]]\n",
    "    return df\n",
    "def minmax(arr, a=-1, b=1): \n",
    "    min = arr.min()\n",
    "    max = arr.max()\n",
    "    return (b - a) * ((arr - min) / (max - min)) + a\n",
    "def operate_on(arr): \n",
    "    # return minmax(arr)\n",
    "    return arr\n",
    "def framify(these_hids): \n",
    "    # these are token categories to be included\n",
    "    # these hids are the corresponding hids\n",
    "    # these numtags are the corresponding tags, named using indices in these\n",
    "    # these_hids = st.zscore(these_hids, axis=0)\n",
    "    df = pd.DataFrame(data=these_hids)\n",
    "    # df = df.rename(columns={0: \"dim_0\", 1: \"dim_1\", 2: \"dim_2\"})\n",
    "    df['dim_0_norm'] = operate_on(df['dim_0'])\n",
    "    df['dim_1_norm'] = operate_on(df['dim_1'])\n",
    "    df['dim_2_norm'] = operate_on(df['dim_2'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3dtrajectory(X): \n",
    "    config = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        'filename': 'custom_image',\n",
    "        'height': 1280,\n",
    "        'width': 1280,\n",
    "        'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "    }\n",
    "\n",
    "    fig = px.line_3d(framify(X), x=\"dim_0_norm\", y=\"dim_1_norm\", z=\"dim_2_norm\", \n",
    "                     hover_data=[\"timestep\"], markers=True)\n",
    "    fig.update_traces(marker=dict(size=2, color=\"red\"))\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        yaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        zaxis = dict(nticks=8, range=[-1,1],),),)\n",
    "    # fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "    # fig.update_layout(legend_title_text='Phone')\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0,\n",
    "            y=1,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=36,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            # bgcolor=\"LightSteelBlue\",\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    )\n",
    "    camera = dict(\n",
    "        eye=dict(x=0., y=0., z=2.5)\n",
    "    )\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    html_plot = fig.to_html(full_html=False, config=config)\n",
    "    # fig.show(config=config)\n",
    "    return html_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(htmlplot, info_rec, info_idx, info_token, info_produce_segs, model_serialnum=\"\"): \n",
    "    save_html_path = os.path.join(word_plot_path, \"{}_{}_{}_{}.html\".format(model_serialnum, info_rec, info_idx, info_token).zfill(8))\n",
    "    with open(save_html_path, \"w\") as f: \n",
    "        f.write('<meta charset=\"UTF-8\">')\n",
    "        f.write(\"<h3>Rec: {}</h3>\".format(\"{}_{}\".format(info_rec, info_idx).zfill(8)))\n",
    "        f.write(\"<h3>Token: {}</h3>\".format(info_token))\n",
    "        f.write(\"<h3>Produced Segments: {}</h3>\".format(info_produce_segs))\n",
    "        f.write(\"<hr>\")\n",
    "        f.write(htmlplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def infer(model_num=\"\"): \n",
    "    model.eval()\n",
    "    reshandler = EncoderResHandler(data_dir=word_plot_res_path, info_dir=word_plot_info_path)\n",
    "\n",
    "    for idx, (x, x_lens, info, info_rec, info_idx, info_token) in enumerate(valid_loader):\n",
    "        info = info[0]\n",
    "        info_rec = info_rec[0]\n",
    "        info_idx = info_idx[0]\n",
    "        info_token = info_token[0]\n",
    "        reshandler.file_prefix = \"{}_{}_{}_{}\".format(model_raw_name, info_rec, info_idx, info_token).zfill(8)\n",
    "\n",
    "        x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "        \n",
    "        x = x.to(device)\n",
    "\n",
    "        hid_r = model.encode(x, x_lens, x_mask)\n",
    "\n",
    "        hid_r = hid_r.cpu().detach().numpy()\n",
    "        # feed in the data and info to be saved\n",
    "        reshandler.data = hid_r[0]\n",
    "        reshandler.info = (info_token, info)\n",
    "\n",
    "        res_df = oneOut2ProgFrame(hid_r[0]) # one in batch\n",
    "        res_df = framify(res_df)\n",
    "        htmlplot = plot3dtrajectory(res_df)\n",
    "        save_html(htmlplot, info_rec, info_idx, info_token, info, model_serialnum=model_raw_name)\n",
    "        reshandler.save()\n",
    "        print(idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinkings\n",
    "We want to test:   \n",
    "1. the degree of returning （回头点） along the frames\n",
    "2. cluster from the points: question is whether to provide number of phonemes as number of clusters or not \n",
    "3. measure the transitional distances (between transition points) and in-cluster distances (between points in one cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
