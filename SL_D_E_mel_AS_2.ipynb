{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English - Testing Session - Boundary Prediction\n",
    "Version 2: encode all validation set tokens, but keeping only those that are \"matching\" (= match_status==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import plotly.express as px\n",
    "import random\n",
    "from sklearn.manifold import TSNE  # Optional: Use t-SNE for dimensionality reduction\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from loss import *\n",
    "from model import SimplerPhxLearner\n",
    "from dataset import SeqDatasetBoundary, MelSpecTransform\n",
    "from my_dataset import DS_Tools\n",
    "from reshandler import BndEncoderResHandler\n",
    "from misc_progress_bar import draw_progress_bar\n",
    "from bnd_detect_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "\n",
    "log_path = compound_word_log_path\n",
    "rec_path = word_seg_anno_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "INPUT_DIM = 64\n",
    "OUTPUT_DIM = 64\n",
    "\n",
    "INTER_DIM_0 = 32\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 8\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "\n",
    "LOADER_WORKER = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-related defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ts = \"0926172946\"\n",
    "stop_epoch = \"194\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): RLEncoder(\n",
       "    (rnn): LSTM(64, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): RALDecoder(\n",
       "    (rnn): LSTM(64, 8, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (w_k): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (w_v): Linear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=8, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw_name = \"PT_{}_{}_full\".format(load_ts, stop_epoch)\n",
    "model_name = model_raw_name + \".pt\"\n",
    "model_path = os.path.join(model_save_dir, model_name)\n",
    "state = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that due to the separate setting of word and phone datasets, we cannot really make it to select those that have not been trained on \n",
    "for this test. This is a point to further fix. Make reference to out first work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MelSpecTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)\n",
    "ds = SeqDatasetBoundary(rec_path, os.path.join(log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "# Cannot load dataset trained, data filtering applied\n",
    "valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(load_ts)))\n",
    "\n",
    "valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "\n",
    "# # this is to reduce the size of the dataset when the training power is not sufficient\n",
    "# small_len = int(0.5 * len(ds))\n",
    "# other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "# valid_ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=SeqDatasetBoundary.collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56808"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(): \n",
    "    model.eval()\n",
    "    reshandler = BndEncoderResHandler(whole_res_dir=compound_plot_res_path, file_prefix=model_raw_name)\n",
    "    all_res = []\n",
    "    all_bnd = []\n",
    "    all_name = []\n",
    "    all_ms = []\n",
    "\n",
    "    total = len(valid_loader)\n",
    "\n",
    "    for idx, (x, x_lens, bnd, name, ms) in enumerate(valid_loader): \n",
    "        bnd = bnd[0]\n",
    "        name = name[0]\n",
    "        ms = ms[0]\n",
    "\n",
    "        x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "        \n",
    "        x = x.to(device)\n",
    "\n",
    "        hid_r = model.encode(x, x_lens, x_mask)\n",
    "\n",
    "        hid_r = hid_r.cpu().detach().numpy().squeeze()\n",
    "\n",
    "        length = hid_r.shape[0]\n",
    "\n",
    "        all_res += [hid_r]\n",
    "        # note that this is bit different, not each frame, but each sequence is treated as one data point\n",
    "        all_bnd += [bnd]\n",
    "        all_name += [name]\n",
    "        all_ms += [ms]\n",
    "\n",
    "        if idx % 10 == 0: \n",
    "            draw_progress_bar(idx, total)\n",
    "    \n",
    "\n",
    "    reshandler.res = all_res\n",
    "    reshandler.tok = all_bnd\n",
    "    reshandler.name = all_name\n",
    "    reshandler.match_status = all_ms\n",
    "    reshandler.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 99%\t"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshandler = BndEncoderResHandler(whole_res_dir=compound_plot_res_path, file_prefix=model_raw_name)\n",
    "reshandler.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with Wang et al. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "all_preds = reshandler.res\n",
    "all_bnds = reshandler.tok\n",
    "all_matching_status = reshandler.match_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17514 56808 0.3083016476552598\n"
     ]
    }
   ],
   "source": [
    "mismatch_counter = 0\n",
    "total_counter = 0\n",
    "\n",
    "for ms in all_matching_status: \n",
    "    if ms != 1: \n",
    "        mismatch_counter += 1\n",
    "    total_counter += 1\n",
    "\n",
    "print(mismatch_counter, total_counter, mismatch_counter/total_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatcher_out: exclude those that are not matching\n",
    "preds_misout = []\n",
    "bnds_misout = []\n",
    "for idx in range(len(all_preds)): \n",
    "    if all_matching_status[idx] != 1: \n",
    "        continue\n",
    "    preds_misout.append(all_preds[idx])\n",
    "    bnds_misout.append(all_bnds[idx][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39294"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_misout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17978 39294 0.4575253219321016\n"
     ]
    }
   ],
   "source": [
    "one_counter = 0\n",
    "total_counter = 0\n",
    "\n",
    "for bnd in bnds_misout: \n",
    "    if len(bnd) <= 1: \n",
    "        one_counter += 1\n",
    "    total_counter += 1\n",
    "\n",
    "print(one_counter, total_counter, one_counter/total_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_bound_out: bnds excludes last\n",
    "preds = []\n",
    "bnds = []\n",
    "for idx in range(len(preds_misout)): \n",
    "    if len(bnds_misout[idx]) <= 1: \n",
    "        continue\n",
    "    preds.append(preds_misout[idx])\n",
    "    bnds.append(bnds_misout[idx][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21316"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_preds = periodic_bnd_detect(preds, every=4, only_then_rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-value for periodic boundary prediction is: -29.35992452336693\n"
     ]
    }
   ],
   "source": [
    "pb_precision_list, pb_recall_list = [], []\n",
    "\n",
    "#Recall\n",
    "for i in range(len(bnds)):\n",
    "    single_utt_recall = tolerance_recall(bnds[i], \\\n",
    "                            periodic_preds[i], tolerance_window=2)\n",
    "    pb_recall_list.append(single_utt_recall)\n",
    "\n",
    "#Precision\n",
    "for i in range(len(periodic_preds)):\n",
    "    single_utt_precision = tolerance_precision(bnds[i], \\\n",
    "                            periodic_preds[i], tolerance_window=2)\n",
    "    pb_precision_list.append(single_utt_precision)\n",
    "\n",
    "\n",
    "precision = sum(pb_precision_list) / len(pb_precision_list)\n",
    "recall = sum(pb_recall_list) / len(pb_recall_list)\n",
    "recall *= 100\n",
    "precision *= 100\n",
    "if recall == 0. or precision == 0.:\n",
    "    f_score = -1.\n",
    "    r_val = -1.\n",
    "else:\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "    r_val = r_val_eval(precision, recall)\n",
    "\n",
    "print(\"R-value for periodic boundary prediction is: {}\".format(r_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a through search through all dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best r_val is: 53.4182, th = 0.05, dim = 0\n",
      "The best r_val is: 47.8377, th = 0.1, dim = 1\n",
      "The best r_val is: 48.2029, th = 0.04, dim = 2\n",
      "The best r_val is: 53.5135, th = 0.1, dim = 3\n",
      "The best r_val is: 29.3523, th = 0.03, dim = 4\n",
      "The best r_val is: 50.3150, th = 0.05, dim = 5\n",
      "The best r_val is: 59.8185, th = 0.05, dim = 6\n",
      "The best r_val is: 51.8937, th = 0.035, dim = 7\n",
      "The best r_val is: 57.3235, th = 0.03, dim = mean\n"
     ]
    }
   ],
   "source": [
    "dims = list(range(8)) + [\"mean\"]\n",
    "th = [0.1, 0.05, 0.04, 0.035, 0.03]\n",
    "# th += [0.029, 0.028, 0.027, 0.026, 0.025, 0.024, 0.023, 0.022, 0.021, 0.02, 0.019]\n",
    "# th += [0.01, 0.009, 0.008, 0.007, 0.006, 0.005, 0.004, 0.003, 0.002, 0.001, 0.0009, 0.0008]\n",
    "th_total = len(th)\n",
    "\n",
    "recall_lslsls, precision_lslsls, r_val_lslsls = [], [], []\n",
    "\n",
    "for idx, dim in enumerate(dims): \n",
    "    recall_lsls, precision_lsls, r_val_ls = [], [], []\n",
    "    \n",
    "    for idx, thresh in enumerate(th): \n",
    "        recall_list, precision_list = thresh_segmentation_eval(batch_delta_hrs(preds, sel=dim, minus=True), bnds, tolerance_window=2, diff_thresh_factor=thresh)\n",
    "        recall_lsls.append(recall_list)\n",
    "        precision_lsls.append(precision_list)\n",
    "\n",
    "    for th_idx in range(len(th)): \n",
    "        precision_list = precision_lsls[th_idx]\n",
    "        recall_list = recall_lsls[th_idx]\n",
    "\n",
    "        precision = sum(precision_list) / len(precision_list)\n",
    "        recall = sum(recall_list) / len(recall_list)\n",
    "        recall *= 100\n",
    "        precision *= 100\n",
    "        if recall == 0. or precision == 0.:\n",
    "            f_score = -1.\n",
    "            r_val = -1.\n",
    "        else:\n",
    "            f_score = (2 * precision * recall) / (precision + recall)\n",
    "            r_val = r_val_eval(precision, recall)\n",
    "        \n",
    "        r_val_ls.append(r_val)\n",
    "    \n",
    "    recall_lslsls.append(recall_lsls)\n",
    "    precision_lslsls.append(precision_lsls)\n",
    "    r_val_lslsls.append(r_val_ls)\n",
    "    \n",
    "    print('The best r_val is: {:.4f}, th = {}, dim = {}'.format(max(r_val_ls), th[r_val_ls.index(max(r_val_ls))], dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe best r_val is: 64.1667, th = 0.028, dim = 0\\nThe best r_val is: 29.5675, th = 0.001, dim = 1\\nThe best r_val is: 62.7918, th = 0.02, dim = 2\\nThe best r_val is: 64.6059, th = 0.03, dim = 3\\nThe best r_val is: 49.6220, th = 0.004, dim = 4\\nThe best r_val is: 67.6130, th = 0.008, dim = 5\\nThe best r_val is: 35.5199, th = 0.001, dim = 6\\nThe best r_val is: 63.5690, th = 0.022, dim = 7\\nThe best r_val is: 55.5489, th = 0.001, dim = mean\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plus\n",
    "\"\"\"\n",
    "The best r_val is: 64.1704, th = 0.027, dim = 0\n",
    "The best r_val is: 29.5702, th = 0.0008, dim = 1\n",
    "The best r_val is: 62.8208, th = 0.019, dim = 2\n",
    "The best r_val is: 64.6059, th = 0.03, dim = 3\n",
    "The best r_val is: 49.6899, th = 0.003, dim = 4\n",
    "The best r_val is: 67.6130, th = 0.008, dim = 5\n",
    "The best r_val is: 35.5558, th = 0.0008, dim = 6\n",
    "The best r_val is: 63.5690, th = 0.022, dim = 7\n",
    "The best r_val is: 55.5981, th = 0.0008, dim = mean\n",
    "\"\"\"\n",
    "\n",
    "# Minus\n",
    "\"\"\"\n",
    "The best r_val is: 65.9907, th = 0.024, dim = 0\n",
    "The best r_val is: 51.9334, th = 0.035, dim = 1\n",
    "The best r_val is: 62.7616, th = 0.01, dim = 2\n",
    "The best r_val is: 65.6081, th = 0.03, dim = 3\n",
    "The best r_val is: 49.1389, th = 0.0008, dim = 4\n",
    "The best r_val is: 65.7445, th = 0.01, dim = 5\n",
    "The best r_val is: 65.8716, th = 0.027, dim = 6\n",
    "The best r_val is: 63.0764, th = 0.019, dim = 7\n",
    "The best r_val is: 66.7116, th = 0.027, dim = mean\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The best r_val is: 64.1667, th = 0.028, dim = 0\n",
    "The best r_val is: 29.5675, th = 0.001, dim = 1\n",
    "The best r_val is: 62.7918, th = 0.02, dim = 2\n",
    "The best r_val is: 64.6059, th = 0.03, dim = 3\n",
    "The best r_val is: 49.6220, th = 0.004, dim = 4\n",
    "The best r_val is: 67.6130, th = 0.008, dim = 5\n",
    "The best r_val is: 35.5199, th = 0.001, dim = 6\n",
    "The best r_val is: 63.5690, th = 0.022, dim = 7\n",
    "The best r_val is: 55.5489, th = 0.001, dim = mean\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some hidrep graphs in relation to boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_with_boundaries(features, boundaries, name):\n",
    "    num_features = features.shape[1]\n",
    "    num_samples = features.shape[0]\n",
    "\n",
    "    time_axis = np.arange(num_samples)\n",
    "\n",
    "    fig, axes = plt.subplots(num_features + 1, 1, figsize=(10, (num_features + 1) * 2), sharex=True)\n",
    "\n",
    "    # Plot each feature on separate subplots\n",
    "    for i in range(num_features):\n",
    "        ax = axes[i]\n",
    "        ax.plot(time_axis, features[:, i], label=f'Feature {i + 1}')\n",
    "\n",
    "        for boundary in boundaries:\n",
    "            if boundary < num_samples:\n",
    "                ax.axvline(x=boundary, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "        ax.set_ylabel(f'Feature {i + 1}')\n",
    "\n",
    "    # Plot all dimensions together with different line colors\n",
    "    ax = axes[num_features]\n",
    "    for i in range(num_features):\n",
    "        ax.plot(time_axis, features[:, i], label=f'Feature {i + 1}', alpha=0.5)\n",
    "\n",
    "    for boundary in boundaries:\n",
    "        if boundary < num_samples:\n",
    "            ax.axvline(x=boundary, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax.set_ylabel('All Features')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.xlabel('Time (frames)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(\"./8dim_hrs/\" + \"{}_dim.png\".format(name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_feature_with_boundaries(features, boundaries, name):\n",
    "    \"\"\"\n",
    "    Plot the mean of the features as a line graph with marked boundaries.\n",
    "    \n",
    "    Parameters:\n",
    "    - features: NumPy array of shape (length, 8)\n",
    "    - boundaries: List of boundary times (frame numbers)\n",
    "    \"\"\"\n",
    "    num_samples = features.shape[0]\n",
    "\n",
    "    # Create a time axis\n",
    "    time_axis = np.arange(num_samples)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_axis, features, label='Mean Feature')\n",
    "\n",
    "    # Mark boundaries on the plot\n",
    "    for boundary in boundaries:\n",
    "        if boundary < num_samples:\n",
    "            plt.axvline(x=boundary, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Set labels and legend\n",
    "    plt.xlabel('Time (frames)')\n",
    "    plt.ylabel('Mean Feature Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # plt.show()\n",
    "    plt.savefig(\"./8dim_hrs/\" + \"{}_mean.png\".format(name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(reshandler.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20): \n",
    "    randidx = random.randint(0, total_len)\n",
    "    name = reshandler.name[randidx]\n",
    "    pred = reshandler.res[randidx]\n",
    "    bnd = reshandler.tok[randidx]\n",
    "\n",
    "    delta = delta_hrs(pred)\n",
    "    plot_feature_with_boundaries(delta, bnd, name)\n",
    "\n",
    "    pred_mean = pred.mean(axis=1)\n",
    "    delta = delta_hrs(pred_mean)\n",
    "    plot_mean_feature_with_boundaries(delta, bnd, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manyOuts2progFrame(manyOuts, groups): \n",
    "    df = pd.DataFrame(manyOuts)\n",
    "    df[\"name\"] = groups\n",
    "\n",
    "    df = df.sort_values(by=[\"name\"])\n",
    "    # Group the DataFrame by the grouping column and assign timesteps within each group\n",
    "    df['timestep'] = df.groupby(\"name\").cumcount() + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshandler = AnnoEncoderResHandler(whole_res_dir=phone_plot_res_path, file_prefix=model_raw_name)\n",
    "reshandler.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(data, guide, selector):\n",
    "    # Ensure that the lengths of annotations and data_array match\n",
    "    if len(guide) != data.shape[0]:\n",
    "        raise ValueError(\"The length of guide must match the number of items in the data.\")\n",
    "\n",
    "    # Create a boolean mask for selected annotations\n",
    "    mask = np.isin(guide, selector)\n",
    "\n",
    "    # Use the mask to select the corresponding items from the data array\n",
    "    selected_items = data[mask]\n",
    "\n",
    "    return selected_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplot by Phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get usable cluster groups\n",
    "cluster_groups = [\"ng\", \"hh\"]\n",
    "\n",
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.tok, \n",
    "                 selector=cluster_groups)\n",
    "tags_cs = select(data=np.array(reshandler.tok), \n",
    "                 guide=reshandler.tok, \n",
    "                 selector=cluster_groups)\n",
    "color_translate = {item: idx for idx, item in enumerate(cluster_groups)}\n",
    "\n",
    "# Use Counter to count the occurrences of each item\n",
    "item_counts = Counter(tags_cs)\n",
    "\n",
    "# Print the item counts\n",
    "for item, count in item_counts.items():\n",
    "    print(f\"{item}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hidr_cs\n",
    "y = tags_cs\n",
    "\n",
    "colors = [color_translate[item] for item in y]\n",
    "df = pd.DataFrame(X)\n",
    "df[\"tag\"] = y\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g = sns.pairplot(df,hue='tag', corner=True, diag_kind=\"kde\")\n",
    "# g.map_lower(sns.kdeplot, levels=4, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_df = pd.read_csv(os.path.join(phone_plot_res_path, \"{}_guide.csv\".format(model_raw_name)))\n",
    "total_len = len(guide_df[\"Name\"].tolist())\n",
    "\n",
    "all_name = guide_df[\"Name\"]\n",
    "all_token = guide_df[\"Token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randidx = random.randint(0, total_len)\n",
    "save_name = all_name[randidx]\n",
    "token = all_token[randidx]\n",
    "print(save_name, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.name, \n",
    "                 selector=[save_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hidr_cs\n",
    "y = list(range(hidr_cs.shape[0]))\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df[\"tag\"] = y\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.pairplot(df,hue='tag', corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by phoneme and rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_df = pd.read_csv(os.path.join(phone_plot_res_path, \"{}_guide.csv\".format(model_raw_name)))\n",
    "filtered_guide_df = guide_df[guide_df['FrameCount'] <= 10]\n",
    "\n",
    "total_len = len(filtered_guide_df[\"Name\"].tolist())\n",
    "\n",
    "all_name = filtered_guide_df[\"Name\"].to_numpy()\n",
    "all_token = filtered_guide_df[\"Token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token = \"ng\"\n",
    "\n",
    "names_by_token = select(data=all_name, \n",
    "                        guide=all_token, \n",
    "                        selector=[target_token])\n",
    "names_by_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_guide_df[filtered_guide_df[\"Token\"] == target_token][\"FrameCount\"].to_numpy().tolist()\n",
    "\n",
    "# Create a histogram of counts\n",
    "plt.hist(data,  edgecolor='black')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selnum = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = selnum if selnum <= names_by_token.shape[0] else names_by_token.shape[0]\n",
    "random_subset_names_by_token = np.random.choice(names_by_token, size=subset_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.name, \n",
    "                 selector=random_subset_names_by_token)\n",
    "tags_cs = select(data=np.array(reshandler.name), \n",
    "                 guide=reshandler.name, \n",
    "                 selector=random_subset_names_by_token)\n",
    "\n",
    "res_df = manyOuts2progFrame(hidr_cs, tags_cs)\n",
    "res_df[\"timestep\"].to_numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.pairplot(res_df,hue='timestep', corner=True, palette=sns.color_palette(\"viridis\", res_df[\"timestep\"].to_numpy().max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
