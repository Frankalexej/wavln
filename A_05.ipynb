{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Run\n",
    "A_01: Copy from SL_D_E_4.ipynb. Fixed the problem as we have found in normalization. This time we normalize over the whole course. \n",
    "\n",
    "\n",
    "A_05: This time we resume using two linear layers, one before RNN and one after. IN this way we make the last linear layer of both encoder and decoder\n",
    "a pure linear layer without other components. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English\n",
    "Version 1: In this version we make the model \"simple\": make the encoder RNN into normal RNN first and try to see the result.  \n",
    "Version 2: Learning is not very much. Following Dr Coupe's advice we try simpler model structure.   \n",
    "Version 3: A simple trial training with Mel spectrogram instead of MFCC.   \n",
    "Version 4: try to enlarge the hidden dimensions so that we might still make sense of the hidden representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import random\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PhxLearner, SimplerPhxLearner, TwoLinPhxLearner\n",
    "from my_dataset import DS_Tools\n",
    "from dataset import SeqDataset, MelTransform, Normalizer, DeNormalizer, MelSpecTransformNew\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_DIM = 64\n",
    "OUTPUT_DIM = 64 \n",
    "\n",
    "INTER_DIM_0 = 32\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 8\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = TwoLinPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model weights\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         torch.nn.init.orthogonal_(m.weight)\n",
    "#         m.bias.data.fill_(0.01)\n",
    "#     if isinstance(m, nn.LSTM): \n",
    "#         for name, p in m.named_parameters():\n",
    "#             if \"weight\" in name: \n",
    "#                 nn.init.orthogonal_(p)\n",
    "#             elif \"bias\" in name: \n",
    "#                 nn.init.constant_(p, 0)\n",
    "\n",
    "# model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "# ts = \"0918192113\"\n",
    "stop_epoch = \"149\"\n",
    "ts = str(get_timestamp())\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    model_raw_name = \"PT_{}_{}_full\".format(ts, stop_epoch)\n",
    "    model_name = model_raw_name + \".pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoLinPhxLearner(\n",
       "  (encoder): LRLEncoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (layernorm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (rnn): LSTM(32, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       "  (decoder): LRALDecoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (layernorm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (rnn): LSTM(32, 8, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (w_k): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (w_v): Linear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (lin_3): Linear(in_features=8, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "# mytrans = MelSpecTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)\n",
    "# mytrans = nn.Sequential(\n",
    "#     MelTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS),\n",
    "#     # torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "#     Normalizer(Normalizer.norm_strip_minmax)\n",
    "# )\n",
    "mytrans = MelSpecTransformNew(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS, normalizer=Normalizer.norm_strip_mvn, denormalizer=DeNormalizer.norm_strip_mvn)\n",
    "ds = SeqDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "test = False\n",
    "if test: \n",
    "    use_len = int(0.1 * len(ds))\n",
    "    remain_len = len(ds) - use_len\n",
    "\n",
    "    # Randomly split the dataset into train and validation sets\n",
    "    ds, remain_ds = random_split(ds, [use_len, remain_len])\n",
    "\n",
    "\n",
    "if READ: \n",
    "    valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)))\n",
    "    all_indices = list(range(len(ds)))\n",
    "    train_ds_indices = list(set(all_indices).difference(set(valid_ds_indices)))\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(ds, train_ds_indices)\n",
    "    valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "else: \n",
    "    train_len = int(0.8 * len(ds))\n",
    "    valid_len = len(ds) - train_len\n",
    "\n",
    "    # Randomly split the dataset into train and validation sets\n",
    "    train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "    DS_Tools.save_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)), valid_ds.indices)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "valid_num = len(valid_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 54, 64])\n"
     ]
    }
   ],
   "source": [
    "# Load sample data from train_loader\n",
    "sample_data = next(iter(valid_loader))\n",
    "xx_pad, seg = sample_data\n",
    "print(xx_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# random.seed(101)\n",
    "# Generate six random indices\n",
    "random_indices = random.sample(range(len(xx_pad)), 6)\n",
    "# random_indices = list(range(6, 12))\n",
    "\n",
    "# Plot the spectrograms and mark the corresponding seg\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    spectrogram = xx_pad[idx]\n",
    "    \n",
    "    ax = axes[i]\n",
    "    img = ax.imshow(spectrogram.T, aspect='auto', origin=\"lower\")\n",
    "    # ax.axvline(x=segment, color='red', linestyle='--')\n",
    "    # ax.axvline(x=segment[1], color='red', linestyle='--')\n",
    "    ax.set_title(f'Spectrogram')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.colorbar(img,ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0122115907'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y = x \n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            # \n",
    "            # torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            # parameters: an iterable of Variables that will have gradients normalized\n",
    "            # max_norm: max norm of the gradients()\n",
    "            # norm_type: type of the used p-norm. Can be'inf'for infinity norm()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"Training loss {train_loss / train_num: .3f}\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            y = x    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"Valid loss {valid_loss / valid_num: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss  1.096 in Step 0\n",
      "Training loss  0.794 in Step 100\n",
      "Training loss  0.738 in Step 200\n",
      "Training loss  0.651 in Step 300\n",
      "Training loss  0.596 in Step 400\n",
      "Training loss  0.597 in Step 500\n",
      "Training loss  0.565 in Step 600\n",
      "Training loss  0.522 in Step 700\n",
      "Training loss  0.515 in Step 800\n",
      "Training loss  0.455 in Step 900\n",
      "Training loss  0.461 in Step 1000\n",
      "Training loss  0.438 in Step 1100\n",
      "Training loss  0.416 in Step 1200\n",
      "Training loss  0.386 in Step 1300\n",
      "Training loss  0.412 in Step 1400\n",
      "Training loss  0.396 in Step 1500\n",
      "Training loss  0.388 in Step 1600\n",
      "Training loss  0.374 in Step 1700\n",
      "Training loss  0.522\n",
      "Training timepoint saved\n",
      "Valid loss  0.353 in Step 0\n",
      "Valid loss  0.362 in Step 10\n",
      "Valid loss  0.390 in Step 20\n",
      "Valid loss  0.386 in Step 30\n",
      "Valid loss  0.339 in Step 40\n",
      "Valid loss  0.382 in Step 50\n",
      "Valid loss  0.383 in Step 60\n",
      "Valid loss  0.385 in Step 70\n",
      "Valid loss  0.382 in Step 80\n",
      "Valid loss  0.363 in Step 90\n",
      "Valid loss  0.372 in Step 100\n",
      "Valid loss  0.376 in Step 110\n",
      "Valid loss  0.366 in Step 120\n",
      "Valid loss  0.379 in Step 130\n",
      "Valid loss  0.365 in Step 140\n",
      "Valid loss  0.373 in Step 150\n",
      "Valid loss  0.385 in Step 160\n",
      "Valid loss  0.376 in Step 170\n",
      "Valid loss  0.369 in Step 180\n",
      "Valid loss  0.345 in Step 190\n",
      "Valid loss  0.359 in Step 200\n",
      "Valid loss  0.379 in Step 210\n",
      "Valid loss  0.378 in Step 220\n",
      "Valid loss  0.379 in Step 230\n",
      "Valid loss  0.358 in Step 240\n",
      "Valid loss  0.380 in Step 250\n",
      "Valid loss  0.362 in Step 260\n",
      "Valid loss  0.398 in Step 270\n",
      "Valid loss  0.372 in Step 280\n",
      "Valid loss  0.386 in Step 290\n",
      "Valid loss  0.383 in Step 300\n",
      "Valid loss  0.388 in Step 310\n",
      "Valid loss  0.373 in Step 320\n",
      "Valid loss  0.400 in Step 330\n",
      "Valid loss  0.372 in Step 340\n",
      "Valid loss  0.353 in Step 350\n",
      "Valid loss  0.386 in Step 360\n",
      "Valid loss  0.365 in Step 370\n",
      "Valid loss  0.353 in Step 380\n",
      "Valid loss  0.361 in Step 390\n",
      "Valid loss  0.381 in Step 400\n",
      "Valid loss  0.347 in Step 410\n",
      "Valid loss  0.380 in Step 420\n",
      "Valid loss  0.371 in Step 430\n",
      "Valid loss  0.346 in Step 440\n",
      "Valid loss  0.372\n",
      "Epoch 1\n",
      "Training loss  0.349 in Step 0\n",
      "Training loss  0.367 in Step 100\n",
      "Training loss  0.360 in Step 200\n",
      "Training loss  0.393 in Step 300\n",
      "Training loss  0.361 in Step 400\n",
      "Training loss  0.368 in Step 500\n",
      "Training loss  0.327 in Step 600\n",
      "Training loss  0.345 in Step 700\n",
      "Training loss  0.347 in Step 800\n",
      "Training loss  0.387 in Step 900\n",
      "Training loss  0.362 in Step 1000\n",
      "Training loss  0.349 in Step 1100\n",
      "Training loss  0.365 in Step 1200\n",
      "Training loss  0.347 in Step 1300\n",
      "Training loss  0.358 in Step 1400\n",
      "Training loss  0.332 in Step 1500\n",
      "Training loss  0.318 in Step 1600\n",
      "Training loss  0.356 in Step 1700\n",
      "Training loss  0.355\n",
      "Training timepoint saved\n",
      "Valid loss  0.329 in Step 0\n",
      "Valid loss  0.342 in Step 10\n",
      "Valid loss  0.360 in Step 20\n",
      "Valid loss  0.366 in Step 30\n",
      "Valid loss  0.315 in Step 40\n",
      "Valid loss  0.360 in Step 50\n",
      "Valid loss  0.363 in Step 60\n",
      "Valid loss  0.360 in Step 70\n",
      "Valid loss  0.349 in Step 80\n",
      "Valid loss  0.346 in Step 90\n",
      "Valid loss  0.344 in Step 100\n",
      "Valid loss  0.345 in Step 110\n",
      "Valid loss  0.340 in Step 120\n",
      "Valid loss  0.351 in Step 130\n",
      "Valid loss  0.346 in Step 140\n",
      "Valid loss  0.341 in Step 150\n",
      "Valid loss  0.369 in Step 160\n",
      "Valid loss  0.351 in Step 170\n",
      "Valid loss  0.345 in Step 180\n",
      "Valid loss  0.315 in Step 190\n",
      "Valid loss  0.327 in Step 200\n",
      "Valid loss  0.361 in Step 210\n",
      "Valid loss  0.351 in Step 220\n",
      "Valid loss  0.353 in Step 230\n",
      "Valid loss  0.337 in Step 240\n",
      "Valid loss  0.357 in Step 250\n",
      "Valid loss  0.325 in Step 260\n",
      "Valid loss  0.380 in Step 270\n",
      "Valid loss  0.350 in Step 280\n",
      "Valid loss  0.352 in Step 290\n",
      "Valid loss  0.350 in Step 300\n",
      "Valid loss  0.358 in Step 310\n",
      "Valid loss  0.356 in Step 320\n",
      "Valid loss  0.372 in Step 330\n",
      "Valid loss  0.348 in Step 340\n",
      "Valid loss  0.320 in Step 350\n",
      "Valid loss  0.357 in Step 360\n",
      "Valid loss  0.337 in Step 370\n",
      "Valid loss  0.327 in Step 380\n",
      "Valid loss  0.337 in Step 390\n",
      "Valid loss  0.361 in Step 400\n",
      "Valid loss  0.324 in Step 410\n",
      "Valid loss  0.360 in Step 420\n",
      "Valid loss  0.348 in Step 430\n",
      "Valid loss  0.318 in Step 440\n",
      "Valid loss  0.347\n",
      "Epoch 2\n",
      "Training loss  0.366 in Step 0\n",
      "Training loss  0.344 in Step 100\n",
      "Training loss  0.329 in Step 200\n",
      "Training loss  0.368 in Step 300\n",
      "Training loss  0.329 in Step 400\n",
      "Training loss  0.362 in Step 500\n",
      "Training loss  0.352 in Step 600\n",
      "Training loss  0.340 in Step 700\n",
      "Training loss  0.302 in Step 800\n",
      "Training loss  0.315 in Step 900\n",
      "Training loss  0.291 in Step 1000\n",
      "Training loss  0.279 in Step 1100\n",
      "Training loss  0.274 in Step 1200\n",
      "Training loss  0.287 in Step 1300\n",
      "Training loss  0.314 in Step 1400\n",
      "Training loss  0.275 in Step 1500\n",
      "Training loss  0.275 in Step 1600\n",
      "Training loss  0.269 in Step 1700\n",
      "Training loss  0.313\n",
      "Training timepoint saved\n",
      "Valid loss  0.279 in Step 0\n",
      "Valid loss  0.291 in Step 10\n",
      "Valid loss  0.303 in Step 20\n",
      "Valid loss  0.311 in Step 30\n",
      "Valid loss  0.262 in Step 40\n",
      "Valid loss  0.306 in Step 50\n",
      "Valid loss  0.310 in Step 60\n",
      "Valid loss  0.306 in Step 70\n",
      "Valid loss  0.292 in Step 80\n",
      "Valid loss  0.292 in Step 90\n",
      "Valid loss  0.292 in Step 100\n",
      "Valid loss  0.296 in Step 110\n",
      "Valid loss  0.283 in Step 120\n",
      "Valid loss  0.298 in Step 130\n",
      "Valid loss  0.291 in Step 140\n",
      "Valid loss  0.287 in Step 150\n",
      "Valid loss  0.312 in Step 160\n",
      "Valid loss  0.302 in Step 170\n",
      "Valid loss  0.290 in Step 180\n",
      "Valid loss  0.261 in Step 190\n",
      "Valid loss  0.274 in Step 200\n",
      "Valid loss  0.299 in Step 210\n",
      "Valid loss  0.298 in Step 220\n",
      "Valid loss  0.300 in Step 230\n",
      "Valid loss  0.280 in Step 240\n",
      "Valid loss  0.304 in Step 250\n",
      "Valid loss  0.272 in Step 260\n",
      "Valid loss  0.322 in Step 270\n",
      "Valid loss  0.291 in Step 280\n",
      "Valid loss  0.295 in Step 290\n",
      "Valid loss  0.297 in Step 300\n",
      "Valid loss  0.299 in Step 310\n",
      "Valid loss  0.299 in Step 320\n",
      "Valid loss  0.311 in Step 330\n",
      "Valid loss  0.289 in Step 340\n",
      "Valid loss  0.267 in Step 350\n",
      "Valid loss  0.299 in Step 360\n",
      "Valid loss  0.283 in Step 370\n",
      "Valid loss  0.273 in Step 380\n",
      "Valid loss  0.279 in Step 390\n",
      "Valid loss  0.308 in Step 400\n",
      "Valid loss  0.268 in Step 410\n",
      "Valid loss  0.302 in Step 420\n",
      "Valid loss  0.299 in Step 430\n",
      "Valid loss  0.267 in Step 440\n",
      "Valid loss  0.291\n",
      "Epoch 3\n",
      "Training loss  0.304 in Step 0\n",
      "Training loss  0.309 in Step 100\n",
      "Training loss  0.311 in Step 200\n",
      "Training loss  0.291 in Step 300\n",
      "Training loss  0.292 in Step 400\n",
      "Training loss  0.261 in Step 500\n",
      "Training loss  0.282 in Step 600\n",
      "Training loss  0.288 in Step 700\n",
      "Training loss  0.283 in Step 800\n",
      "Training loss  0.309 in Step 900\n",
      "Training loss  0.295 in Step 1000\n",
      "Training loss  0.306 in Step 1100\n",
      "Training loss  0.289 in Step 1200\n",
      "Training loss  0.302 in Step 1300\n",
      "Training loss  0.282 in Step 1400\n",
      "Training loss  0.292 in Step 1500\n",
      "Training loss  0.278 in Step 1600\n",
      "Training loss  0.305 in Step 1700\n",
      "Training loss  0.290\n",
      "Training timepoint saved\n",
      "Valid loss  0.277 in Step 0\n",
      "Valid loss  0.289 in Step 10\n",
      "Valid loss  0.301 in Step 20\n",
      "Valid loss  0.308 in Step 30\n",
      "Valid loss  0.260 in Step 40\n",
      "Valid loss  0.304 in Step 50\n",
      "Valid loss  0.309 in Step 60\n",
      "Valid loss  0.303 in Step 70\n",
      "Valid loss  0.290 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.291 in Step 100\n",
      "Valid loss  0.295 in Step 110\n",
      "Valid loss  0.280 in Step 120\n",
      "Valid loss  0.295 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.285 in Step 150\n",
      "Valid loss  0.310 in Step 160\n",
      "Valid loss  0.299 in Step 170\n",
      "Valid loss  0.288 in Step 180\n",
      "Valid loss  0.259 in Step 190\n",
      "Valid loss  0.272 in Step 200\n",
      "Valid loss  0.296 in Step 210\n",
      "Valid loss  0.296 in Step 220\n",
      "Valid loss  0.299 in Step 230\n",
      "Valid loss  0.277 in Step 240\n",
      "Valid loss  0.302 in Step 250\n",
      "Valid loss  0.271 in Step 260\n",
      "Valid loss  0.319 in Step 270\n",
      "Valid loss  0.288 in Step 280\n",
      "Valid loss  0.293 in Step 290\n",
      "Valid loss  0.294 in Step 300\n",
      "Valid loss  0.297 in Step 310\n",
      "Valid loss  0.296 in Step 320\n",
      "Valid loss  0.308 in Step 330\n",
      "Valid loss  0.287 in Step 340\n",
      "Valid loss  0.265 in Step 350\n",
      "Valid loss  0.296 in Step 360\n",
      "Valid loss  0.281 in Step 370\n",
      "Valid loss  0.273 in Step 380\n",
      "Valid loss  0.277 in Step 390\n",
      "Valid loss  0.305 in Step 400\n",
      "Valid loss  0.266 in Step 410\n",
      "Valid loss  0.299 in Step 420\n",
      "Valid loss  0.296 in Step 430\n",
      "Valid loss  0.266 in Step 440\n",
      "Valid loss  0.289\n",
      "Epoch 4\n",
      "Training loss  0.262 in Step 0\n",
      "Training loss  0.282 in Step 100\n",
      "Training loss  0.285 in Step 200\n",
      "Training loss  0.294 in Step 300\n",
      "Training loss  0.279 in Step 400\n",
      "Training loss  0.291 in Step 500\n",
      "Training loss  0.287 in Step 600\n",
      "Training loss  0.298 in Step 700\n",
      "Training loss  0.291 in Step 800\n",
      "Training loss  0.295 in Step 900\n",
      "Training loss  0.308 in Step 1000\n",
      "Training loss  0.274 in Step 1100\n",
      "Training loss  0.270 in Step 1200\n",
      "Training loss  0.292 in Step 1300\n",
      "Training loss  0.289 in Step 1400\n",
      "Training loss  0.303 in Step 1500\n",
      "Training loss  0.286 in Step 1600\n",
      "Training loss  0.293 in Step 1700\n",
      "Training loss  0.289\n",
      "Training timepoint saved\n",
      "Valid loss  0.277 in Step 0\n",
      "Valid loss  0.289 in Step 10\n",
      "Valid loss  0.300 in Step 20\n",
      "Valid loss  0.306 in Step 30\n",
      "Valid loss  0.259 in Step 40\n",
      "Valid loss  0.302 in Step 50\n",
      "Valid loss  0.308 in Step 60\n",
      "Valid loss  0.302 in Step 70\n",
      "Valid loss  0.288 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.290 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.279 in Step 120\n",
      "Valid loss  0.294 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.284 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.298 in Step 170\n",
      "Valid loss  0.288 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.270 in Step 200\n",
      "Valid loss  0.295 in Step 210\n",
      "Valid loss  0.296 in Step 220\n",
      "Valid loss  0.298 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.302 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.318 in Step 270\n",
      "Valid loss  0.288 in Step 280\n",
      "Valid loss  0.291 in Step 290\n",
      "Valid loss  0.294 in Step 300\n",
      "Valid loss  0.296 in Step 310\n",
      "Valid loss  0.295 in Step 320\n",
      "Valid loss  0.307 in Step 330\n",
      "Valid loss  0.287 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.281 in Step 370\n",
      "Valid loss  0.273 in Step 380\n",
      "Valid loss  0.276 in Step 390\n",
      "Valid loss  0.304 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.298 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.265 in Step 440\n",
      "Valid loss  0.288\n",
      "Epoch 5\n",
      "Training loss  0.291 in Step 0\n",
      "Training loss  0.286 in Step 100\n",
      "Training loss  0.266 in Step 200\n",
      "Training loss  0.282 in Step 300\n",
      "Training loss  0.279 in Step 400\n",
      "Training loss  0.292 in Step 500\n",
      "Training loss  0.295 in Step 600\n",
      "Training loss  0.298 in Step 700\n",
      "Training loss  0.302 in Step 800\n",
      "Training loss  0.282 in Step 900\n",
      "Training loss  0.294 in Step 1000\n",
      "Training loss  0.278 in Step 1100\n",
      "Training loss  0.308 in Step 1200\n",
      "Training loss  0.297 in Step 1300\n",
      "Training loss  0.283 in Step 1400\n",
      "Training loss  0.283 in Step 1500\n",
      "Training loss  0.309 in Step 1600\n",
      "Training loss  0.291 in Step 1700\n",
      "Training loss  0.289\n",
      "Training timepoint saved\n",
      "Valid loss  0.277 in Step 0\n",
      "Valid loss  0.289 in Step 10\n",
      "Valid loss  0.300 in Step 20\n",
      "Valid loss  0.305 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.302 in Step 50\n",
      "Valid loss  0.308 in Step 60\n",
      "Valid loss  0.302 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.290 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.278 in Step 120\n",
      "Valid loss  0.293 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.298 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.270 in Step 200\n",
      "Valid loss  0.295 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.301 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.318 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.291 in Step 290\n",
      "Valid loss  0.293 in Step 300\n",
      "Valid loss  0.295 in Step 310\n",
      "Valid loss  0.295 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.286 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.304 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.298 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.288\n",
      "Epoch 6\n",
      "Training loss  0.299 in Step 0\n",
      "Training loss  0.289 in Step 100\n",
      "Training loss  0.307 in Step 200\n",
      "Training loss  0.309 in Step 300\n",
      "Training loss  0.294 in Step 400\n",
      "Training loss  0.262 in Step 500\n",
      "Training loss  0.288 in Step 600\n",
      "Training loss  0.299 in Step 700\n",
      "Training loss  0.282 in Step 800\n",
      "Training loss  0.272 in Step 900\n",
      "Training loss  0.269 in Step 1000\n",
      "Training loss  0.292 in Step 1100\n",
      "Training loss  0.292 in Step 1200\n",
      "Training loss  0.287 in Step 1300\n",
      "Training loss  0.286 in Step 1400\n",
      "Training loss  0.301 in Step 1500\n",
      "Training loss  0.289 in Step 1600\n",
      "Training loss  0.294 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.289 in Step 10\n",
      "Valid loss  0.299 in Step 20\n",
      "Valid loss  0.305 in Step 30\n",
      "Valid loss  0.259 in Step 40\n",
      "Valid loss  0.302 in Step 50\n",
      "Valid loss  0.308 in Step 60\n",
      "Valid loss  0.302 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.278 in Step 120\n",
      "Valid loss  0.293 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.298 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.270 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.301 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.291 in Step 290\n",
      "Valid loss  0.293 in Step 300\n",
      "Valid loss  0.296 in Step 310\n",
      "Valid loss  0.295 in Step 320\n",
      "Valid loss  0.307 in Step 330\n",
      "Valid loss  0.286 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.288\n",
      "Epoch 7\n",
      "Training loss  0.279 in Step 0\n",
      "Training loss  0.295 in Step 100\n",
      "Training loss  0.307 in Step 200\n",
      "Training loss  0.263 in Step 300\n",
      "Training loss  0.292 in Step 400\n",
      "Training loss  0.286 in Step 500\n",
      "Training loss  0.277 in Step 600\n",
      "Training loss  0.275 in Step 700\n",
      "Training loss  0.308 in Step 800\n",
      "Training loss  0.310 in Step 900\n",
      "Training loss  0.293 in Step 1000\n",
      "Training loss  0.295 in Step 1100\n",
      "Training loss  0.296 in Step 1200\n",
      "Training loss  0.297 in Step 1300\n",
      "Training loss  0.307 in Step 1400\n",
      "Training loss  0.300 in Step 1500\n",
      "Training loss  0.295 in Step 1600\n",
      "Training loss  0.273 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.299 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.302 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.278 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.270 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.301 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.291 in Step 290\n",
      "Valid loss  0.293 in Step 300\n",
      "Valid loss  0.295 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 8\n",
      "Training loss  0.282 in Step 0\n",
      "Training loss  0.267 in Step 100\n",
      "Training loss  0.313 in Step 200\n",
      "Training loss  0.288 in Step 300\n",
      "Training loss  0.305 in Step 400\n",
      "Training loss  0.332 in Step 500\n",
      "Training loss  0.267 in Step 600\n",
      "Training loss  0.305 in Step 700\n",
      "Training loss  0.288 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.291 in Step 1000\n",
      "Training loss  0.281 in Step 1100\n",
      "Training loss  0.295 in Step 1200\n",
      "Training loss  0.275 in Step 1300\n",
      "Training loss  0.297 in Step 1400\n",
      "Training loss  0.283 in Step 1500\n",
      "Training loss  0.284 in Step 1600\n",
      "Training loss  0.267 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.285 in Step 0\n",
      "Valid loss  0.298 in Step 10\n",
      "Valid loss  0.309 in Step 20\n",
      "Valid loss  0.315 in Step 30\n",
      "Valid loss  0.269 in Step 40\n",
      "Valid loss  0.312 in Step 50\n",
      "Valid loss  0.319 in Step 60\n",
      "Valid loss  0.311 in Step 70\n",
      "Valid loss  0.297 in Step 80\n",
      "Valid loss  0.300 in Step 90\n",
      "Valid loss  0.299 in Step 100\n",
      "Valid loss  0.305 in Step 110\n",
      "Valid loss  0.287 in Step 120\n",
      "Valid loss  0.304 in Step 130\n",
      "Valid loss  0.299 in Step 140\n",
      "Valid loss  0.293 in Step 150\n",
      "Valid loss  0.319 in Step 160\n",
      "Valid loss  0.309 in Step 170\n",
      "Valid loss  0.297 in Step 180\n",
      "Valid loss  0.267 in Step 190\n",
      "Valid loss  0.280 in Step 200\n",
      "Valid loss  0.303 in Step 210\n",
      "Valid loss  0.305 in Step 220\n",
      "Valid loss  0.307 in Step 230\n",
      "Valid loss  0.286 in Step 240\n",
      "Valid loss  0.310 in Step 250\n",
      "Valid loss  0.281 in Step 260\n",
      "Valid loss  0.329 in Step 270\n",
      "Valid loss  0.297 in Step 280\n",
      "Valid loss  0.302 in Step 290\n",
      "Valid loss  0.303 in Step 300\n",
      "Valid loss  0.306 in Step 310\n",
      "Valid loss  0.305 in Step 320\n",
      "Valid loss  0.316 in Step 330\n",
      "Valid loss  0.296 in Step 340\n",
      "Valid loss  0.273 in Step 350\n",
      "Valid loss  0.304 in Step 360\n",
      "Valid loss  0.291 in Step 370\n",
      "Valid loss  0.281 in Step 380\n",
      "Valid loss  0.285 in Step 390\n",
      "Valid loss  0.314 in Step 400\n",
      "Valid loss  0.275 in Step 410\n",
      "Valid loss  0.309 in Step 420\n",
      "Valid loss  0.306 in Step 430\n",
      "Valid loss  0.274 in Step 440\n",
      "Valid loss  0.298\n",
      "Epoch 9\n",
      "Training loss  0.320 in Step 0\n",
      "Training loss  0.293 in Step 100\n",
      "Training loss  0.290 in Step 200\n",
      "Training loss  0.303 in Step 300\n",
      "Training loss  0.282 in Step 400\n",
      "Training loss  0.267 in Step 500\n",
      "Training loss  0.282 in Step 600\n",
      "Training loss  0.297 in Step 700\n",
      "Training loss  0.271 in Step 800\n",
      "Training loss  0.301 in Step 900\n",
      "Training loss  0.287 in Step 1000\n",
      "Training loss  0.289 in Step 1100\n",
      "Training loss  0.308 in Step 1200\n",
      "Training loss  0.270 in Step 1300\n",
      "Training loss  0.286 in Step 1400\n",
      "Training loss  0.280 in Step 1500\n",
      "Training loss  0.285 in Step 1600\n",
      "Training loss  0.274 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.295 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 10\n",
      "Training loss  0.286 in Step 0\n",
      "Training loss  0.310 in Step 100\n",
      "Training loss  0.279 in Step 200\n",
      "Training loss  0.287 in Step 300\n",
      "Training loss  0.294 in Step 400\n",
      "Training loss  0.315 in Step 500\n",
      "Training loss  0.307 in Step 600\n",
      "Training loss  0.286 in Step 700\n",
      "Training loss  0.290 in Step 800\n",
      "Training loss  0.268 in Step 900\n",
      "Training loss  0.289 in Step 1000\n",
      "Training loss  0.282 in Step 1100\n",
      "Training loss  0.288 in Step 1200\n",
      "Training loss  0.296 in Step 1300\n",
      "Training loss  0.282 in Step 1400\n",
      "Training loss  0.281 in Step 1500\n",
      "Training loss  0.252 in Step 1600\n",
      "Training loss  0.293 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.299 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.293 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.295 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 11\n",
      "Training loss  0.277 in Step 0\n",
      "Training loss  0.298 in Step 100\n",
      "Training loss  0.287 in Step 200\n",
      "Training loss  0.268 in Step 300\n",
      "Training loss  0.277 in Step 400\n",
      "Training loss  0.314 in Step 500\n",
      "Training loss  0.290 in Step 600\n",
      "Training loss  0.324 in Step 700\n",
      "Training loss  0.295 in Step 800\n",
      "Training loss  0.304 in Step 900\n",
      "Training loss  0.305 in Step 1000\n",
      "Training loss  0.274 in Step 1100\n",
      "Training loss  0.295 in Step 1200\n",
      "Training loss  0.294 in Step 1300\n",
      "Training loss  0.276 in Step 1400\n",
      "Training loss  0.345 in Step 1500\n",
      "Training loss  0.290 in Step 1600\n",
      "Training loss  0.280 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.293 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 12\n",
      "Training loss  0.279 in Step 0\n",
      "Training loss  0.287 in Step 100\n",
      "Training loss  0.285 in Step 200\n",
      "Training loss  0.268 in Step 300\n",
      "Training loss  0.298 in Step 400\n",
      "Training loss  0.287 in Step 500\n",
      "Training loss  0.306 in Step 600\n",
      "Training loss  0.269 in Step 700\n",
      "Training loss  0.312 in Step 800\n",
      "Training loss  0.278 in Step 900\n",
      "Training loss  0.293 in Step 1000\n",
      "Training loss  0.307 in Step 1100\n",
      "Training loss  0.288 in Step 1200\n",
      "Training loss  0.294 in Step 1300\n",
      "Training loss  0.284 in Step 1400\n",
      "Training loss  0.298 in Step 1500\n",
      "Training loss  0.278 in Step 1600\n",
      "Training loss  0.292 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.291 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 13\n",
      "Training loss  0.255 in Step 0\n",
      "Training loss  0.288 in Step 100\n",
      "Training loss  0.268 in Step 200\n",
      "Training loss  0.299 in Step 300\n",
      "Training loss  0.290 in Step 400\n",
      "Training loss  0.300 in Step 500\n",
      "Training loss  0.276 in Step 600\n",
      "Training loss  0.285 in Step 700\n",
      "Training loss  0.282 in Step 800\n",
      "Training loss  0.316 in Step 900\n",
      "Training loss  0.293 in Step 1000\n",
      "Training loss  0.301 in Step 1100\n",
      "Training loss  0.301 in Step 1200\n",
      "Training loss  0.285 in Step 1300\n",
      "Training loss  0.292 in Step 1400\n",
      "Training loss  0.287 in Step 1500\n",
      "Training loss  0.277 in Step 1600\n",
      "Training loss  0.280 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 14\n",
      "Training loss  0.277 in Step 0\n",
      "Training loss  0.271 in Step 100\n",
      "Training loss  0.316 in Step 200\n",
      "Training loss  0.268 in Step 300\n",
      "Training loss  0.275 in Step 400\n",
      "Training loss  0.312 in Step 500\n",
      "Training loss  0.294 in Step 600\n",
      "Training loss  0.298 in Step 700\n",
      "Training loss  0.284 in Step 800\n",
      "Training loss  0.264 in Step 900\n",
      "Training loss  0.302 in Step 1000\n",
      "Training loss  0.271 in Step 1100\n",
      "Training loss  0.298 in Step 1200\n",
      "Training loss  0.316 in Step 1300\n",
      "Training loss  0.286 in Step 1400\n",
      "Training loss  0.274 in Step 1500\n",
      "Training loss  0.268 in Step 1600\n",
      "Training loss  0.276 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 15\n",
      "Training loss  0.298 in Step 0\n",
      "Training loss  0.285 in Step 100\n",
      "Training loss  0.270 in Step 200\n",
      "Training loss  0.270 in Step 300\n",
      "Training loss  0.299 in Step 400\n",
      "Training loss  0.283 in Step 500\n",
      "Training loss  0.262 in Step 600\n",
      "Training loss  0.324 in Step 700\n",
      "Training loss  0.293 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.281 in Step 1000\n",
      "Training loss  0.284 in Step 1100\n",
      "Training loss  0.281 in Step 1200\n",
      "Training loss  0.303 in Step 1300\n",
      "Training loss  0.278 in Step 1400\n",
      "Training loss  0.271 in Step 1500\n",
      "Training loss  0.296 in Step 1600\n",
      "Training loss  0.279 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.308 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 16\n",
      "Training loss  0.320 in Step 0\n",
      "Training loss  0.285 in Step 100\n",
      "Training loss  0.314 in Step 200\n",
      "Training loss  0.275 in Step 300\n",
      "Training loss  0.283 in Step 400\n",
      "Training loss  0.274 in Step 500\n",
      "Training loss  0.281 in Step 600\n",
      "Training loss  0.298 in Step 700\n",
      "Training loss  0.305 in Step 800\n",
      "Training loss  0.274 in Step 900\n",
      "Training loss  0.296 in Step 1000\n",
      "Training loss  0.317 in Step 1100\n",
      "Training loss  0.281 in Step 1200\n",
      "Training loss  0.285 in Step 1300\n",
      "Training loss  0.287 in Step 1400\n",
      "Training loss  0.248 in Step 1500\n",
      "Training loss  0.288 in Step 1600\n",
      "Training loss  0.288 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 17\n",
      "Training loss  0.284 in Step 0\n",
      "Training loss  0.318 in Step 100\n",
      "Training loss  0.299 in Step 200\n",
      "Training loss  0.274 in Step 300\n",
      "Training loss  0.257 in Step 400\n",
      "Training loss  0.295 in Step 500\n",
      "Training loss  0.298 in Step 600\n",
      "Training loss  0.282 in Step 700\n",
      "Training loss  0.301 in Step 800\n",
      "Training loss  0.292 in Step 900\n",
      "Training loss  0.285 in Step 1000\n",
      "Training loss  0.286 in Step 1100\n",
      "Training loss  0.292 in Step 1200\n",
      "Training loss  0.270 in Step 1300\n",
      "Training loss  0.272 in Step 1400\n",
      "Training loss  0.309 in Step 1500\n",
      "Training loss  0.312 in Step 1600\n",
      "Training loss  0.286 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.293 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.293 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 18\n",
      "Training loss  0.282 in Step 0\n",
      "Training loss  0.275 in Step 100\n",
      "Training loss  0.299 in Step 200\n",
      "Training loss  0.307 in Step 300\n",
      "Training loss  0.282 in Step 400\n",
      "Training loss  0.297 in Step 500\n",
      "Training loss  0.300 in Step 600\n",
      "Training loss  0.271 in Step 700\n",
      "Training loss  0.261 in Step 800\n",
      "Training loss  0.302 in Step 900\n",
      "Training loss  0.264 in Step 1000\n",
      "Training loss  0.305 in Step 1100\n",
      "Training loss  0.311 in Step 1200\n",
      "Training loss  0.281 in Step 1300\n",
      "Training loss  0.294 in Step 1400\n",
      "Training loss  0.256 in Step 1500\n",
      "Training loss  0.297 in Step 1600\n",
      "Training loss  0.285 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.289 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.290 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.295 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.286 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.294 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 19\n",
      "Training loss  0.271 in Step 0\n",
      "Training loss  0.281 in Step 100\n",
      "Training loss  0.270 in Step 200\n",
      "Training loss  0.299 in Step 300\n",
      "Training loss  0.270 in Step 400\n",
      "Training loss  0.287 in Step 500\n",
      "Training loss  0.288 in Step 600\n",
      "Training loss  0.282 in Step 700\n",
      "Training loss  0.265 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.286 in Step 1000\n",
      "Training loss  0.299 in Step 1100\n",
      "Training loss  0.304 in Step 1200\n",
      "Training loss  0.325 in Step 1300\n",
      "Training loss  0.280 in Step 1400\n",
      "Training loss  0.306 in Step 1500\n",
      "Training loss  0.298 in Step 1600\n",
      "Training loss  0.275 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.287 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 20\n",
      "Training loss  0.283 in Step 0\n",
      "Training loss  0.270 in Step 100\n",
      "Training loss  0.286 in Step 200\n",
      "Training loss  0.283 in Step 300\n",
      "Training loss  0.298 in Step 400\n",
      "Training loss  0.282 in Step 500\n",
      "Training loss  0.288 in Step 600\n",
      "Training loss  0.304 in Step 700\n",
      "Training loss  0.308 in Step 800\n",
      "Training loss  0.286 in Step 900\n",
      "Training loss  0.292 in Step 1000\n",
      "Training loss  0.292 in Step 1100\n",
      "Training loss  0.292 in Step 1200\n",
      "Training loss  0.329 in Step 1300\n",
      "Training loss  0.279 in Step 1400\n",
      "Training loss  0.279 in Step 1500\n",
      "Training loss  0.306 in Step 1600\n",
      "Training loss  0.293 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 21\n",
      "Training loss  0.282 in Step 0\n",
      "Training loss  0.247 in Step 100\n",
      "Training loss  0.283 in Step 200\n",
      "Training loss  0.283 in Step 300\n",
      "Training loss  0.281 in Step 400\n",
      "Training loss  0.296 in Step 500\n",
      "Training loss  0.306 in Step 600\n",
      "Training loss  0.285 in Step 700\n",
      "Training loss  0.273 in Step 800\n",
      "Training loss  0.281 in Step 900\n",
      "Training loss  0.274 in Step 1000\n",
      "Training loss  0.286 in Step 1100\n",
      "Training loss  0.294 in Step 1200\n",
      "Training loss  0.314 in Step 1300\n",
      "Training loss  0.310 in Step 1400\n",
      "Training loss  0.322 in Step 1500\n",
      "Training loss  0.288 in Step 1600\n",
      "Training loss  0.278 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 22\n",
      "Training loss  0.274 in Step 0\n",
      "Training loss  0.277 in Step 100\n",
      "Training loss  0.304 in Step 200\n",
      "Training loss  0.286 in Step 300\n",
      "Training loss  0.289 in Step 400\n",
      "Training loss  0.272 in Step 500\n",
      "Training loss  0.267 in Step 600\n",
      "Training loss  0.274 in Step 700\n",
      "Training loss  0.310 in Step 800\n",
      "Training loss  0.308 in Step 900\n",
      "Training loss  0.282 in Step 1000\n",
      "Training loss  0.293 in Step 1100\n",
      "Training loss  0.275 in Step 1200\n",
      "Training loss  0.282 in Step 1300\n",
      "Training loss  0.265 in Step 1400\n",
      "Training loss  0.310 in Step 1500\n",
      "Training loss  0.279 in Step 1600\n",
      "Training loss  0.289 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 23\n",
      "Training loss  0.264 in Step 0\n",
      "Training loss  0.293 in Step 100\n",
      "Training loss  0.278 in Step 200\n",
      "Training loss  0.290 in Step 300\n",
      "Training loss  0.296 in Step 400\n",
      "Training loss  0.262 in Step 500\n",
      "Training loss  0.336 in Step 600\n",
      "Training loss  0.297 in Step 700\n",
      "Training loss  0.298 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.284 in Step 1000\n",
      "Training loss  0.283 in Step 1100\n",
      "Training loss  0.279 in Step 1200\n",
      "Training loss  0.293 in Step 1300\n",
      "Training loss  0.291 in Step 1400\n",
      "Training loss  0.295 in Step 1500\n",
      "Training loss  0.257 in Step 1600\n",
      "Training loss  0.289 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 24\n",
      "Training loss  0.258 in Step 0\n",
      "Training loss  0.257 in Step 100\n",
      "Training loss  0.260 in Step 200\n",
      "Training loss  0.299 in Step 300\n",
      "Training loss  0.292 in Step 400\n",
      "Training loss  0.289 in Step 500\n",
      "Training loss  0.298 in Step 600\n",
      "Training loss  0.294 in Step 700\n",
      "Training loss  0.290 in Step 800\n",
      "Training loss  0.286 in Step 900\n",
      "Training loss  0.294 in Step 1000\n",
      "Training loss  0.278 in Step 1100\n",
      "Training loss  0.284 in Step 1200\n",
      "Training loss  0.273 in Step 1300\n",
      "Training loss  0.290 in Step 1400\n",
      "Training loss  0.284 in Step 1500\n",
      "Training loss  0.281 in Step 1600\n",
      "Training loss  0.281 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.275 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 25\n",
      "Training loss  0.305 in Step 0\n",
      "Training loss  0.311 in Step 100\n",
      "Training loss  0.276 in Step 200\n",
      "Training loss  0.281 in Step 300\n",
      "Training loss  0.294 in Step 400\n",
      "Training loss  0.322 in Step 500\n",
      "Training loss  0.305 in Step 600\n",
      "Training loss  0.295 in Step 700\n",
      "Training loss  0.270 in Step 800\n",
      "Training loss  0.289 in Step 900\n",
      "Training loss  0.286 in Step 1000\n",
      "Training loss  0.291 in Step 1100\n",
      "Training loss  0.276 in Step 1200\n",
      "Training loss  0.321 in Step 1300\n",
      "Training loss  0.284 in Step 1400\n",
      "Training loss  0.291 in Step 1500\n",
      "Training loss  0.280 in Step 1600\n",
      "Training loss  0.298 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 26\n",
      "Training loss  0.296 in Step 0\n",
      "Training loss  0.284 in Step 100\n",
      "Training loss  0.303 in Step 200\n",
      "Training loss  0.284 in Step 300\n",
      "Training loss  0.282 in Step 400\n",
      "Training loss  0.294 in Step 500\n",
      "Training loss  0.292 in Step 600\n",
      "Training loss  0.301 in Step 700\n",
      "Training loss  0.280 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.311 in Step 1000\n",
      "Training loss  0.276 in Step 1100\n",
      "Training loss  0.293 in Step 1200\n",
      "Training loss  0.268 in Step 1300\n",
      "Training loss  0.286 in Step 1400\n",
      "Training loss  0.304 in Step 1500\n",
      "Training loss  0.293 in Step 1600\n",
      "Training loss  0.271 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.299 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.302 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.283 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.293 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.286 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 27\n",
      "Training loss  0.288 in Step 0\n",
      "Training loss  0.297 in Step 100\n",
      "Training loss  0.252 in Step 200\n",
      "Training loss  0.296 in Step 300\n",
      "Training loss  0.282 in Step 400\n",
      "Training loss  0.306 in Step 500\n",
      "Training loss  0.288 in Step 600\n",
      "Training loss  0.295 in Step 700\n",
      "Training loss  0.317 in Step 800\n",
      "Training loss  0.294 in Step 900\n",
      "Training loss  0.295 in Step 1000\n",
      "Training loss  0.274 in Step 1100\n",
      "Training loss  0.295 in Step 1200\n",
      "Training loss  0.299 in Step 1300\n",
      "Training loss  0.278 in Step 1400\n",
      "Training loss  0.273 in Step 1500\n",
      "Training loss  0.275 in Step 1600\n",
      "Training loss  0.295 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 28\n",
      "Training loss  0.301 in Step 0\n",
      "Training loss  0.284 in Step 100\n",
      "Training loss  0.286 in Step 200\n",
      "Training loss  0.284 in Step 300\n",
      "Training loss  0.300 in Step 400\n",
      "Training loss  0.269 in Step 500\n",
      "Training loss  0.280 in Step 600\n",
      "Training loss  0.300 in Step 700\n",
      "Training loss  0.258 in Step 800\n",
      "Training loss  0.300 in Step 900\n",
      "Training loss  0.291 in Step 1000\n",
      "Training loss  0.325 in Step 1100\n",
      "Training loss  0.289 in Step 1200\n",
      "Training loss  0.274 in Step 1300\n",
      "Training loss  0.314 in Step 1400\n",
      "Training loss  0.305 in Step 1500\n",
      "Training loss  0.291 in Step 1600\n",
      "Training loss  0.266 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.291 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 29\n",
      "Training loss  0.306 in Step 0\n",
      "Training loss  0.301 in Step 100\n",
      "Training loss  0.272 in Step 200\n",
      "Training loss  0.272 in Step 300\n",
      "Training loss  0.273 in Step 400\n",
      "Training loss  0.309 in Step 500\n",
      "Training loss  0.313 in Step 600\n",
      "Training loss  0.276 in Step 700\n",
      "Training loss  0.290 in Step 800\n",
      "Training loss  0.256 in Step 900\n",
      "Training loss  0.270 in Step 1000\n",
      "Training loss  0.288 in Step 1100\n",
      "Training loss  0.278 in Step 1200\n",
      "Training loss  0.252 in Step 1300\n",
      "Training loss  0.271 in Step 1400\n",
      "Training loss  0.383 in Step 1500\n",
      "Training loss  0.265 in Step 1600\n",
      "Training loss  0.292 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.263 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 30\n",
      "Training loss  0.318 in Step 0\n",
      "Training loss  0.310 in Step 100\n",
      "Training loss  0.258 in Step 200\n",
      "Training loss  0.280 in Step 300\n",
      "Training loss  0.262 in Step 400\n",
      "Training loss  0.288 in Step 500\n",
      "Training loss  0.265 in Step 600\n",
      "Training loss  0.288 in Step 700\n",
      "Training loss  0.307 in Step 800\n",
      "Training loss  0.279 in Step 900\n",
      "Training loss  0.281 in Step 1000\n",
      "Training loss  0.268 in Step 1100\n",
      "Training loss  0.293 in Step 1200\n",
      "Training loss  0.296 in Step 1300\n",
      "Training loss  0.296 in Step 1400\n",
      "Training loss  0.293 in Step 1500\n",
      "Training loss  0.266 in Step 1600\n",
      "Training loss  0.275 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 31\n",
      "Training loss  0.280 in Step 0\n",
      "Training loss  0.275 in Step 100\n",
      "Training loss  0.285 in Step 200\n",
      "Training loss  0.311 in Step 300\n",
      "Training loss  0.325 in Step 400\n",
      "Training loss  0.290 in Step 500\n",
      "Training loss  0.280 in Step 600\n",
      "Training loss  0.304 in Step 700\n",
      "Training loss  0.305 in Step 800\n",
      "Training loss  0.256 in Step 900\n",
      "Training loss  0.300 in Step 1000\n",
      "Training loss  0.306 in Step 1100\n",
      "Training loss  0.251 in Step 1200\n",
      "Training loss  0.289 in Step 1300\n",
      "Training loss  0.284 in Step 1400\n",
      "Training loss  0.280 in Step 1500\n",
      "Training loss  0.297 in Step 1600\n",
      "Training loss  0.286 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.277 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.304 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.308 in Step 60\n",
      "Valid loss  0.301 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.295 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.295 in Step 130\n",
      "Valid loss  0.289 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.309 in Step 160\n",
      "Valid loss  0.297 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.257 in Step 190\n",
      "Valid loss  0.270 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.270 in Step 260\n",
      "Valid loss  0.317 in Step 270\n",
      "Valid loss  0.288 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.264 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.272 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.304 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.298 in Step 420\n",
      "Valid loss  0.295 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.288\n",
      "Epoch 32\n",
      "Training loss  0.289 in Step 0\n",
      "Training loss  0.277 in Step 100\n",
      "Training loss  0.291 in Step 200\n",
      "Training loss  0.289 in Step 300\n",
      "Training loss  0.314 in Step 400\n",
      "Training loss  0.286 in Step 500\n",
      "Training loss  0.281 in Step 600\n",
      "Training loss  0.284 in Step 700\n",
      "Training loss  0.255 in Step 800\n",
      "Training loss  0.285 in Step 900\n",
      "Training loss  0.274 in Step 1000\n",
      "Training loss  0.281 in Step 1100\n",
      "Training loss  0.289 in Step 1200\n",
      "Training loss  0.277 in Step 1300\n",
      "Training loss  0.266 in Step 1400\n",
      "Training loss  0.275 in Step 1500\n",
      "Training loss  0.307 in Step 1600\n",
      "Training loss  0.297 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.292 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.286 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 33\n",
      "Training loss  0.299 in Step 0\n",
      "Training loss  0.301 in Step 100\n",
      "Training loss  0.290 in Step 200\n",
      "Training loss  0.273 in Step 300\n",
      "Training loss  0.306 in Step 400\n",
      "Training loss  0.283 in Step 500\n",
      "Training loss  0.308 in Step 600\n",
      "Training loss  0.310 in Step 700\n",
      "Training loss  0.281 in Step 800\n",
      "Training loss  0.309 in Step 900\n",
      "Training loss  0.253 in Step 1000\n",
      "Training loss  0.272 in Step 1100\n",
      "Training loss  0.275 in Step 1200\n",
      "Training loss  0.299 in Step 1300\n",
      "Training loss  0.302 in Step 1400\n",
      "Training loss  0.286 in Step 1500\n",
      "Training loss  0.278 in Step 1600\n",
      "Training loss  0.288 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 34\n",
      "Training loss  0.276 in Step 0\n",
      "Training loss  0.295 in Step 100\n",
      "Training loss  0.278 in Step 200\n",
      "Training loss  0.296 in Step 300\n",
      "Training loss  0.290 in Step 400\n",
      "Training loss  0.271 in Step 500\n",
      "Training loss  0.285 in Step 600\n",
      "Training loss  0.263 in Step 700\n",
      "Training loss  0.287 in Step 800\n",
      "Training loss  0.287 in Step 900\n",
      "Training loss  0.312 in Step 1000\n",
      "Training loss  0.311 in Step 1100\n",
      "Training loss  0.290 in Step 1200\n",
      "Training loss  0.291 in Step 1300\n",
      "Training loss  0.299 in Step 1400\n",
      "Training loss  0.291 in Step 1500\n",
      "Training loss  0.295 in Step 1600\n",
      "Training loss  0.278 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.287 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.284 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 35\n",
      "Training loss  0.292 in Step 0\n",
      "Training loss  0.263 in Step 100\n",
      "Training loss  0.257 in Step 200\n",
      "Training loss  0.299 in Step 300\n",
      "Training loss  0.282 in Step 400\n",
      "Training loss  0.306 in Step 500\n",
      "Training loss  0.286 in Step 600\n",
      "Training loss  0.263 in Step 700\n",
      "Training loss  0.289 in Step 800\n",
      "Training loss  0.273 in Step 900\n",
      "Training loss  0.299 in Step 1000\n",
      "Training loss  0.264 in Step 1100\n",
      "Training loss  0.287 in Step 1200\n",
      "Training loss  0.295 in Step 1300\n",
      "Training loss  0.300 in Step 1400\n",
      "Training loss  0.289 in Step 1500\n",
      "Training loss  0.297 in Step 1600\n",
      "Training loss  0.310 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.275 in Step 0\n",
      "Valid loss  0.287 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.306 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.291 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.284 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 36\n",
      "Training loss  0.286 in Step 0\n",
      "Training loss  0.276 in Step 100\n",
      "Training loss  0.257 in Step 200\n",
      "Training loss  0.289 in Step 300\n",
      "Training loss  0.297 in Step 400\n",
      "Training loss  0.278 in Step 500\n",
      "Training loss  0.276 in Step 600\n",
      "Training loss  0.319 in Step 700\n",
      "Training loss  0.285 in Step 800\n",
      "Training loss  0.286 in Step 900\n",
      "Training loss  0.262 in Step 1000\n",
      "Training loss  0.283 in Step 1100\n",
      "Training loss  0.296 in Step 1200\n",
      "Training loss  0.292 in Step 1300\n",
      "Training loss  0.302 in Step 1400\n",
      "Training loss  0.301 in Step 1500\n",
      "Training loss  0.288 in Step 1600\n",
      "Training loss  0.275 in Step 1700\n",
      "Training loss  0.288\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.306 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 37\n",
      "Training loss  0.279 in Step 0\n",
      "Training loss  0.310 in Step 100\n",
      "Training loss  0.291 in Step 200\n",
      "Training loss  0.288 in Step 300\n",
      "Training loss  0.270 in Step 400\n",
      "Training loss  0.284 in Step 500\n",
      "Training loss  0.278 in Step 600\n",
      "Training loss  0.280 in Step 700\n",
      "Training loss  0.298 in Step 800\n",
      "Training loss  0.292 in Step 900\n",
      "Training loss  0.276 in Step 1000\n",
      "Training loss  0.298 in Step 1100\n",
      "Training loss  0.273 in Step 1200\n",
      "Training loss  0.275 in Step 1300\n",
      "Training loss  0.288 in Step 1400\n",
      "Training loss  0.299 in Step 1500\n",
      "Training loss  0.272 in Step 1600\n",
      "Training loss  0.314 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.287 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 38\n",
      "Training loss  0.286 in Step 0\n",
      "Training loss  0.283 in Step 100\n",
      "Training loss  0.267 in Step 200\n",
      "Training loss  0.289 in Step 300\n",
      "Training loss  0.286 in Step 400\n",
      "Training loss  0.293 in Step 500\n",
      "Training loss  0.279 in Step 600\n",
      "Training loss  0.271 in Step 700\n",
      "Training loss  0.297 in Step 800\n",
      "Training loss  0.283 in Step 900\n",
      "Training loss  0.284 in Step 1000\n",
      "Training loss  0.299 in Step 1100\n",
      "Training loss  0.280 in Step 1200\n",
      "Training loss  0.286 in Step 1300\n",
      "Training loss  0.277 in Step 1400\n",
      "Training loss  0.260 in Step 1500\n",
      "Training loss  0.295 in Step 1600\n",
      "Training loss  0.287 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 39\n",
      "Training loss  0.275 in Step 0\n",
      "Training loss  0.286 in Step 100\n",
      "Training loss  0.300 in Step 200\n",
      "Training loss  0.286 in Step 300\n",
      "Training loss  0.298 in Step 400\n",
      "Training loss  0.282 in Step 500\n",
      "Training loss  0.282 in Step 600\n",
      "Training loss  0.278 in Step 700\n",
      "Training loss  0.292 in Step 800\n",
      "Training loss  0.289 in Step 900\n",
      "Training loss  0.290 in Step 1000\n",
      "Training loss  0.276 in Step 1100\n",
      "Training loss  0.287 in Step 1200\n",
      "Training loss  0.315 in Step 1300\n",
      "Training loss  0.303 in Step 1400\n",
      "Training loss  0.278 in Step 1500\n",
      "Training loss  0.277 in Step 1600\n",
      "Training loss  0.289 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.287 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.297 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.284 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 40\n",
      "Training loss  0.271 in Step 0\n",
      "Training loss  0.294 in Step 100\n",
      "Training loss  0.293 in Step 200\n",
      "Training loss  0.291 in Step 300\n",
      "Training loss  0.268 in Step 400\n",
      "Training loss  0.283 in Step 500\n",
      "Training loss  0.265 in Step 600\n",
      "Training loss  0.292 in Step 700\n",
      "Training loss  0.262 in Step 800\n",
      "Training loss  0.286 in Step 900\n",
      "Training loss  0.301 in Step 1000\n",
      "Training loss  0.303 in Step 1100\n",
      "Training loss  0.274 in Step 1200\n",
      "Training loss  0.284 in Step 1300\n",
      "Training loss  0.279 in Step 1400\n",
      "Training loss  0.260 in Step 1500\n",
      "Training loss  0.299 in Step 1600\n",
      "Training loss  0.261 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.275 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.286 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.286 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 41\n",
      "Training loss  0.285 in Step 0\n",
      "Training loss  0.278 in Step 100\n",
      "Training loss  0.313 in Step 200\n",
      "Training loss  0.299 in Step 300\n",
      "Training loss  0.275 in Step 400\n",
      "Training loss  0.296 in Step 500\n",
      "Training loss  0.285 in Step 600\n",
      "Training loss  0.275 in Step 700\n",
      "Training loss  0.278 in Step 800\n",
      "Training loss  0.246 in Step 900\n",
      "Training loss  0.299 in Step 1000\n",
      "Training loss  0.288 in Step 1100\n",
      "Training loss  0.277 in Step 1200\n",
      "Training loss  0.283 in Step 1300\n",
      "Training loss  0.294 in Step 1400\n",
      "Training loss  0.282 in Step 1500\n",
      "Training loss  0.264 in Step 1600\n",
      "Training loss  0.287 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.275 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.299 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.286 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.275 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.295 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 42\n",
      "Training loss  0.287 in Step 0\n",
      "Training loss  0.280 in Step 100\n",
      "Training loss  0.286 in Step 200\n",
      "Training loss  0.255 in Step 300\n",
      "Training loss  0.295 in Step 400\n",
      "Training loss  0.306 in Step 500\n",
      "Training loss  0.293 in Step 600\n",
      "Training loss  0.300 in Step 700\n",
      "Training loss  0.287 in Step 800\n",
      "Training loss  0.288 in Step 900\n",
      "Training loss  0.296 in Step 1000\n",
      "Training loss  0.296 in Step 1100\n",
      "Training loss  0.268 in Step 1200\n",
      "Training loss  0.240 in Step 1300\n",
      "Training loss  0.266 in Step 1400\n",
      "Training loss  0.284 in Step 1500\n",
      "Training loss  0.275 in Step 1600\n",
      "Training loss  0.299 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.301 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.284 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.295 in Step 420\n",
      "Valid loss  0.293 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 43\n",
      "Training loss  0.271 in Step 0\n",
      "Training loss  0.303 in Step 100\n",
      "Training loss  0.282 in Step 200\n",
      "Training loss  0.285 in Step 300\n",
      "Training loss  0.286 in Step 400\n",
      "Training loss  0.288 in Step 500\n",
      "Training loss  0.360 in Step 600\n",
      "Training loss  0.306 in Step 700\n",
      "Training loss  0.297 in Step 800\n",
      "Training loss  0.303 in Step 900\n",
      "Training loss  0.289 in Step 1000\n",
      "Training loss  0.293 in Step 1100\n",
      "Training loss  0.296 in Step 1200\n",
      "Training loss  0.315 in Step 1300\n",
      "Training loss  0.289 in Step 1400\n",
      "Training loss  0.286 in Step 1500\n",
      "Training loss  0.283 in Step 1600\n",
      "Training loss  0.281 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.295 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.306 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 44\n",
      "Training loss  0.286 in Step 0\n",
      "Training loss  0.293 in Step 100\n",
      "Training loss  0.254 in Step 200\n",
      "Training loss  0.307 in Step 300\n",
      "Training loss  0.287 in Step 400\n",
      "Training loss  0.255 in Step 500\n",
      "Training loss  0.296 in Step 600\n",
      "Training loss  0.281 in Step 700\n",
      "Training loss  0.300 in Step 800\n",
      "Training loss  0.275 in Step 900\n",
      "Training loss  0.270 in Step 1000\n",
      "Training loss  0.273 in Step 1100\n",
      "Training loss  0.272 in Step 1200\n",
      "Training loss  0.288 in Step 1300\n",
      "Training loss  0.290 in Step 1400\n",
      "Training loss  0.291 in Step 1500\n",
      "Training loss  0.282 in Step 1600\n",
      "Training loss  0.260 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.301 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.306 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 45\n",
      "Training loss  0.303 in Step 0\n",
      "Training loss  0.273 in Step 100\n",
      "Training loss  0.302 in Step 200\n",
      "Training loss  0.297 in Step 300\n",
      "Training loss  0.303 in Step 400\n",
      "Training loss  0.274 in Step 500\n",
      "Training loss  0.288 in Step 600\n",
      "Training loss  0.272 in Step 700\n",
      "Training loss  0.276 in Step 800\n",
      "Training loss  0.297 in Step 900\n",
      "Training loss  0.300 in Step 1000\n",
      "Training loss  0.320 in Step 1100\n",
      "Training loss  0.273 in Step 1200\n",
      "Training loss  0.288 in Step 1300\n",
      "Training loss  0.284 in Step 1400\n",
      "Training loss  0.269 in Step 1500\n",
      "Training loss  0.315 in Step 1600\n",
      "Training loss  0.274 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.287 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.294 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.268 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 46\n",
      "Training loss  0.288 in Step 0\n",
      "Training loss  0.295 in Step 100\n",
      "Training loss  0.281 in Step 200\n",
      "Training loss  0.288 in Step 300\n",
      "Training loss  0.278 in Step 400\n",
      "Training loss  0.263 in Step 500\n",
      "Training loss  0.289 in Step 600\n",
      "Training loss  0.291 in Step 700\n",
      "Training loss  0.276 in Step 800\n",
      "Training loss  0.288 in Step 900\n",
      "Training loss  0.302 in Step 1000\n",
      "Training loss  0.285 in Step 1100\n",
      "Training loss  0.269 in Step 1200\n",
      "Training loss  0.273 in Step 1300\n",
      "Training loss  0.301 in Step 1400\n",
      "Training loss  0.289 in Step 1500\n",
      "Training loss  0.289 in Step 1600\n",
      "Training loss  0.281 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.301 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.293 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.293 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n",
      "Epoch 47\n",
      "Training loss  0.302 in Step 0\n",
      "Training loss  0.292 in Step 100\n",
      "Training loss  0.303 in Step 200\n",
      "Training loss  0.320 in Step 300\n",
      "Training loss  0.297 in Step 400\n",
      "Training loss  0.289 in Step 500\n",
      "Training loss  0.291 in Step 600\n",
      "Training loss  0.314 in Step 700\n",
      "Training loss  0.276 in Step 800\n",
      "Training loss  0.276 in Step 900\n",
      "Training loss  0.312 in Step 1000\n",
      "Training loss  0.283 in Step 1100\n",
      "Training loss  0.261 in Step 1200\n",
      "Training loss  0.270 in Step 1300\n",
      "Training loss  0.305 in Step 1400\n",
      "Training loss  0.318 in Step 1500\n",
      "Training loss  0.308 in Step 1600\n",
      "Training loss  0.281 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.302 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.289 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.294 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.275 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 48\n",
      "Training loss  0.299 in Step 0\n",
      "Training loss  0.304 in Step 100\n",
      "Training loss  0.303 in Step 200\n",
      "Training loss  0.262 in Step 300\n",
      "Training loss  0.304 in Step 400\n",
      "Training loss  0.299 in Step 500\n",
      "Training loss  0.292 in Step 600\n",
      "Training loss  0.271 in Step 700\n",
      "Training loss  0.275 in Step 800\n",
      "Training loss  0.271 in Step 900\n",
      "Training loss  0.300 in Step 1000\n",
      "Training loss  0.286 in Step 1100\n",
      "Training loss  0.283 in Step 1200\n",
      "Training loss  0.274 in Step 1300\n",
      "Training loss  0.305 in Step 1400\n",
      "Training loss  0.285 in Step 1500\n",
      "Training loss  0.306 in Step 1600\n",
      "Training loss  0.316 in Step 1700\n",
      "Training loss  0.287\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.298 in Step 20\n",
      "Valid loss  0.303 in Step 30\n",
      "Valid loss  0.258 in Step 40\n",
      "Valid loss  0.301 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.288 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.277 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.307 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.299 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.290 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.292 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.285 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.280 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.303 in Step 400\n",
      "Valid loss  0.265 in Step 410\n",
      "Valid loss  0.297 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.264 in Step 440\n",
      "Valid loss  0.287\n",
      "Epoch 49\n",
      "Training loss  0.300 in Step 0\n",
      "Training loss  0.300 in Step 100\n",
      "Training loss  0.301 in Step 200\n",
      "Training loss  0.313 in Step 300\n",
      "Training loss  0.276 in Step 400\n",
      "Training loss  0.305 in Step 500\n",
      "Training loss  0.321 in Step 600\n",
      "Training loss  0.262 in Step 700\n",
      "Training loss  0.266 in Step 800\n",
      "Training loss  0.282 in Step 900\n",
      "Training loss  0.277 in Step 1000\n",
      "Training loss  0.282 in Step 1100\n",
      "Training loss  0.295 in Step 1200\n",
      "Training loss  0.277 in Step 1300\n",
      "Training loss  0.298 in Step 1400\n",
      "Training loss  0.273 in Step 1500\n",
      "Training loss  0.270 in Step 1600\n",
      "Training loss  0.308 in Step 1700\n",
      "Training loss  0.286\n",
      "Training timepoint saved\n",
      "Valid loss  0.276 in Step 0\n",
      "Valid loss  0.288 in Step 10\n",
      "Valid loss  0.297 in Step 20\n",
      "Valid loss  0.301 in Step 30\n",
      "Valid loss  0.257 in Step 40\n",
      "Valid loss  0.300 in Step 50\n",
      "Valid loss  0.307 in Step 60\n",
      "Valid loss  0.300 in Step 70\n",
      "Valid loss  0.286 in Step 80\n",
      "Valid loss  0.289 in Step 90\n",
      "Valid loss  0.288 in Step 100\n",
      "Valid loss  0.293 in Step 110\n",
      "Valid loss  0.276 in Step 120\n",
      "Valid loss  0.291 in Step 130\n",
      "Valid loss  0.288 in Step 140\n",
      "Valid loss  0.282 in Step 150\n",
      "Valid loss  0.308 in Step 160\n",
      "Valid loss  0.296 in Step 170\n",
      "Valid loss  0.287 in Step 180\n",
      "Valid loss  0.256 in Step 190\n",
      "Valid loss  0.269 in Step 200\n",
      "Valid loss  0.293 in Step 210\n",
      "Valid loss  0.294 in Step 220\n",
      "Valid loss  0.296 in Step 230\n",
      "Valid loss  0.276 in Step 240\n",
      "Valid loss  0.300 in Step 250\n",
      "Valid loss  0.269 in Step 260\n",
      "Valid loss  0.316 in Step 270\n",
      "Valid loss  0.287 in Step 280\n",
      "Valid loss  0.289 in Step 290\n",
      "Valid loss  0.292 in Step 300\n",
      "Valid loss  0.294 in Step 310\n",
      "Valid loss  0.291 in Step 320\n",
      "Valid loss  0.305 in Step 330\n",
      "Valid loss  0.284 in Step 340\n",
      "Valid loss  0.263 in Step 350\n",
      "Valid loss  0.293 in Step 360\n",
      "Valid loss  0.279 in Step 370\n",
      "Valid loss  0.271 in Step 380\n",
      "Valid loss  0.274 in Step 390\n",
      "Valid loss  0.302 in Step 400\n",
      "Valid loss  0.264 in Step 410\n",
      "Valid loss  0.296 in Step 420\n",
      "Valid loss  0.294 in Step 430\n",
      "Valid loss  0.263 in Step 440\n",
      "Valid loss  0.286\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "train_losses.save()\n",
    "\n",
    "valid_losses.save()\n",
    "\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1e487cc610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This model should converge to loss around 0.49x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
