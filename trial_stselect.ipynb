{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sibilant + stop Deaspiration Phenomenon Selection\n",
    "\n",
    "Here we want to work out how we can select only those instances (words) with only target seqs. But one problem is that we don't have teh exact recording files on that granularity level. We only have cut words and cut phones. But our target is something like two or three phones. This is a problem. \n",
    "\n",
    "However, considering that our target is not very long, I am thinking of finding all valid instances and integrate them into recordings. Then each time we train, read from the integrated recordings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE   # one type of clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import block_diag\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from model_padding import generate_mask_from_lengths_mat, mask_it\n",
    "from paths import *\n",
    "from misc_my_utils import *\n",
    "from model_loss import *\n",
    "from model_model import CTCPredNetV1 as TheLearner\n",
    "from model_dataset import WordDatasetPath as ThisDataset\n",
    "from model_dataset import Normalizer, DeNormalizer, TokenMap\n",
    "from model_dataset import MelSpecTransformDB as TheTransform\n",
    "from model_dataset import DS_Tools\n",
    "from reshandler import DictResHandler\n",
    "from misc_progress_bar import draw_progress_bar\n",
    "from test_bnd_detect_tools import *\n",
    "from misc_tools import PathUtils as PU\n",
    "from misc_tools import AudioCut, ARPABET\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dir = train_cut_word_\n",
    "train_guide_path = os.path.join(src_, \"guide_train.csv\")\n",
    "valid_guide_path = os.path.join(src_, \"guide_validation.csv\")\n",
    "test_guide_path = os.path.join(src_, \"guide_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in guide file\n",
    "guide_file = pd.read_csv(valid_guide_path)\n",
    "# filtering out is not necessary, since we only include wuid for encoded words\n",
    "guide_file = guide_file[~guide_file[\"segment_nostress\"].isin([\"sil\", \"sp\", \"spn\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_guide = guide_file.groupby('wuid').apply(lambda x: ([row[\"segment\"] for index, row in x.iterrows()]).tolist()\n",
    "words_guide_str = guide_file.groupby('wuid').apply(lambda x: (\" \".join([row[\"segment\"] for index, row in x.iterrows()]), x[\"wuid\"].iloc[0])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_span_to_list_indices(phoneme_str, pattern):\n",
    "    # Split the string into a list of phonemes\n",
    "    phonemes = phoneme_str.split()\n",
    "    # Calculate the cumulative lengths including spaces (add 1 for each space)\n",
    "    cumulative_lengths = [0]  # Start with 0 for the first phoneme\n",
    "    for phoneme in phonemes:\n",
    "        # Add the length of the current phoneme and a space (except for the last one)\n",
    "        cumulative_lengths.append(cumulative_lengths[-1] + len(phoneme) + 1)\n",
    "    # Find all matches using re.finditer\n",
    "    matches = list(re.finditer(pattern, phoneme_str))\n",
    "    # Map regex span indices to phoneme list indices\n",
    "    match_indices = []\n",
    "    for match in matches:\n",
    "        start, end = match.span()\n",
    "        # Find the phoneme list index corresponding to the start of the match\n",
    "        list_start = next(i for i, length in enumerate(cumulative_lengths) if length > start) - 1\n",
    "        # Find the phoneme list index corresponding to the end of the match (subtract 1 because end is exclusive)\n",
    "        list_end = next(i for i, length in enumerate(cumulative_lengths) if length >= end) - 1\n",
    "        match_indices.append((list_start, list_end))\n",
    "    return match_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_pattern = '^[PTK] (?!R)'\n",
    "sibstop_pattern = 'S [PTK] (?!R)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "phoneme_str = \"T A S T P A\"\n",
    "match_indices = regex_span_to_list_indices(phoneme_str, sibstop_pattern)\n",
    "print(match_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_indices = [name for i, (word, name) in enumerate(words_guide_str) if re.search(stop_pattern, word)]\n",
    "sibstop_indices = [name for i, (word, name) in enumerate(words_guide_str) if re.search(sibstop_pattern, word)]\n",
    "sibstop_subidx = [regex_span_to_list_indices(word, sibstop_pattern) for i, (word, name) in enumerate(words_guide_str) if re.search(sibstop_pattern, word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 2606)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_indices), len(sibstop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibstops = guide_file[guide_file[\"wuid\"].isin(sibstop_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment                                               AE0\n",
       "file                                        103-1240-0001\n",
       "id                                                    130\n",
       "startTime                                           10.49\n",
       "endTime                                             10.57\n",
       "nSample                                              1280\n",
       "word_id                                              36.0\n",
       "word                                              cascade\n",
       "in_id                                                 2.0\n",
       "segment_nostress                                       AE\n",
       "stress_type                                             0\n",
       "phone_path          103/1240/0001/103-1240-0001-0130.flac\n",
       "word_path           103/1240/0001/103-1240-0001-0036.flac\n",
       "speaker                                               103\n",
       "word_startTime                                      10.36\n",
       "word_endTime                                         11.0\n",
       "word_nSample                                      10240.0\n",
       "wuid                                   103-1240-0001-0036\n",
       "Name: 276, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibstops[(sibstops[\"wuid\"] == \"103-1240-0001-0036\") & (sibstops[\"in_id\"].isin((1, 2)))].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(df, name_list, target_idx_list=None): \n",
    "    sibilant_list = []\n",
    "    sibilant_path = []\n",
    "    sibilant_startTime = []\n",
    "    sibilant_endTime = []\n",
    "    stop_list = []\n",
    "    stop_path = []\n",
    "    stop_startTime = []\n",
    "    stop_endTime = []\n",
    "    speaker_list = []\n",
    "    wuid_list = []\n",
    "    for name in name_list: \n",
    "        # this is one word, there might be multiple matching cases\n",
    "        word_phonemes = df[df[\"wuid\"] == name]\n",
    "        for target in target_idx_list: \n",
    "            target_phonemes = word_phonemes[word_phonemes[\"in_id\"].isin(target)]\n",
    "            sib = target_phonemes.iloc[0]\n",
    "            stop = target_phonemes.iloc[1]\n",
    "            sibilant_list.append(sib[\"segment_nostress\"])\n",
    "            sibilant_path.append(sib[\"phone_path\"])\n",
    "            sibilant_startTime.append(sib[\"startTime\"])\n",
    "            sibilant_endTime.append(sib[\"endTime\"])\n",
    "\n",
    "            stop_list.append(stop[\"segment_nostress\"])\n",
    "            stop_path.append(stop[\"phone_path\"])\n",
    "            stop_startTime.append(stop[\"startTime\"])\n",
    "            stop_endTime.append(stop[\"endTime\"])\n",
    "\n",
    "            speaker_list.append(sib[\"speaker\"])\n",
    "            wuid_list.append(name)\n",
    "    out_dict = {\n",
    "        \"sibilant\": sibilant_list, \n",
    "        \"stop\": stop_list, \n",
    "        \"sibilant_path\": sibilant_path, \n",
    "        \"stop_path\": stop_path, \n",
    "        \"sibilant_startTime\": sibilant_startTime, \n",
    "        \"sibilant_endTime\": sibilant_endTime, \n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>nSample</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>in_id</th>\n",
       "      <th>segment_nostress</th>\n",
       "      <th>stress_type</th>\n",
       "      <th>phone_path</th>\n",
       "      <th>word_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_startTime</th>\n",
       "      <th>word_endTime</th>\n",
       "      <th>word_nSample</th>\n",
       "      <th>wuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>103-1240-0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>SNA</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0001.flac</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0000.flac</td>\n",
       "      <td>103</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>103-1240-0000-0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE1</td>\n",
       "      <td>103-1240-0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AE</td>\n",
       "      <td>1</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0002.flac</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0000.flac</td>\n",
       "      <td>103</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>103-1240-0000-0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>103-1240-0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>3.0</td>\n",
       "      <td>P</td>\n",
       "      <td>SNA</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0003.flac</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0000.flac</td>\n",
       "      <td>103</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>103-1240-0000-0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>103-1240-0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>T</td>\n",
       "      <td>SNA</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0004.flac</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0000.flac</td>\n",
       "      <td>103</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>103-1240-0000-0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ER0</td>\n",
       "      <td>103-1240-0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chapter</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ER</td>\n",
       "      <td>0</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0005.flac</td>\n",
       "      <td>103/1240/0000/103-1240-0000-0000.flac</td>\n",
       "      <td>103</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>103-1240-0000-0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383565</th>\n",
       "      <td>IH1</td>\n",
       "      <td>909-131045-0043</td>\n",
       "      <td>164</td>\n",
       "      <td>14.70</td>\n",
       "      <td>14.79</td>\n",
       "      <td>1440</td>\n",
       "      <td>35.0</td>\n",
       "      <td>opinion</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IH</td>\n",
       "      <td>1</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0164.flac</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0035.flac</td>\n",
       "      <td>909</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.08</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>909-131045-0043-0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383566</th>\n",
       "      <td>N</td>\n",
       "      <td>909-131045-0043</td>\n",
       "      <td>165</td>\n",
       "      <td>14.79</td>\n",
       "      <td>14.86</td>\n",
       "      <td>1120</td>\n",
       "      <td>35.0</td>\n",
       "      <td>opinion</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N</td>\n",
       "      <td>SNA</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0165.flac</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0035.flac</td>\n",
       "      <td>909</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.08</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>909-131045-0043-0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383567</th>\n",
       "      <td>Y</td>\n",
       "      <td>909-131045-0043</td>\n",
       "      <td>166</td>\n",
       "      <td>14.86</td>\n",
       "      <td>14.94</td>\n",
       "      <td>1280</td>\n",
       "      <td>35.0</td>\n",
       "      <td>opinion</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>SNA</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0166.flac</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0035.flac</td>\n",
       "      <td>909</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.08</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>909-131045-0043-0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383568</th>\n",
       "      <td>AH0</td>\n",
       "      <td>909-131045-0043</td>\n",
       "      <td>167</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.98</td>\n",
       "      <td>640</td>\n",
       "      <td>35.0</td>\n",
       "      <td>opinion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>0</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0167.flac</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0035.flac</td>\n",
       "      <td>909</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.08</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>909-131045-0043-0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383569</th>\n",
       "      <td>N</td>\n",
       "      <td>909-131045-0043</td>\n",
       "      <td>168</td>\n",
       "      <td>14.98</td>\n",
       "      <td>15.08</td>\n",
       "      <td>1600</td>\n",
       "      <td>35.0</td>\n",
       "      <td>opinion</td>\n",
       "      <td>7.0</td>\n",
       "      <td>N</td>\n",
       "      <td>SNA</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0168.flac</td>\n",
       "      <td>909/131045/0043/909-131045-0043-0035.flac</td>\n",
       "      <td>909</td>\n",
       "      <td>14.53</td>\n",
       "      <td>15.08</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>909-131045-0043-0035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365147 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment             file   id  startTime  endTime  nSample  word_id  \\\n",
       "1           CH    103-1240-0000    1       0.44     0.57     2080      0.0   \n",
       "2          AE1    103-1240-0000    2       0.57     0.63      960      0.0   \n",
       "3            P    103-1240-0000    3       0.63     0.70     1120      0.0   \n",
       "4            T    103-1240-0000    4       0.70     0.75      800      0.0   \n",
       "5          ER0    103-1240-0000    5       0.75     0.81      960      0.0   \n",
       "...        ...              ...  ...        ...      ...      ...      ...   \n",
       "383565     IH1  909-131045-0043  164      14.70    14.79     1440     35.0   \n",
       "383566       N  909-131045-0043  165      14.79    14.86     1120     35.0   \n",
       "383567       Y  909-131045-0043  166      14.86    14.94     1280     35.0   \n",
       "383568     AH0  909-131045-0043  167      14.94    14.98      640     35.0   \n",
       "383569       N  909-131045-0043  168      14.98    15.08     1600     35.0   \n",
       "\n",
       "           word  in_id segment_nostress stress_type  \\\n",
       "1       chapter    1.0               CH         SNA   \n",
       "2       chapter    2.0               AE           1   \n",
       "3       chapter    3.0                P         SNA   \n",
       "4       chapter    4.0                T         SNA   \n",
       "5       chapter    5.0               ER           0   \n",
       "...         ...    ...              ...         ...   \n",
       "383565  opinion    3.0               IH           1   \n",
       "383566  opinion    4.0                N         SNA   \n",
       "383567  opinion    5.0                Y         SNA   \n",
       "383568  opinion    6.0               AH           0   \n",
       "383569  opinion    7.0                N         SNA   \n",
       "\n",
       "                                       phone_path  \\\n",
       "1           103/1240/0000/103-1240-0000-0001.flac   \n",
       "2           103/1240/0000/103-1240-0000-0002.flac   \n",
       "3           103/1240/0000/103-1240-0000-0003.flac   \n",
       "4           103/1240/0000/103-1240-0000-0004.flac   \n",
       "5           103/1240/0000/103-1240-0000-0005.flac   \n",
       "...                                           ...   \n",
       "383565  909/131045/0043/909-131045-0043-0164.flac   \n",
       "383566  909/131045/0043/909-131045-0043-0165.flac   \n",
       "383567  909/131045/0043/909-131045-0043-0166.flac   \n",
       "383568  909/131045/0043/909-131045-0043-0167.flac   \n",
       "383569  909/131045/0043/909-131045-0043-0168.flac   \n",
       "\n",
       "                                        word_path  speaker  word_startTime  \\\n",
       "1           103/1240/0000/103-1240-0000-0000.flac      103            0.44   \n",
       "2           103/1240/0000/103-1240-0000-0000.flac      103            0.44   \n",
       "3           103/1240/0000/103-1240-0000-0000.flac      103            0.44   \n",
       "4           103/1240/0000/103-1240-0000-0000.flac      103            0.44   \n",
       "5           103/1240/0000/103-1240-0000-0000.flac      103            0.44   \n",
       "...                                           ...      ...             ...   \n",
       "383565  909/131045/0043/909-131045-0043-0035.flac      909           14.53   \n",
       "383566  909/131045/0043/909-131045-0043-0035.flac      909           14.53   \n",
       "383567  909/131045/0043/909-131045-0043-0035.flac      909           14.53   \n",
       "383568  909/131045/0043/909-131045-0043-0035.flac      909           14.53   \n",
       "383569  909/131045/0043/909-131045-0043-0035.flac      909           14.53   \n",
       "\n",
       "        word_endTime  word_nSample                  wuid  \n",
       "1               0.81        5920.0    103-1240-0000-0000  \n",
       "2               0.81        5920.0    103-1240-0000-0000  \n",
       "3               0.81        5920.0    103-1240-0000-0000  \n",
       "4               0.81        5920.0    103-1240-0000-0000  \n",
       "5               0.81        5920.0    103-1240-0000-0000  \n",
       "...              ...           ...                   ...  \n",
       "383565         15.08        8800.0  909-131045-0043-0035  \n",
       "383566         15.08        8800.0  909-131045-0043-0035  \n",
       "383567         15.08        8800.0  909-131045-0043-0035  \n",
       "383568         15.08        8800.0  909-131045-0043-0035  \n",
       "383569         15.08        8800.0  909-131045-0043-0035  \n",
       "\n",
       "[365147 rows x 18 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
