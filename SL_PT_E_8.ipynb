{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Phone Training - English\n",
    "Version 2:  This version has a core structure using HM-RNN. Unlike traditional approaches, our model can automatically detect boundaries. It is trainable and updates the upper layer only upon detecting boundaries. This makes our model suitable for detecting boundaries and capturing the representations of sub-segments based on these detected boundaries. In essence, our model performs boundary detection and representation learning simultaneously.\n",
    "\n",
    "Version 3: this version completed the coding of the core model structure as well as the dataloading, preprocessing, padding and loss calculation processes. At present we only try mel->model -> mel structure, since wav <> wav would introduce extra complexion. In addition, our model will process padded multi-batch tensors as normal but count for the paddings (ignore paddings) during calculation. \n",
    "\n",
    "Version 4: this version is testing whether our hmrnn is not working. It imports a modified version of model: model_test\n",
    "\n",
    "Version 5: this version is testing phase two, mainly working on preprocessing modifications. \n",
    "\n",
    "Version 6: this version deletes lin2, as this will destroy the predicted segmental boundaries. \n",
    "\n",
    "Version 7: After learning from Dr Coupe, I added an additional linear layer. Also, I am trying to make the first inter-linear dimension to be even larger, so as to enrich the representation power of our model. \n",
    "\n",
    "Version 8: The problem of is almost every-timestep-boundary is lingering. So this version is trying to modify the loss function so that it could regularize and punish the model if it wants to optimize itself by passing on each timestep's information to decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import PhonLearn_Net\n",
    "from model import PhonLearn_Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范用语；规定两种方式：全加载；按rec加载（舍弃了按chunk加载，处理起来更简单）\n",
    "# RandomPhoneDataset; AnnoPhoneDataset; AnnoSeqDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset that loads cutted wave files from disk and returns input-output pairs for\n",
    "    training autoencoder. \n",
    "    \n",
    "    Version 3: wav -> mel\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, load_dir, load_control_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the class by reading a CSV file and merging the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        The function reads the CSV file from the provided control path, extracts the \"rec\" and \"idx\" columns,\n",
    "        and concatenates the values from these columns using an underscore. It then appends the \".wav\" extension\n",
    "        to each of the merged strings and converts the merged pandas Series to a list, which is assigned to\n",
    "        the 'dataset' attribute of the class.\n",
    "\n",
    "        Args:\n",
    "        load_dir (str): The directory containing the files to load.\n",
    "        load_control_path (str): The path to the CSV file containing the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        Attributes:\n",
    "        dataset (list): A list of merged strings from the \"rec\" and \"idx\" columns, with the \".wav\" extension.\n",
    "        \"\"\"\n",
    "        control_file = pd.read_csv(load_control_path)\n",
    "        control_file = control_file[control_file['n_frames'] > 400]\n",
    "        control_file = control_file[control_file['duration'] <= 2.0]\n",
    "        \n",
    "        # Extract the \"rec\" and \"idx\" columns\n",
    "        rec_col = control_file['rec'].astype(str)\n",
    "        idx_col = control_file['idx'].astype(str).str.zfill(8)\n",
    "        \n",
    "        # Merge the two columns by concatenating the strings with '_' and append extension name\n",
    "        merged_col = rec_col + '_' + idx_col + \".wav\"\n",
    "        \n",
    "        self.dataset = merged_col.tolist()\n",
    "        self.load_dir = load_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: The number of input-output pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input_data, output_data) for the given index.\n",
    "\n",
    "        The function first checks if the provided index is a tensor, and if so, converts it to a list.\n",
    "        It then constructs the file path for the .wav file using the dataset attribute and the provided index.\n",
    "        The .wav file is loaded using torchaudio, and its data is normalized. If a transform is provided,\n",
    "        the data is transformed using the specified transform. Finally, the input_data and output_data are\n",
    "        set to the same data (creating a tuple), and the tuple is returned.\n",
    "\n",
    "        Args:\n",
    "        idx (int or torch.Tensor): The index of the desired data.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing input_data and output_data, both of which are the audio data\n",
    "               from the .wav file at the specified index.\n",
    "\n",
    "        Note: \n",
    "        This function assumes that the class has the following attributes:\n",
    "        - self.load_dir (str): The directory containing the .wav files.\n",
    "        - self.dataset (list): A list of .wav file names.\n",
    "        - self.transform (callable, optional): An optional transform to apply to the audio data.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        wav_name = os.path.join(self.load_dir,\n",
    "                                self.dataset[idx])\n",
    "        \n",
    "        data, sample_rate = torchaudio.load(wav_name, normalize=True)\n",
    "        if self.transform:\n",
    "            data = self.transform(data, sr=sample_rate)\n",
    "        \n",
    "        # # Prepare for possible in-out discrepencies in the future\n",
    "        # input_data = data\n",
    "        # output_data = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "def collate_fn(xx):\n",
    "    # only working for one data at the moment\n",
    "    batch_first = True\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=batch_first, padding_value=0)\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "\n",
    "class MyTransform(nn.Module): \n",
    "    def __init__(self, sample_rate, n_fft): \n",
    "        super().__init__()\n",
    "        # self.transform = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, n_mels=64)\n",
    "        # self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        # self.transform = torchaudio.transforms.MFCC(n_mfcc=13)\n",
    "    \n",
    "    def forward(self, waveform, sr=16000): \n",
    "        # extract mfcc\n",
    "        feature = torchaudio.compliance.kaldi.mfcc(waveform, sample_frequency=sr)\n",
    "\n",
    "        # add deltas\n",
    "        d1 = torchaudio.functional.compute_deltas(feature)\n",
    "        d2 = torchaudio.functional.compute_deltas(d1)\n",
    "        feature = torch.cat([feature, d1, d2], dim=-1)\n",
    "\n",
    "        # Apply normalization (CMVN)\n",
    "        eps = 1e-9\n",
    "        mean = feature.mean(0, keepdim=True)\n",
    "        std = feature.std(0, keepdim=True, unbiased=False)\n",
    "        # print(feature.shape)\n",
    "        # print(mean, std)\n",
    "        feature = (feature - mean) / (std + eps)\n",
    "\n",
    "        # mel_spec = self.transform(waveform)\n",
    "        # # mel_spec = self.to_db(mel_spec)\n",
    "        # mel_spec = mel_spec.squeeze()\n",
    "        # mel_spec = mel_spec.permute(1, 0) # (F, L) -> (L, F)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# INPUT_DIM = 128\n",
    "# OUTPUT_DIM = 128\n",
    "\n",
    "INPUT_DIM = 39\n",
    "OUTPUT_DIM = 13\n",
    "\n",
    "INTER_DIM_0 = 64\n",
    "INTER_DIM_1 = 32\n",
    "INTER_DIM_2 = 16\n",
    "INTER_DIM_3 = 3\n",
    "\n",
    "SIZE_LIST = [INTER_DIM_2, INTER_DIM_3]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = CombinedLoss(masked_recon_loss, alpha=0.9)\n",
    "# model = TwoRNNAttn(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "#                       in2_size=INTER_DIM_0, hid_size=INTER_DIM_3, out_size=OUTPUT_DIM)\n",
    "model = PhonLearn_Net(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "                      in2_size=INTER_DIM_0, in3_size=INTER_DIM_1, hid_size=SIZE_LIST[1], out_size=OUTPUT_DIM)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhonLearn_Net(\n",
       "  (encoder): Encoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=39, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (rnn): HM_LSTM(\n",
       "      (cell_1): HM_LSTMCell()\n",
       "      (cell_2): HM_LSTMCell()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=13, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (rnn): LSTM(3, 32, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=32, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=32, bias=True)\n",
       "    )\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=32, out_features=13, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14799"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "ts = str(get_timestamp())\n",
    "# ts = \"0623152604\"\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "save_train1hist_name = \"train_hist_recon{}.hst\".format(ts)\n",
    "save_train2hist_name = \"train_hist_reg{}.hst\".format(ts)\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)\n",
    "save_val1hist_name = \"val_hist_recon{}.hst\".format(ts)\n",
    "save_val2hist_name = \"val_hist_reg{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "train_recon_losses = LossRecorder(model_save_dir + save_train1hist_name)\n",
    "train_reg_losses = LossRecorder(model_save_dir + save_train2hist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "valid_recon_losses = LossRecorder(model_save_dir + save_val1hist_name)\n",
    "valid_reg_losses = LossRecorder(model_save_dir + save_val2hist_name)\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    # model_name = last_model_namec\n",
    "    model_name = \"PT_0623152604_29_full.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model = PhonLearn_Net(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "                      in2_size=INTER_DIM_0, hid_size=SIZE_LIST[1], out_size=OUTPUT_DIM)\n",
    "    model.load_state_dict(state)\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = PhoneDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "# small_len = int(0.1 * len(ds))\n",
    "# other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "# ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "valid_len = len(ds) - train_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_recon_loss = 0.\n",
    "        train_reg_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch = x.size(0)\n",
    "            batch, length, dim = x.shape\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight, z_2 = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "\n",
    "            # print(y)\n",
    "            # print(recon_x)\n",
    "            # raise Exception\n",
    "\n",
    "            recon_loss_val, reg_loss_val = model_loss.get_loss(recon_x, y, x_mask, z_2)\n",
    "            # reg_loss_val = torch.tensor(0)\n",
    "            loss = recon_loss_val + reg_loss_val\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_recon_loss += recon_loss_val.item()\n",
    "            train_reg_loss += reg_loss_val.item()\n",
    "\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 1 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f}: {recon_loss_val: .3f} + {reg_loss_val: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        train_recon_losses.append(train_recon_loss / train_num)\n",
    "        train_reg_losses.append(train_reg_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}: {train_recon_loss / train_num: .3f} + {train_reg_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_recon_loss = 0.\n",
    "        valid_reg_loss = 0.\n",
    "\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            # batch = x.size(0)\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight, z_2 = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "\n",
    "            recon_loss_val, reg_loss_val = model_loss.get_loss(recon_x, y, x_mask, z_2)\n",
    "            loss = recon_loss_val + reg_loss_val\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_recon_loss += recon_loss_val.item()\n",
    "            valid_reg_loss += reg_loss_val.item()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f}: {recon_loss_val: .3f} + {reg_loss_val: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "        valid_recon_losses.append(valid_recon_loss / valid_num)\n",
    "        valid_recon_losses.append(valid_recon_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}: {valid_recon_loss / valid_num: .3f} + {valid_reg_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 0\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 1\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 2\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 3\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 4\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 5\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 6\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 7\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 8\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 9\n",
      "Training loss  1.100:  1.000 +  0.100 in Step 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[1;32m----> 2\u001b[0m     train()\n",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m train_reg_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[0;32m      9\u001b[0m train_num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)    \u001b[39m# train_loader\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m idx, (x, x_lens) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m     batch \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m, in \u001b[0;36mPhoneDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m data, sample_rate \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mload(wav_name, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> 80\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(data, sr\u001b[39m=\u001b[39;49msample_rate)\n\u001b[0;32m     82\u001b[0m \u001b[39m# # Prepare for possible in-out discrepencies in the future\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m# input_data = data\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m# output_data = data\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 109\u001b[0m, in \u001b[0;36mMyTransform.forward\u001b[1;34m(self, waveform, sr)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m# add deltas\u001b[39;00m\n\u001b[0;32m    108\u001b[0m d1 \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcompute_deltas(feature)\n\u001b[1;32m--> 109\u001b[0m d2 \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcompute_deltas(d1)\n\u001b[0;32m    110\u001b[0m feature \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([feature, d1, d2], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39m# Apply normalization (CMVN)\u001b[39;00m\n",
      "File \u001b[1;32ma:\\ProgramData\\anaconda3\\envs\\wavln\\lib\\site-packages\\torchaudio\\functional\\functional.py:974\u001b[0m, in \u001b[0;36mcompute_deltas\u001b[1;34m(specgram, win_length, mode)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39m# twice sum of integer squared\u001b[39;00m\n\u001b[0;32m    972\u001b[0m denom \u001b[39m=\u001b[39m n \u001b[39m*\u001b[39m (n \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m n \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m--> 974\u001b[0m specgram \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mpad(specgram, (n, n), mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m    976\u001b[0m kernel \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m-\u001b[39mn, n \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mdtype)\u001b[39m.\u001b[39mrepeat(specgram\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    978\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mconv1d(specgram, kernel, groups\u001b[39m=\u001b[39mspecgram\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m denom\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "valid_losses.save()\n",
    "train_losses.save()\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0bebd359d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_UcLyHcQMGu0",
    "outputId": "4b56200c-1dc4-4286-b51a-d19e9c75ddd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0613160106'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E6-6g-sW3zeg"
   },
   "source": [
    "We can see that with Sigmoid the model seems to perform slightly worse, but this should not be a big problem. Then the decision might depend more on whether the use of it is common and justifiable. I don't think it's common, and the use of it does not seem to be analytically necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNJ0DAlaWrEE"
   },
   "outputs": [],
   "source": [
    "class ResAECluster(ResAE): \n",
    "    def __init__(self, input_dim=INPUT_DIM, inter_dim1=INTER_DIM_1, inter_dim2=INTER_DIM_2, inter_dim3=INTER_DIM_3, latent_dim=LATENT_DIM, output_dim=OUTPUT_DIM): \n",
    "        super().__init__(input_dim, inter_dim1, inter_dim2, inter_dim3, latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        org_size = x.size()\n",
    "        batch = org_size[0]\n",
    "        x = x.view(batch, -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        # mu, logvar = h.chunk(2, dim=1)\n",
    "        # z = self.reparameterise(mu, logvar)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFrvzaGC45Gi"
   },
   "outputs": [],
   "source": [
    "seq = \"_01_05\"\n",
    "tags = pd.read_csv(tags_name + seq + \".csv\")\n",
    "gsds = GroundedSoundDataset(tags, test_name + seq + \".npy\")\n",
    "eval_loader = DataLoader(gsds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QARr-C_qpBLb",
    "outputId": "acd5e8ab-1ef6-4968-c205-b437ecfd7b8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'model_english_0130021416_29_full'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXLqyT3PYFkR"
   },
   "outputs": [],
   "source": [
    "# model_name = last_model_name\n",
    "model_name = \"model_english_0130021416_13_full\"\n",
    "model_path = save_dir + model_name + \".pt\"\n",
    "state = torch.load(model_path)\n",
    "model = ResAECluster()\n",
    "model.load_state_dict(state)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "hiddens = None\n",
    "tags = None\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (s, e, t) in enumerate(eval_loader):\n",
    "        s = s.to(device)\n",
    "        hidden = model(s)\n",
    "        hidden = hidden.cpu().data.numpy()\n",
    "\n",
    "        if hiddens is not None: \n",
    "            hiddens = np.concatenate((hiddens, hidden), axis=0)\n",
    "            tags = np.concatenate((tags, t), axis=0)\n",
    "        else: \n",
    "            hiddens = hidden\n",
    "            tags = t\n",
    "num_phones = np.unique(tags).shape[0]\n",
    "kmeansmodel = KMeans(n_clusters=num_phones) # , random_state=0\n",
    "clusters = kmeansmodel.fit_predict(hiddens)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenclusters.npy\", clusters)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenrepresentation.npy\", hiddens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzTuc2Mz6niT"
   },
   "outputs": [],
   "source": [
    "h, c, v = homogeneity_completeness_v_measure(tags, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ogsEovzEbpc",
    "outputId": "3cd43d32-f30c-4fb3-f5eb-945d6dd0ecc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_01_05 0.30813685860010276 0.2726217590636009 0.2892933823757265\n"
     ]
    }
   ],
   "source": [
    "print(seq, h, c, v) # trained on sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMFbNimpx-iJ"
   },
   "outputs": [],
   "source": [
    "# _17_24 0.3429902101084872 0.329164358854651 0.33593508938856537   # 256+8\n",
    "# _17_24 0.3071758873778334 0.2958512436337788 0.3014072290332542   # 128+4\n",
    "# _17_24 0.3048181747064378 0.303971996633573 0.3043944976042278    # 128+2\n",
    "# _17_24 0.3109960687106377 0.3020004935745723 0.3064322772063619   # 256+2, 2res\n",
    "# _17_24 0.27632046463064963 0.29796767719078493 0.28673608598337974    # 256+64+2, 2res, new model\n",
    "# _17_24 0.29619001674434664 0.30940705212658304 0.30265430485339223    # 256+64+4, 0res\n",
    "# _17_24 0.3394207670351701 0.3356821861468344 0.33754112484613674      # 256+64+4, 2res\n",
    "# _17_24 0.3246121630042821 0.3173438869288583 0.32093687897447765  # 256+3, 2res, not very bad. So we may try this. This is error, decoder only having 1 res\n",
    "# _17_24 0.3227539602867097 0.32256957773330264 0.3226617426690128  # 256+3, 2res\n",
    "# _17_24 0.3403517130774138 0.33762198107176034 0.33898135170147237 # 256+3, 1res\n",
    "# _17_24 0.3202704367215642 0.31097127191607643 0.3155523587925454  # 256+3, 0res\n",
    "\n",
    "\n",
    "# _01_05 0.30784101366300043 0.2717512535534188 0.28867252408265254"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gYDGP0Cdf1o"
   },
   "source": [
    "总的来说分成四个，神经网层来进行降维处理，得到的损失比较大，但是 hcv值倒是接近不过，如果能尽量的接近原作的模型结构，我们就不去动它了，所以可能目前来看最好的是保留两个降为层加上两个残差层，最后从256降到2，也许是最好的结果当然降到4也是可以的，都是比较低的维度，不过如果我们想要直接能够，在，可视的空间中画出这些点来，2或者3可能会比四更好一些。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nTTdgp_HokAn"
   },
   "source": [
    "从使用不同数量残插块儿的实验结果来看，是由一个残渣块，应该是最好的解决方式，使用零个或两个第三个都可能是都会使hcv值相对降低。由此来看在选择，隐性层纬度为三的情况下，我们应该选择适用一个参差款。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdQ9f85WY1K"
   },
   "source": [
    "### Conclusion\n",
    "Adding new data slightly improves the performance of the model in HCV score, in addition, shuffling the training data largely lowers the HGV score perhaps we should discuss this phenomenon and justify use no shuffling during training. Perhaps this is because of some sort of phonotactics or naturalness of sound streams. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kjoJ2fFKpmVC"
   },
   "source": [
    "Good news is that for the English model it performs similar well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPWgjpid7PR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
