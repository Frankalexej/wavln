{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Run\n",
    "A_01: Copy from SL_D_E_4.ipynb. Fixed the problem as we have found in normalization. This time we normalize over the whole course. \n",
    "\n",
    "A_03: LHY version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English\n",
    "Version 1: In this version we make the model \"simple\": make the encoder RNN into normal RNN first and try to see the result.  \n",
    "Version 2: Learning is not very much. Following Dr Coupe's advice we try simpler model structure.   \n",
    "Version 3: A simple trial training with Mel spectrogram instead of MFCC.   \n",
    "Version 4: try to enlarge the hidden dimensions so that we might still make sense of the hidden representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PhxLearner, SimplerPhxLearner, LHYPhxLearner\n",
    "from my_dataset import DS_Tools\n",
    "from dataset import SeqDataset, MelTransform, Normalizer, DeNormalizer, MelSpecTransformNew\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_DIM = 64\n",
    "OUTPUT_DIM = 64 \n",
    "\n",
    "INTER_DIM_0 = 32\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 8\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.7\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "# model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model = LHYPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model weights\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         torch.nn.init.orthogonal_(m.weight)\n",
    "#         m.bias.data.fill_(0.01)\n",
    "#     if isinstance(m, nn.LSTM): \n",
    "#         for name, p in m.named_parameters():\n",
    "#             if \"weight\" in name: \n",
    "#                 nn.init.orthogonal_(p)\n",
    "#             elif \"bias\" in name: \n",
    "#                 nn.init.constant_(p, 0)\n",
    "\n",
    "# model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "# ts = \"0918192113\"\n",
    "stop_epoch = \"149\"\n",
    "ts = str(get_timestamp())\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    model_raw_name = \"PT_{}_{}_full\".format(ts, stop_epoch)\n",
    "    model_name = model_raw_name + \".pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "# mytrans = MelSpecTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)\n",
    "# mytrans = nn.Sequential(\n",
    "#     MelTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS),\n",
    "#     # torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "#     Normalizer(Normalizer.norm_strip_mvn)\n",
    "# )\n",
    "mytrans = MelSpecTransformNew(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS, normalizer=Normalizer.norm_strip_mvn, denormalizer=DeNormalizer.norm_strip_mvn)\n",
    "ds = SeqDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "test = False\n",
    "if test: \n",
    "    use_len = int(0.1 * len(ds))\n",
    "    remain_len = len(ds) - use_len\n",
    "\n",
    "    # Randomly split the dataset into train and validation sets\n",
    "    ds, remain_ds = random_split(ds, [use_len, remain_len])\n",
    "\n",
    "\n",
    "if READ: \n",
    "    valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)))\n",
    "    all_indices = list(range(len(ds)))\n",
    "    train_ds_indices = list(set(all_indices).difference(set(valid_ds_indices)))\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(ds, train_ds_indices)\n",
    "    valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "else: \n",
    "    train_len = int(0.8 * len(ds))\n",
    "    valid_len = len(ds) - train_len\n",
    "\n",
    "    # Randomly split the dataset into train and validation sets\n",
    "    train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "    DS_Tools.save_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)), valid_ds.indices)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "valid_num = len(valid_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 61, 64])\n"
     ]
    }
   ],
   "source": [
    "# Load sample data from train_loader\n",
    "sample_data = next(iter(valid_loader))\n",
    "xx_pad, seg = sample_data\n",
    "print(xx_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# random.seed(101)\n",
    "# Generate six random indices\n",
    "random_indices = random.sample(range(len(xx_pad)), 6)\n",
    "# random_indices = list(range(6, 12))\n",
    "\n",
    "# Plot the spectrograms and mark the corresponding seg\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    spectrogram = xx_pad[idx]\n",
    "    \n",
    "    ax = axes[i]\n",
    "    img = ax.imshow(spectrogram.T, aspect='auto', origin=\"lower\")\n",
    "    # ax.axvline(x=segment, color='red', linestyle='--')\n",
    "    # ax.axvline(x=segment[1], color='red', linestyle='--')\n",
    "    ax.set_title(f'Spectrogram')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.colorbar(img,ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0122110827'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y = x \n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            # \n",
    "            # torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            # parameters: an iterable of Variables that will have gradients normalized\n",
    "            # max_norm: max norm of the gradients()\n",
    "            # norm_type: type of the used p-norm. Can be'inf'for infinity norm()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"Training loss {train_loss / train_num: .3f}\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            y = x    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"Valid loss {valid_loss / valid_num: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss  0.995 in Step 0\n",
      "Training loss  0.832 in Step 100\n",
      "Training loss  0.756 in Step 200\n",
      "Training loss  0.729 in Step 300\n",
      "Training loss  0.716 in Step 400\n",
      "Training loss  0.712 in Step 500\n",
      "Training loss  0.684 in Step 600\n",
      "Training loss  0.698 in Step 700\n",
      "Training loss  0.683 in Step 800\n",
      "Training loss  0.692 in Step 900\n",
      "Training loss  0.666 in Step 1000\n",
      "Training loss  0.666 in Step 1100\n",
      "Training loss  0.669 in Step 1200\n",
      "Training loss  0.659 in Step 1300\n",
      "Training loss  0.673 in Step 1400\n",
      "Training loss  0.661 in Step 1500\n",
      "Training loss  0.655 in Step 1600\n",
      "Training loss  0.661 in Step 1700\n",
      "Training loss  0.702\n",
      "Training timepoint saved\n",
      "Valid loss  0.453 in Step 0\n",
      "Valid loss  0.449 in Step 10\n",
      "Valid loss  0.464 in Step 20\n",
      "Valid loss  0.452 in Step 30\n",
      "Valid loss  0.433 in Step 40\n",
      "Valid loss  0.449 in Step 50\n",
      "Valid loss  0.455 in Step 60\n",
      "Valid loss  0.436 in Step 70\n",
      "Valid loss  0.454 in Step 80\n",
      "Valid loss  0.461 in Step 90\n",
      "Valid loss  0.459 in Step 100\n",
      "Valid loss  0.448 in Step 110\n",
      "Valid loss  0.458 in Step 120\n",
      "Valid loss  0.445 in Step 130\n",
      "Valid loss  0.452 in Step 140\n",
      "Valid loss  0.455 in Step 150\n",
      "Valid loss  0.448 in Step 160\n",
      "Valid loss  0.448 in Step 170\n",
      "Valid loss  0.445 in Step 180\n",
      "Valid loss  0.436 in Step 190\n",
      "Valid loss  0.442 in Step 200\n",
      "Valid loss  0.450 in Step 210\n",
      "Valid loss  0.446 in Step 220\n",
      "Valid loss  0.455 in Step 230\n",
      "Valid loss  0.451 in Step 240\n",
      "Valid loss  0.465 in Step 250\n",
      "Valid loss  0.466 in Step 260\n",
      "Valid loss  0.460 in Step 270\n",
      "Valid loss  0.443 in Step 280\n",
      "Valid loss  0.452 in Step 290\n",
      "Valid loss  0.446 in Step 300\n",
      "Valid loss  0.449 in Step 310\n",
      "Valid loss  0.453 in Step 320\n",
      "Valid loss  0.440 in Step 330\n",
      "Valid loss  0.437 in Step 340\n",
      "Valid loss  0.470 in Step 350\n",
      "Valid loss  0.442 in Step 360\n",
      "Valid loss  0.442 in Step 370\n",
      "Valid loss  0.459 in Step 380\n",
      "Valid loss  0.446 in Step 390\n",
      "Valid loss  0.444 in Step 400\n",
      "Valid loss  0.456 in Step 410\n",
      "Valid loss  0.452 in Step 420\n",
      "Valid loss  0.444 in Step 430\n",
      "Valid loss  0.433 in Step 440\n",
      "Valid loss  0.450\n",
      "Epoch 1\n",
      "Training loss  0.650 in Step 0\n",
      "Training loss  0.668 in Step 100\n",
      "Training loss  0.656 in Step 200\n",
      "Training loss  0.660 in Step 300\n",
      "Training loss  0.663 in Step 400\n",
      "Training loss  0.663 in Step 500\n",
      "Training loss  0.646 in Step 600\n",
      "Training loss  0.640 in Step 700\n",
      "Training loss  0.657 in Step 800\n",
      "Training loss  0.637 in Step 900\n",
      "Training loss  0.654 in Step 1000\n",
      "Training loss  0.647 in Step 1100\n",
      "Training loss  0.645 in Step 1200\n",
      "Training loss  0.642 in Step 1300\n",
      "Training loss  0.651 in Step 1400\n",
      "Training loss  0.658 in Step 1500\n",
      "Training loss  0.634 in Step 1600\n",
      "Training loss  0.645 in Step 1700\n",
      "Training loss  0.652\n",
      "Training timepoint saved\n",
      "Valid loss  0.439 in Step 0\n",
      "Valid loss  0.432 in Step 10\n",
      "Valid loss  0.447 in Step 20\n",
      "Valid loss  0.434 in Step 30\n",
      "Valid loss  0.421 in Step 40\n",
      "Valid loss  0.435 in Step 50\n",
      "Valid loss  0.439 in Step 60\n",
      "Valid loss  0.423 in Step 70\n",
      "Valid loss  0.438 in Step 80\n",
      "Valid loss  0.445 in Step 90\n",
      "Valid loss  0.443 in Step 100\n",
      "Valid loss  0.434 in Step 110\n",
      "Valid loss  0.443 in Step 120\n",
      "Valid loss  0.430 in Step 130\n",
      "Valid loss  0.438 in Step 140\n",
      "Valid loss  0.439 in Step 150\n",
      "Valid loss  0.434 in Step 160\n",
      "Valid loss  0.433 in Step 170\n",
      "Valid loss  0.428 in Step 180\n",
      "Valid loss  0.420 in Step 190\n",
      "Valid loss  0.426 in Step 200\n",
      "Valid loss  0.435 in Step 210\n",
      "Valid loss  0.429 in Step 220\n",
      "Valid loss  0.438 in Step 230\n",
      "Valid loss  0.436 in Step 240\n",
      "Valid loss  0.449 in Step 250\n",
      "Valid loss  0.448 in Step 260\n",
      "Valid loss  0.442 in Step 270\n",
      "Valid loss  0.430 in Step 280\n",
      "Valid loss  0.437 in Step 290\n",
      "Valid loss  0.432 in Step 300\n",
      "Valid loss  0.432 in Step 310\n",
      "Valid loss  0.439 in Step 320\n",
      "Valid loss  0.425 in Step 330\n",
      "Valid loss  0.421 in Step 340\n",
      "Valid loss  0.455 in Step 350\n",
      "Valid loss  0.427 in Step 360\n",
      "Valid loss  0.427 in Step 370\n",
      "Valid loss  0.443 in Step 380\n",
      "Valid loss  0.431 in Step 390\n",
      "Valid loss  0.430 in Step 400\n",
      "Valid loss  0.441 in Step 410\n",
      "Valid loss  0.438 in Step 420\n",
      "Valid loss  0.433 in Step 430\n",
      "Valid loss  0.419 in Step 440\n",
      "Valid loss  0.435\n",
      "Epoch 2\n",
      "Training loss  0.638 in Step 0\n",
      "Training loss  0.643 in Step 100\n",
      "Training loss  0.662 in Step 200\n",
      "Training loss  0.649 in Step 300\n",
      "Training loss  0.632 in Step 400\n",
      "Training loss  0.644 in Step 500\n",
      "Training loss  0.640 in Step 600\n",
      "Training loss  0.654 in Step 700\n",
      "Training loss  0.642 in Step 800\n",
      "Training loss  0.635 in Step 900\n",
      "Training loss  0.635 in Step 1000\n",
      "Training loss  0.637 in Step 1100\n",
      "Training loss  0.630 in Step 1200\n",
      "Training loss  0.647 in Step 1300\n",
      "Training loss  0.646 in Step 1400\n",
      "Training loss  0.644 in Step 1500\n",
      "Training loss  0.648 in Step 1600\n",
      "Training loss  0.643 in Step 1700\n",
      "Training loss  0.645\n",
      "Training timepoint saved\n",
      "Valid loss  0.438 in Step 0\n",
      "Valid loss  0.430 in Step 10\n",
      "Valid loss  0.444 in Step 20\n",
      "Valid loss  0.431 in Step 30\n",
      "Valid loss  0.420 in Step 40\n",
      "Valid loss  0.433 in Step 50\n",
      "Valid loss  0.437 in Step 60\n",
      "Valid loss  0.421 in Step 70\n",
      "Valid loss  0.435 in Step 80\n",
      "Valid loss  0.443 in Step 90\n",
      "Valid loss  0.440 in Step 100\n",
      "Valid loss  0.431 in Step 110\n",
      "Valid loss  0.440 in Step 120\n",
      "Valid loss  0.429 in Step 130\n",
      "Valid loss  0.434 in Step 140\n",
      "Valid loss  0.437 in Step 150\n",
      "Valid loss  0.432 in Step 160\n",
      "Valid loss  0.432 in Step 170\n",
      "Valid loss  0.426 in Step 180\n",
      "Valid loss  0.417 in Step 190\n",
      "Valid loss  0.423 in Step 200\n",
      "Valid loss  0.432 in Step 210\n",
      "Valid loss  0.427 in Step 220\n",
      "Valid loss  0.436 in Step 230\n",
      "Valid loss  0.435 in Step 240\n",
      "Valid loss  0.447 in Step 250\n",
      "Valid loss  0.443 in Step 260\n",
      "Valid loss  0.439 in Step 270\n",
      "Valid loss  0.429 in Step 280\n",
      "Valid loss  0.435 in Step 290\n",
      "Valid loss  0.429 in Step 300\n",
      "Valid loss  0.430 in Step 310\n",
      "Valid loss  0.436 in Step 320\n",
      "Valid loss  0.422 in Step 330\n",
      "Valid loss  0.419 in Step 340\n",
      "Valid loss  0.453 in Step 350\n",
      "Valid loss  0.425 in Step 360\n",
      "Valid loss  0.424 in Step 370\n",
      "Valid loss  0.441 in Step 380\n",
      "Valid loss  0.430 in Step 390\n",
      "Valid loss  0.427 in Step 400\n",
      "Valid loss  0.441 in Step 410\n",
      "Valid loss  0.436 in Step 420\n",
      "Valid loss  0.431 in Step 430\n",
      "Valid loss  0.417 in Step 440\n",
      "Valid loss  0.432\n",
      "Epoch 3\n",
      "Training loss  0.647 in Step 0\n",
      "Training loss  0.640 in Step 100\n",
      "Training loss  0.633 in Step 200\n",
      "Training loss  0.630 in Step 300\n",
      "Training loss  0.649 in Step 400\n",
      "Training loss  0.651 in Step 500\n",
      "Training loss  0.645 in Step 600\n",
      "Training loss  0.642 in Step 700\n",
      "Training loss  0.638 in Step 800\n",
      "Training loss  0.648 in Step 900\n",
      "Training loss  0.653 in Step 1000\n",
      "Training loss  0.638 in Step 1100\n",
      "Training loss  0.638 in Step 1200\n",
      "Training loss  0.635 in Step 1300\n",
      "Training loss  0.645 in Step 1400\n",
      "Training loss  0.647 in Step 1500\n",
      "Training loss  0.634 in Step 1600\n",
      "Training loss  0.636 in Step 1700\n",
      "Training loss  0.642\n",
      "Training timepoint saved\n",
      "Valid loss  0.435 in Step 0\n",
      "Valid loss  0.427 in Step 10\n",
      "Valid loss  0.441 in Step 20\n",
      "Valid loss  0.429 in Step 30\n",
      "Valid loss  0.417 in Step 40\n",
      "Valid loss  0.430 in Step 50\n",
      "Valid loss  0.434 in Step 60\n",
      "Valid loss  0.418 in Step 70\n",
      "Valid loss  0.433 in Step 80\n",
      "Valid loss  0.438 in Step 90\n",
      "Valid loss  0.437 in Step 100\n",
      "Valid loss  0.428 in Step 110\n",
      "Valid loss  0.437 in Step 120\n",
      "Valid loss  0.426 in Step 130\n",
      "Valid loss  0.430 in Step 140\n",
      "Valid loss  0.433 in Step 150\n",
      "Valid loss  0.428 in Step 160\n",
      "Valid loss  0.430 in Step 170\n",
      "Valid loss  0.423 in Step 180\n",
      "Valid loss  0.414 in Step 190\n",
      "Valid loss  0.420 in Step 200\n",
      "Valid loss  0.429 in Step 210\n",
      "Valid loss  0.425 in Step 220\n",
      "Valid loss  0.434 in Step 230\n",
      "Valid loss  0.431 in Step 240\n",
      "Valid loss  0.443 in Step 250\n",
      "Valid loss  0.440 in Step 260\n",
      "Valid loss  0.437 in Step 270\n",
      "Valid loss  0.425 in Step 280\n",
      "Valid loss  0.432 in Step 290\n",
      "Valid loss  0.425 in Step 300\n",
      "Valid loss  0.428 in Step 310\n",
      "Valid loss  0.432 in Step 320\n",
      "Valid loss  0.419 in Step 330\n",
      "Valid loss  0.416 in Step 340\n",
      "Valid loss  0.451 in Step 350\n",
      "Valid loss  0.422 in Step 360\n",
      "Valid loss  0.421 in Step 370\n",
      "Valid loss  0.437 in Step 380\n",
      "Valid loss  0.426 in Step 390\n",
      "Valid loss  0.423 in Step 400\n",
      "Valid loss  0.437 in Step 410\n",
      "Valid loss  0.432 in Step 420\n",
      "Valid loss  0.428 in Step 430\n",
      "Valid loss  0.414 in Step 440\n",
      "Valid loss  0.429\n",
      "Epoch 4\n",
      "Training loss  0.642 in Step 0\n",
      "Training loss  0.647 in Step 100\n",
      "Training loss  0.646 in Step 200\n",
      "Training loss  0.641 in Step 300\n",
      "Training loss  0.650 in Step 400\n",
      "Training loss  0.640 in Step 500\n",
      "Training loss  0.639 in Step 600\n",
      "Training loss  0.638 in Step 700\n",
      "Training loss  0.643 in Step 800\n",
      "Training loss  0.636 in Step 900\n",
      "Training loss  0.653 in Step 1000\n",
      "Training loss  0.634 in Step 1100\n",
      "Training loss  0.641 in Step 1200\n",
      "Training loss  0.642 in Step 1300\n",
      "Training loss  0.624 in Step 1400\n",
      "Training loss  0.641 in Step 1500\n",
      "Training loss  0.637 in Step 1600\n",
      "Training loss  0.635 in Step 1700\n",
      "Training loss  0.640\n",
      "Training timepoint saved\n",
      "Valid loss  0.433 in Step 0\n",
      "Valid loss  0.426 in Step 10\n",
      "Valid loss  0.440 in Step 20\n",
      "Valid loss  0.428 in Step 30\n",
      "Valid loss  0.416 in Step 40\n",
      "Valid loss  0.429 in Step 50\n",
      "Valid loss  0.432 in Step 60\n",
      "Valid loss  0.417 in Step 70\n",
      "Valid loss  0.432 in Step 80\n",
      "Valid loss  0.437 in Step 90\n",
      "Valid loss  0.436 in Step 100\n",
      "Valid loss  0.427 in Step 110\n",
      "Valid loss  0.437 in Step 120\n",
      "Valid loss  0.426 in Step 130\n",
      "Valid loss  0.429 in Step 140\n",
      "Valid loss  0.432 in Step 150\n",
      "Valid loss  0.427 in Step 160\n",
      "Valid loss  0.429 in Step 170\n",
      "Valid loss  0.422 in Step 180\n",
      "Valid loss  0.412 in Step 190\n",
      "Valid loss  0.419 in Step 200\n",
      "Valid loss  0.428 in Step 210\n",
      "Valid loss  0.424 in Step 220\n",
      "Valid loss  0.433 in Step 230\n",
      "Valid loss  0.430 in Step 240\n",
      "Valid loss  0.442 in Step 250\n",
      "Valid loss  0.439 in Step 260\n",
      "Valid loss  0.436 in Step 270\n",
      "Valid loss  0.424 in Step 280\n",
      "Valid loss  0.431 in Step 290\n",
      "Valid loss  0.424 in Step 300\n",
      "Valid loss  0.427 in Step 310\n",
      "Valid loss  0.431 in Step 320\n",
      "Valid loss  0.418 in Step 330\n",
      "Valid loss  0.415 in Step 340\n",
      "Valid loss  0.449 in Step 350\n",
      "Valid loss  0.421 in Step 360\n",
      "Valid loss  0.420 in Step 370\n",
      "Valid loss  0.437 in Step 380\n",
      "Valid loss  0.426 in Step 390\n",
      "Valid loss  0.422 in Step 400\n",
      "Valid loss  0.436 in Step 410\n",
      "Valid loss  0.431 in Step 420\n",
      "Valid loss  0.427 in Step 430\n",
      "Valid loss  0.412 in Step 440\n",
      "Valid loss  0.428\n",
      "Epoch 5\n",
      "Training loss  0.641 in Step 0\n",
      "Training loss  0.644 in Step 100\n",
      "Training loss  0.640 in Step 200\n",
      "Training loss  0.642 in Step 300\n",
      "Training loss  0.640 in Step 400\n",
      "Training loss  0.636 in Step 500\n",
      "Training loss  0.632 in Step 600\n",
      "Training loss  0.638 in Step 700\n",
      "Training loss  0.648 in Step 800\n",
      "Training loss  0.638 in Step 900\n",
      "Training loss  0.641 in Step 1000\n",
      "Training loss  0.647 in Step 1100\n",
      "Training loss  0.635 in Step 1200\n",
      "Training loss  0.637 in Step 1300\n",
      "Training loss  0.662 in Step 1400\n",
      "Training loss  0.642 in Step 1500\n",
      "Training loss  0.649 in Step 1600\n",
      "Training loss  0.641 in Step 1700\n",
      "Training loss  0.639\n",
      "Training timepoint saved\n",
      "Valid loss  0.435 in Step 0\n",
      "Valid loss  0.428 in Step 10\n",
      "Valid loss  0.442 in Step 20\n",
      "Valid loss  0.429 in Step 30\n",
      "Valid loss  0.417 in Step 40\n",
      "Valid loss  0.430 in Step 50\n",
      "Valid loss  0.434 in Step 60\n",
      "Valid loss  0.418 in Step 70\n",
      "Valid loss  0.433 in Step 80\n",
      "Valid loss  0.438 in Step 90\n",
      "Valid loss  0.437 in Step 100\n",
      "Valid loss  0.429 in Step 110\n",
      "Valid loss  0.438 in Step 120\n",
      "Valid loss  0.428 in Step 130\n",
      "Valid loss  0.430 in Step 140\n",
      "Valid loss  0.434 in Step 150\n",
      "Valid loss  0.428 in Step 160\n",
      "Valid loss  0.430 in Step 170\n",
      "Valid loss  0.423 in Step 180\n",
      "Valid loss  0.414 in Step 190\n",
      "Valid loss  0.421 in Step 200\n",
      "Valid loss  0.430 in Step 210\n",
      "Valid loss  0.425 in Step 220\n",
      "Valid loss  0.434 in Step 230\n",
      "Valid loss  0.432 in Step 240\n",
      "Valid loss  0.443 in Step 250\n",
      "Valid loss  0.440 in Step 260\n",
      "Valid loss  0.437 in Step 270\n",
      "Valid loss  0.425 in Step 280\n",
      "Valid loss  0.432 in Step 290\n",
      "Valid loss  0.425 in Step 300\n",
      "Valid loss  0.428 in Step 310\n",
      "Valid loss  0.432 in Step 320\n",
      "Valid loss  0.419 in Step 330\n",
      "Valid loss  0.417 in Step 340\n",
      "Valid loss  0.451 in Step 350\n",
      "Valid loss  0.423 in Step 360\n",
      "Valid loss  0.422 in Step 370\n",
      "Valid loss  0.438 in Step 380\n",
      "Valid loss  0.427 in Step 390\n",
      "Valid loss  0.423 in Step 400\n",
      "Valid loss  0.437 in Step 410\n",
      "Valid loss  0.433 in Step 420\n",
      "Valid loss  0.428 in Step 430\n",
      "Valid loss  0.414 in Step 440\n",
      "Valid loss  0.430\n",
      "Epoch 6\n",
      "Training loss  0.627 in Step 0\n",
      "Training loss  0.635 in Step 100\n",
      "Training loss  0.640 in Step 200\n",
      "Training loss  0.652 in Step 300\n",
      "Training loss  0.631 in Step 400\n",
      "Training loss  0.642 in Step 500\n",
      "Training loss  0.641 in Step 600\n",
      "Training loss  0.641 in Step 700\n",
      "Training loss  0.635 in Step 800\n",
      "Training loss  0.641 in Step 900\n",
      "Training loss  0.630 in Step 1000\n",
      "Training loss  0.641 in Step 1100\n",
      "Training loss  0.635 in Step 1200\n",
      "Training loss  0.644 in Step 1300\n",
      "Training loss  0.625 in Step 1400\n",
      "Training loss  0.627 in Step 1500\n",
      "Training loss  0.650 in Step 1600\n",
      "Training loss  0.649 in Step 1700\n",
      "Training loss  0.638\n",
      "Training timepoint saved\n",
      "Valid loss  0.436 in Step 0\n",
      "Valid loss  0.428 in Step 10\n",
      "Valid loss  0.443 in Step 20\n",
      "Valid loss  0.430 in Step 30\n",
      "Valid loss  0.418 in Step 40\n",
      "Valid loss  0.431 in Step 50\n",
      "Valid loss  0.434 in Step 60\n",
      "Valid loss  0.418 in Step 70\n",
      "Valid loss  0.434 in Step 80\n",
      "Valid loss  0.438 in Step 90\n",
      "Valid loss  0.438 in Step 100\n",
      "Valid loss  0.429 in Step 110\n",
      "Valid loss  0.439 in Step 120\n",
      "Valid loss  0.429 in Step 130\n",
      "Valid loss  0.431 in Step 140\n",
      "Valid loss  0.435 in Step 150\n",
      "Valid loss  0.428 in Step 160\n",
      "Valid loss  0.431 in Step 170\n",
      "Valid loss  0.424 in Step 180\n",
      "Valid loss  0.416 in Step 190\n",
      "Valid loss  0.422 in Step 200\n",
      "Valid loss  0.431 in Step 210\n",
      "Valid loss  0.427 in Step 220\n",
      "Valid loss  0.435 in Step 230\n",
      "Valid loss  0.433 in Step 240\n",
      "Valid loss  0.444 in Step 250\n",
      "Valid loss  0.441 in Step 260\n",
      "Valid loss  0.438 in Step 270\n",
      "Valid loss  0.426 in Step 280\n",
      "Valid loss  0.433 in Step 290\n",
      "Valid loss  0.426 in Step 300\n",
      "Valid loss  0.430 in Step 310\n",
      "Valid loss  0.432 in Step 320\n",
      "Valid loss  0.420 in Step 330\n",
      "Valid loss  0.418 in Step 340\n",
      "Valid loss  0.452 in Step 350\n",
      "Valid loss  0.423 in Step 360\n",
      "Valid loss  0.422 in Step 370\n",
      "Valid loss  0.439 in Step 380\n",
      "Valid loss  0.427 in Step 390\n",
      "Valid loss  0.423 in Step 400\n",
      "Valid loss  0.438 in Step 410\n",
      "Valid loss  0.433 in Step 420\n",
      "Valid loss  0.429 in Step 430\n",
      "Valid loss  0.414 in Step 440\n",
      "Valid loss  0.430\n",
      "Epoch 7\n",
      "Training loss  0.634 in Step 0\n",
      "Training loss  0.632 in Step 100\n",
      "Training loss  0.636 in Step 200\n",
      "Training loss  0.649 in Step 300\n",
      "Training loss  0.639 in Step 400\n",
      "Training loss  0.647 in Step 500\n",
      "Training loss  0.646 in Step 600\n",
      "Training loss  0.637 in Step 700\n",
      "Training loss  0.630 in Step 800\n",
      "Training loss  0.639 in Step 900\n",
      "Training loss  0.633 in Step 1000\n",
      "Training loss  0.628 in Step 1100\n",
      "Training loss  0.635 in Step 1200\n",
      "Training loss  0.638 in Step 1300\n",
      "Training loss  0.639 in Step 1400\n",
      "Training loss  0.639 in Step 1500\n",
      "Training loss  0.621 in Step 1600\n",
      "Training loss  0.651 in Step 1700\n",
      "Training loss  0.637\n",
      "Training timepoint saved\n",
      "Valid loss  0.439 in Step 0\n",
      "Valid loss  0.431 in Step 10\n",
      "Valid loss  0.445 in Step 20\n",
      "Valid loss  0.434 in Step 30\n",
      "Valid loss  0.421 in Step 40\n",
      "Valid loss  0.433 in Step 50\n",
      "Valid loss  0.437 in Step 60\n",
      "Valid loss  0.422 in Step 70\n",
      "Valid loss  0.437 in Step 80\n",
      "Valid loss  0.440 in Step 90\n",
      "Valid loss  0.441 in Step 100\n",
      "Valid loss  0.433 in Step 110\n",
      "Valid loss  0.441 in Step 120\n",
      "Valid loss  0.431 in Step 130\n",
      "Valid loss  0.434 in Step 140\n",
      "Valid loss  0.437 in Step 150\n",
      "Valid loss  0.432 in Step 160\n",
      "Valid loss  0.434 in Step 170\n",
      "Valid loss  0.427 in Step 180\n",
      "Valid loss  0.419 in Step 190\n",
      "Valid loss  0.425 in Step 200\n",
      "Valid loss  0.435 in Step 210\n",
      "Valid loss  0.431 in Step 220\n",
      "Valid loss  0.438 in Step 230\n",
      "Valid loss  0.435 in Step 240\n",
      "Valid loss  0.447 in Step 250\n",
      "Valid loss  0.444 in Step 260\n",
      "Valid loss  0.441 in Step 270\n",
      "Valid loss  0.429 in Step 280\n",
      "Valid loss  0.437 in Step 290\n",
      "Valid loss  0.428 in Step 300\n",
      "Valid loss  0.434 in Step 310\n",
      "Valid loss  0.436 in Step 320\n",
      "Valid loss  0.423 in Step 330\n",
      "Valid loss  0.421 in Step 340\n",
      "Valid loss  0.455 in Step 350\n",
      "Valid loss  0.426 in Step 360\n",
      "Valid loss  0.425 in Step 370\n",
      "Valid loss  0.442 in Step 380\n",
      "Valid loss  0.431 in Step 390\n",
      "Valid loss  0.427 in Step 400\n",
      "Valid loss  0.442 in Step 410\n",
      "Valid loss  0.436 in Step 420\n",
      "Valid loss  0.432 in Step 430\n",
      "Valid loss  0.418 in Step 440\n",
      "Valid loss  0.433\n",
      "Epoch 8\n",
      "Training loss  0.631 in Step 0\n",
      "Training loss  0.650 in Step 100\n",
      "Training loss  0.628 in Step 200\n",
      "Training loss  0.635 in Step 300\n",
      "Training loss  0.643 in Step 400\n",
      "Training loss  0.645 in Step 500\n",
      "Training loss  0.627 in Step 600\n",
      "Training loss  0.632 in Step 700\n",
      "Training loss  0.634 in Step 800\n",
      "Training loss  0.638 in Step 900\n",
      "Training loss  0.648 in Step 1000\n",
      "Training loss  0.631 in Step 1100\n",
      "Training loss  0.631 in Step 1200\n",
      "Training loss  0.640 in Step 1300\n",
      "Training loss  0.647 in Step 1400\n",
      "Training loss  0.638 in Step 1500\n",
      "Training loss  0.635 in Step 1600\n",
      "Training loss  0.648 in Step 1700\n",
      "Training loss  0.637\n",
      "Training timepoint saved\n",
      "Valid loss  0.438 in Step 0\n",
      "Valid loss  0.429 in Step 10\n",
      "Valid loss  0.443 in Step 20\n",
      "Valid loss  0.432 in Step 30\n",
      "Valid loss  0.419 in Step 40\n",
      "Valid loss  0.431 in Step 50\n",
      "Valid loss  0.435 in Step 60\n",
      "Valid loss  0.420 in Step 70\n",
      "Valid loss  0.434 in Step 80\n",
      "Valid loss  0.439 in Step 90\n",
      "Valid loss  0.438 in Step 100\n",
      "Valid loss  0.431 in Step 110\n",
      "Valid loss  0.439 in Step 120\n",
      "Valid loss  0.429 in Step 130\n",
      "Valid loss  0.431 in Step 140\n",
      "Valid loss  0.435 in Step 150\n",
      "Valid loss  0.430 in Step 160\n",
      "Valid loss  0.432 in Step 170\n",
      "Valid loss  0.425 in Step 180\n",
      "Valid loss  0.417 in Step 190\n",
      "Valid loss  0.424 in Step 200\n",
      "Valid loss  0.432 in Step 210\n",
      "Valid loss  0.429 in Step 220\n",
      "Valid loss  0.436 in Step 230\n",
      "Valid loss  0.433 in Step 240\n",
      "Valid loss  0.444 in Step 250\n",
      "Valid loss  0.443 in Step 260\n",
      "Valid loss  0.438 in Step 270\n",
      "Valid loss  0.426 in Step 280\n",
      "Valid loss  0.435 in Step 290\n",
      "Valid loss  0.426 in Step 300\n",
      "Valid loss  0.432 in Step 310\n",
      "Valid loss  0.433 in Step 320\n",
      "Valid loss  0.421 in Step 330\n",
      "Valid loss  0.419 in Step 340\n",
      "Valid loss  0.453 in Step 350\n",
      "Valid loss  0.424 in Step 360\n",
      "Valid loss  0.423 in Step 370\n",
      "Valid loss  0.440 in Step 380\n",
      "Valid loss  0.428 in Step 390\n",
      "Valid loss  0.425 in Step 400\n",
      "Valid loss  0.440 in Step 410\n",
      "Valid loss  0.433 in Step 420\n",
      "Valid loss  0.430 in Step 430\n",
      "Valid loss  0.415 in Step 440\n",
      "Valid loss  0.431\n",
      "Epoch 9\n",
      "Training loss  0.641 in Step 0\n",
      "Training loss  0.636 in Step 100\n",
      "Training loss  0.639 in Step 200\n",
      "Training loss  0.628 in Step 300\n",
      "Training loss  0.636 in Step 400\n",
      "Training loss  0.638 in Step 500\n",
      "Training loss  0.634 in Step 600\n",
      "Training loss  0.631 in Step 700\n",
      "Training loss  0.636 in Step 800\n",
      "Training loss  0.640 in Step 900\n",
      "Training loss  0.642 in Step 1000\n",
      "Training loss  0.635 in Step 1100\n",
      "Training loss  0.633 in Step 1200\n",
      "Training loss  0.638 in Step 1300\n",
      "Training loss  0.635 in Step 1400\n",
      "Training loss  0.625 in Step 1500\n",
      "Training loss  0.631 in Step 1600\n",
      "Training loss  0.629 in Step 1700\n",
      "Training loss  0.636\n",
      "Training timepoint saved\n",
      "Valid loss  0.441 in Step 0\n",
      "Valid loss  0.431 in Step 10\n",
      "Valid loss  0.446 in Step 20\n",
      "Valid loss  0.434 in Step 30\n",
      "Valid loss  0.422 in Step 40\n",
      "Valid loss  0.434 in Step 50\n",
      "Valid loss  0.439 in Step 60\n",
      "Valid loss  0.423 in Step 70\n",
      "Valid loss  0.437 in Step 80\n",
      "Valid loss  0.441 in Step 90\n",
      "Valid loss  0.442 in Step 100\n",
      "Valid loss  0.434 in Step 110\n",
      "Valid loss  0.442 in Step 120\n",
      "Valid loss  0.432 in Step 130\n",
      "Valid loss  0.434 in Step 140\n",
      "Valid loss  0.439 in Step 150\n",
      "Valid loss  0.434 in Step 160\n",
      "Valid loss  0.436 in Step 170\n",
      "Valid loss  0.427 in Step 180\n",
      "Valid loss  0.420 in Step 190\n",
      "Valid loss  0.426 in Step 200\n",
      "Valid loss  0.435 in Step 210\n",
      "Valid loss  0.432 in Step 220\n",
      "Valid loss  0.439 in Step 230\n",
      "Valid loss  0.436 in Step 240\n",
      "Valid loss  0.447 in Step 250\n",
      "Valid loss  0.445 in Step 260\n",
      "Valid loss  0.441 in Step 270\n",
      "Valid loss  0.429 in Step 280\n",
      "Valid loss  0.437 in Step 290\n",
      "Valid loss  0.429 in Step 300\n",
      "Valid loss  0.434 in Step 310\n",
      "Valid loss  0.437 in Step 320\n",
      "Valid loss  0.425 in Step 330\n",
      "Valid loss  0.423 in Step 340\n",
      "Valid loss  0.456 in Step 350\n",
      "Valid loss  0.427 in Step 360\n",
      "Valid loss  0.425 in Step 370\n",
      "Valid loss  0.444 in Step 380\n",
      "Valid loss  0.431 in Step 390\n",
      "Valid loss  0.429 in Step 400\n",
      "Valid loss  0.443 in Step 410\n",
      "Valid loss  0.436 in Step 420\n",
      "Valid loss  0.433 in Step 430\n",
      "Valid loss  0.419 in Step 440\n",
      "Valid loss  0.434\n",
      "Epoch 10\n",
      "Training loss  0.635 in Step 0\n",
      "Training loss  0.639 in Step 100\n",
      "Training loss  0.638 in Step 200\n",
      "Training loss  0.635 in Step 300\n",
      "Training loss  0.638 in Step 400\n",
      "Training loss  0.622 in Step 500\n",
      "Training loss  0.629 in Step 600\n",
      "Training loss  0.632 in Step 700\n",
      "Training loss  0.637 in Step 800\n",
      "Training loss  0.631 in Step 900\n",
      "Training loss  0.634 in Step 1000\n",
      "Training loss  0.634 in Step 1100\n",
      "Training loss  0.636 in Step 1200\n",
      "Training loss  0.626 in Step 1300\n",
      "Training loss  0.632 in Step 1400\n",
      "Training loss  0.632 in Step 1500\n",
      "Training loss  0.643 in Step 1600\n",
      "Training loss  0.638 in Step 1700\n",
      "Training loss  0.635\n",
      "Training timepoint saved\n",
      "Valid loss  0.442 in Step 0\n",
      "Valid loss  0.433 in Step 10\n",
      "Valid loss  0.448 in Step 20\n",
      "Valid loss  0.438 in Step 30\n",
      "Valid loss  0.424 in Step 40\n",
      "Valid loss  0.436 in Step 50\n",
      "Valid loss  0.441 in Step 60\n",
      "Valid loss  0.425 in Step 70\n",
      "Valid loss  0.440 in Step 80\n",
      "Valid loss  0.444 in Step 90\n",
      "Valid loss  0.444 in Step 100\n",
      "Valid loss  0.437 in Step 110\n",
      "Valid loss  0.444 in Step 120\n",
      "Valid loss  0.434 in Step 130\n",
      "Valid loss  0.437 in Step 140\n",
      "Valid loss  0.441 in Step 150\n",
      "Valid loss  0.436 in Step 160\n",
      "Valid loss  0.438 in Step 170\n",
      "Valid loss  0.430 in Step 180\n",
      "Valid loss  0.422 in Step 190\n",
      "Valid loss  0.429 in Step 200\n",
      "Valid loss  0.437 in Step 210\n",
      "Valid loss  0.435 in Step 220\n",
      "Valid loss  0.440 in Step 230\n",
      "Valid loss  0.437 in Step 240\n",
      "Valid loss  0.449 in Step 250\n",
      "Valid loss  0.447 in Step 260\n",
      "Valid loss  0.443 in Step 270\n",
      "Valid loss  0.431 in Step 280\n",
      "Valid loss  0.440 in Step 290\n",
      "Valid loss  0.431 in Step 300\n",
      "Valid loss  0.436 in Step 310\n",
      "Valid loss  0.439 in Step 320\n",
      "Valid loss  0.427 in Step 330\n",
      "Valid loss  0.425 in Step 340\n",
      "Valid loss  0.457 in Step 350\n",
      "Valid loss  0.428 in Step 360\n",
      "Valid loss  0.428 in Step 370\n",
      "Valid loss  0.446 in Step 380\n",
      "Valid loss  0.434 in Step 390\n",
      "Valid loss  0.432 in Step 400\n",
      "Valid loss  0.445 in Step 410\n",
      "Valid loss  0.439 in Step 420\n",
      "Valid loss  0.436 in Step 430\n",
      "Valid loss  0.421 in Step 440\n",
      "Valid loss  0.436\n",
      "Epoch 11\n",
      "Training loss  0.636 in Step 0\n",
      "Training loss  0.625 in Step 100\n",
      "Training loss  0.631 in Step 200\n",
      "Training loss  0.624 in Step 300\n",
      "Training loss  0.632 in Step 400\n",
      "Training loss  0.635 in Step 500\n",
      "Training loss  0.620 in Step 600\n",
      "Training loss  0.641 in Step 700\n",
      "Training loss  0.632 in Step 800\n",
      "Training loss  0.639 in Step 900\n",
      "Training loss  0.631 in Step 1000\n",
      "Training loss  0.626 in Step 1100\n",
      "Training loss  0.644 in Step 1200\n",
      "Training loss  0.631 in Step 1300\n",
      "Training loss  0.639 in Step 1400\n",
      "Training loss  0.642 in Step 1500\n",
      "Training loss  0.623 in Step 1600\n",
      "Training loss  0.637 in Step 1700\n",
      "Training loss  0.635\n",
      "Training timepoint saved\n",
      "Valid loss  0.447 in Step 0\n",
      "Valid loss  0.437 in Step 10\n",
      "Valid loss  0.452 in Step 20\n",
      "Valid loss  0.444 in Step 30\n",
      "Valid loss  0.428 in Step 40\n",
      "Valid loss  0.441 in Step 50\n",
      "Valid loss  0.447 in Step 60\n",
      "Valid loss  0.431 in Step 70\n",
      "Valid loss  0.446 in Step 80\n",
      "Valid loss  0.449 in Step 90\n",
      "Valid loss  0.449 in Step 100\n",
      "Valid loss  0.443 in Step 110\n",
      "Valid loss  0.448 in Step 120\n",
      "Valid loss  0.437 in Step 130\n",
      "Valid loss  0.441 in Step 140\n",
      "Valid loss  0.445 in Step 150\n",
      "Valid loss  0.443 in Step 160\n",
      "Valid loss  0.444 in Step 170\n",
      "Valid loss  0.434 in Step 180\n",
      "Valid loss  0.428 in Step 190\n",
      "Valid loss  0.435 in Step 200\n",
      "Valid loss  0.442 in Step 210\n",
      "Valid loss  0.441 in Step 220\n",
      "Valid loss  0.445 in Step 230\n",
      "Valid loss  0.443 in Step 240\n",
      "Valid loss  0.455 in Step 250\n",
      "Valid loss  0.452 in Step 260\n",
      "Valid loss  0.448 in Step 270\n",
      "Valid loss  0.436 in Step 280\n",
      "Valid loss  0.446 in Step 290\n",
      "Valid loss  0.437 in Step 300\n",
      "Valid loss  0.441 in Step 310\n",
      "Valid loss  0.445 in Step 320\n",
      "Valid loss  0.432 in Step 330\n",
      "Valid loss  0.429 in Step 340\n",
      "Valid loss  0.462 in Step 350\n",
      "Valid loss  0.433 in Step 360\n",
      "Valid loss  0.433 in Step 370\n",
      "Valid loss  0.451 in Step 380\n",
      "Valid loss  0.439 in Step 390\n",
      "Valid loss  0.438 in Step 400\n",
      "Valid loss  0.451 in Step 410\n",
      "Valid loss  0.443 in Step 420\n",
      "Valid loss  0.441 in Step 430\n",
      "Valid loss  0.427 in Step 440\n",
      "Valid loss  0.441\n",
      "Epoch 12\n",
      "Training loss  0.629 in Step 0\n",
      "Training loss  0.645 in Step 100\n",
      "Training loss  0.623 in Step 200\n",
      "Training loss  0.636 in Step 300\n",
      "Training loss  0.622 in Step 400\n",
      "Training loss  0.625 in Step 500\n",
      "Training loss  0.630 in Step 600\n",
      "Training loss  0.637 in Step 700\n",
      "Training loss  0.640 in Step 800\n",
      "Training loss  0.636 in Step 900\n",
      "Training loss  0.636 in Step 1000\n",
      "Training loss  0.622 in Step 1100\n",
      "Training loss  0.631 in Step 1200\n",
      "Training loss  0.631 in Step 1300\n",
      "Training loss  0.638 in Step 1400\n",
      "Training loss  0.633 in Step 1500\n",
      "Training loss  0.641 in Step 1600\n",
      "Training loss  0.642 in Step 1700\n",
      "Training loss  0.634\n",
      "Training timepoint saved\n",
      "Valid loss  0.454 in Step 0\n",
      "Valid loss  0.444 in Step 10\n",
      "Valid loss  0.459 in Step 20\n",
      "Valid loss  0.451 in Step 30\n",
      "Valid loss  0.435 in Step 40\n",
      "Valid loss  0.449 in Step 50\n",
      "Valid loss  0.454 in Step 60\n",
      "Valid loss  0.438 in Step 70\n",
      "Valid loss  0.453 in Step 80\n",
      "Valid loss  0.456 in Step 90\n",
      "Valid loss  0.455 in Step 100\n",
      "Valid loss  0.450 in Step 110\n",
      "Valid loss  0.455 in Step 120\n",
      "Valid loss  0.445 in Step 130\n",
      "Valid loss  0.448 in Step 140\n",
      "Valid loss  0.452 in Step 150\n",
      "Valid loss  0.450 in Step 160\n",
      "Valid loss  0.452 in Step 170\n",
      "Valid loss  0.441 in Step 180\n",
      "Valid loss  0.435 in Step 190\n",
      "Valid loss  0.443 in Step 200\n",
      "Valid loss  0.449 in Step 210\n",
      "Valid loss  0.448 in Step 220\n",
      "Valid loss  0.452 in Step 230\n",
      "Valid loss  0.449 in Step 240\n",
      "Valid loss  0.461 in Step 250\n",
      "Valid loss  0.459 in Step 260\n",
      "Valid loss  0.455 in Step 270\n",
      "Valid loss  0.443 in Step 280\n",
      "Valid loss  0.452 in Step 290\n",
      "Valid loss  0.444 in Step 300\n",
      "Valid loss  0.447 in Step 310\n",
      "Valid loss  0.453 in Step 320\n",
      "Valid loss  0.440 in Step 330\n",
      "Valid loss  0.437 in Step 340\n",
      "Valid loss  0.469 in Step 350\n",
      "Valid loss  0.440 in Step 360\n",
      "Valid loss  0.440 in Step 370\n",
      "Valid loss  0.459 in Step 380\n",
      "Valid loss  0.446 in Step 390\n",
      "Valid loss  0.445 in Step 400\n",
      "Valid loss  0.458 in Step 410\n",
      "Valid loss  0.451 in Step 420\n",
      "Valid loss  0.448 in Step 430\n",
      "Valid loss  0.435 in Step 440\n",
      "Valid loss  0.449\n",
      "Epoch 13\n",
      "Training loss  0.630 in Step 0\n",
      "Training loss  0.634 in Step 100\n",
      "Training loss  0.639 in Step 200\n",
      "Training loss  0.633 in Step 300\n",
      "Training loss  0.627 in Step 400\n",
      "Training loss  0.633 in Step 500\n",
      "Training loss  0.647 in Step 600\n",
      "Training loss  0.641 in Step 700\n",
      "Training loss  0.644 in Step 800\n",
      "Training loss  0.636 in Step 900\n",
      "Training loss  0.630 in Step 1000\n",
      "Training loss  0.640 in Step 1100\n",
      "Training loss  0.631 in Step 1200\n",
      "Training loss  0.635 in Step 1300\n",
      "Training loss  0.632 in Step 1400\n",
      "Training loss  0.626 in Step 1500\n",
      "Training loss  0.643 in Step 1600\n",
      "Training loss  0.636 in Step 1700\n",
      "Training loss  0.633\n",
      "Training timepoint saved\n",
      "Valid loss  0.455 in Step 0\n",
      "Valid loss  0.445 in Step 10\n",
      "Valid loss  0.460 in Step 20\n",
      "Valid loss  0.453 in Step 30\n",
      "Valid loss  0.436 in Step 40\n",
      "Valid loss  0.450 in Step 50\n",
      "Valid loss  0.457 in Step 60\n",
      "Valid loss  0.440 in Step 70\n",
      "Valid loss  0.455 in Step 80\n",
      "Valid loss  0.458 in Step 90\n",
      "Valid loss  0.458 in Step 100\n",
      "Valid loss  0.452 in Step 110\n",
      "Valid loss  0.456 in Step 120\n",
      "Valid loss  0.445 in Step 130\n",
      "Valid loss  0.449 in Step 140\n",
      "Valid loss  0.453 in Step 150\n",
      "Valid loss  0.452 in Step 160\n",
      "Valid loss  0.454 in Step 170\n",
      "Valid loss  0.442 in Step 180\n",
      "Valid loss  0.437 in Step 190\n",
      "Valid loss  0.444 in Step 200\n",
      "Valid loss  0.449 in Step 210\n",
      "Valid loss  0.449 in Step 220\n",
      "Valid loss  0.454 in Step 230\n",
      "Valid loss  0.451 in Step 240\n",
      "Valid loss  0.464 in Step 250\n",
      "Valid loss  0.459 in Step 260\n",
      "Valid loss  0.457 in Step 270\n",
      "Valid loss  0.444 in Step 280\n",
      "Valid loss  0.454 in Step 290\n",
      "Valid loss  0.445 in Step 300\n",
      "Valid loss  0.449 in Step 310\n",
      "Valid loss  0.454 in Step 320\n",
      "Valid loss  0.442 in Step 330\n",
      "Valid loss  0.437 in Step 340\n",
      "Valid loss  0.470 in Step 350\n",
      "Valid loss  0.441 in Step 360\n",
      "Valid loss  0.441 in Step 370\n",
      "Valid loss  0.459 in Step 380\n",
      "Valid loss  0.448 in Step 390\n",
      "Valid loss  0.447 in Step 400\n",
      "Valid loss  0.459 in Step 410\n",
      "Valid loss  0.452 in Step 420\n",
      "Valid loss  0.449 in Step 430\n",
      "Valid loss  0.436 in Step 440\n",
      "Valid loss  0.450\n",
      "Epoch 14\n",
      "Training loss  0.632 in Step 0\n",
      "Training loss  0.628 in Step 100\n",
      "Training loss  0.640 in Step 200\n",
      "Training loss  0.629 in Step 300\n",
      "Training loss  0.623 in Step 400\n",
      "Training loss  0.631 in Step 500\n",
      "Training loss  0.629 in Step 600\n",
      "Training loss  0.625 in Step 700\n",
      "Training loss  0.640 in Step 800\n",
      "Training loss  0.635 in Step 900\n",
      "Training loss  0.625 in Step 1000\n",
      "Training loss  0.627 in Step 1100\n",
      "Training loss  0.637 in Step 1200\n",
      "Training loss  0.634 in Step 1300\n",
      "Training loss  0.635 in Step 1400\n",
      "Training loss  0.641 in Step 1500\n",
      "Training loss  0.638 in Step 1600\n",
      "Training loss  0.625 in Step 1700\n",
      "Training loss  0.633\n",
      "Training timepoint saved\n",
      "Valid loss  0.459 in Step 0\n",
      "Valid loss  0.449 in Step 10\n",
      "Valid loss  0.464 in Step 20\n",
      "Valid loss  0.456 in Step 30\n",
      "Valid loss  0.440 in Step 40\n",
      "Valid loss  0.454 in Step 50\n",
      "Valid loss  0.462 in Step 60\n",
      "Valid loss  0.444 in Step 70\n",
      "Valid loss  0.459 in Step 80\n",
      "Valid loss  0.461 in Step 90\n",
      "Valid loss  0.462 in Step 100\n",
      "Valid loss  0.456 in Step 110\n",
      "Valid loss  0.460 in Step 120\n",
      "Valid loss  0.449 in Step 130\n",
      "Valid loss  0.453 in Step 140\n",
      "Valid loss  0.456 in Step 150\n",
      "Valid loss  0.457 in Step 160\n",
      "Valid loss  0.458 in Step 170\n",
      "Valid loss  0.445 in Step 180\n",
      "Valid loss  0.441 in Step 190\n",
      "Valid loss  0.449 in Step 200\n",
      "Valid loss  0.454 in Step 210\n",
      "Valid loss  0.453 in Step 220\n",
      "Valid loss  0.457 in Step 230\n",
      "Valid loss  0.455 in Step 240\n",
      "Valid loss  0.468 in Step 250\n",
      "Valid loss  0.463 in Step 260\n",
      "Valid loss  0.460 in Step 270\n",
      "Valid loss  0.448 in Step 280\n",
      "Valid loss  0.457 in Step 290\n",
      "Valid loss  0.450 in Step 300\n",
      "Valid loss  0.452 in Step 310\n",
      "Valid loss  0.458 in Step 320\n",
      "Valid loss  0.447 in Step 330\n",
      "Valid loss  0.441 in Step 340\n",
      "Valid loss  0.474 in Step 350\n",
      "Valid loss  0.445 in Step 360\n",
      "Valid loss  0.445 in Step 370\n",
      "Valid loss  0.463 in Step 380\n",
      "Valid loss  0.452 in Step 390\n",
      "Valid loss  0.451 in Step 400\n",
      "Valid loss  0.463 in Step 410\n",
      "Valid loss  0.455 in Step 420\n",
      "Valid loss  0.453 in Step 430\n",
      "Valid loss  0.440 in Step 440\n",
      "Valid loss  0.454\n",
      "Epoch 15\n",
      "Training loss  0.626 in Step 0\n",
      "Training loss  0.630 in Step 100\n",
      "Training loss  0.638 in Step 200\n",
      "Training loss  0.634 in Step 300\n",
      "Training loss  0.643 in Step 400\n",
      "Training loss  0.638 in Step 500\n",
      "Training loss  0.630 in Step 600\n",
      "Training loss  0.632 in Step 700\n",
      "Training loss  0.632 in Step 800\n",
      "Training loss  0.631 in Step 900\n",
      "Training loss  0.639 in Step 1000\n",
      "Training loss  0.642 in Step 1100\n",
      "Training loss  0.633 in Step 1200\n",
      "Training loss  0.626 in Step 1300\n",
      "Training loss  0.629 in Step 1400\n",
      "Training loss  0.638 in Step 1500\n",
      "Training loss  0.653 in Step 1600\n",
      "Training loss  0.636 in Step 1700\n",
      "Training loss  0.633\n",
      "Training timepoint saved\n",
      "Valid loss  0.464 in Step 0\n",
      "Valid loss  0.454 in Step 10\n",
      "Valid loss  0.470 in Step 20\n",
      "Valid loss  0.462 in Step 30\n",
      "Valid loss  0.445 in Step 40\n",
      "Valid loss  0.459 in Step 50\n",
      "Valid loss  0.467 in Step 60\n",
      "Valid loss  0.450 in Step 70\n",
      "Valid loss  0.464 in Step 80\n",
      "Valid loss  0.466 in Step 90\n",
      "Valid loss  0.468 in Step 100\n",
      "Valid loss  0.462 in Step 110\n",
      "Valid loss  0.465 in Step 120\n",
      "Valid loss  0.453 in Step 130\n",
      "Valid loss  0.458 in Step 140\n",
      "Valid loss  0.462 in Step 150\n",
      "Valid loss  0.463 in Step 160\n",
      "Valid loss  0.463 in Step 170\n",
      "Valid loss  0.449 in Step 180\n",
      "Valid loss  0.447 in Step 190\n",
      "Valid loss  0.453 in Step 200\n",
      "Valid loss  0.459 in Step 210\n",
      "Valid loss  0.459 in Step 220\n",
      "Valid loss  0.462 in Step 230\n",
      "Valid loss  0.460 in Step 240\n",
      "Valid loss  0.474 in Step 250\n",
      "Valid loss  0.468 in Step 260\n",
      "Valid loss  0.465 in Step 270\n",
      "Valid loss  0.453 in Step 280\n",
      "Valid loss  0.463 in Step 290\n",
      "Valid loss  0.454 in Step 300\n",
      "Valid loss  0.458 in Step 310\n",
      "Valid loss  0.464 in Step 320\n",
      "Valid loss  0.452 in Step 330\n",
      "Valid loss  0.447 in Step 340\n",
      "Valid loss  0.480 in Step 350\n",
      "Valid loss  0.451 in Step 360\n",
      "Valid loss  0.450 in Step 370\n",
      "Valid loss  0.469 in Step 380\n",
      "Valid loss  0.458 in Step 390\n",
      "Valid loss  0.457 in Step 400\n",
      "Valid loss  0.469 in Step 410\n",
      "Valid loss  0.461 in Step 420\n",
      "Valid loss  0.458 in Step 430\n",
      "Valid loss  0.446 in Step 440\n",
      "Valid loss  0.459\n",
      "Epoch 16\n",
      "Training loss  0.632 in Step 0\n",
      "Training loss  0.633 in Step 100\n",
      "Training loss  0.623 in Step 200\n",
      "Training loss  0.634 in Step 300\n",
      "Training loss  0.618 in Step 400\n",
      "Training loss  0.628 in Step 500\n",
      "Training loss  0.640 in Step 600\n",
      "Training loss  0.633 in Step 700\n",
      "Training loss  0.626 in Step 800\n",
      "Training loss  0.633 in Step 900\n",
      "Training loss  0.621 in Step 1000\n",
      "Training loss  0.638 in Step 1100\n",
      "Training loss  0.621 in Step 1200\n",
      "Training loss  0.629 in Step 1300\n",
      "Training loss  0.635 in Step 1400\n",
      "Training loss  0.640 in Step 1500\n",
      "Training loss  0.638 in Step 1600\n",
      "Training loss  0.646 in Step 1700\n",
      "Training loss  0.632\n",
      "Training timepoint saved\n",
      "Valid loss  0.464 in Step 0\n",
      "Valid loss  0.454 in Step 10\n",
      "Valid loss  0.471 in Step 20\n",
      "Valid loss  0.464 in Step 30\n",
      "Valid loss  0.446 in Step 40\n",
      "Valid loss  0.460 in Step 50\n",
      "Valid loss  0.468 in Step 60\n",
      "Valid loss  0.451 in Step 70\n",
      "Valid loss  0.465 in Step 80\n",
      "Valid loss  0.467 in Step 90\n",
      "Valid loss  0.469 in Step 100\n",
      "Valid loss  0.463 in Step 110\n",
      "Valid loss  0.466 in Step 120\n",
      "Valid loss  0.454 in Step 130\n",
      "Valid loss  0.459 in Step 140\n",
      "Valid loss  0.462 in Step 150\n",
      "Valid loss  0.464 in Step 160\n",
      "Valid loss  0.463 in Step 170\n",
      "Valid loss  0.450 in Step 180\n",
      "Valid loss  0.448 in Step 190\n",
      "Valid loss  0.455 in Step 200\n",
      "Valid loss  0.459 in Step 210\n",
      "Valid loss  0.459 in Step 220\n",
      "Valid loss  0.463 in Step 230\n",
      "Valid loss  0.461 in Step 240\n",
      "Valid loss  0.475 in Step 250\n",
      "Valid loss  0.468 in Step 260\n",
      "Valid loss  0.466 in Step 270\n",
      "Valid loss  0.454 in Step 280\n",
      "Valid loss  0.463 in Step 290\n",
      "Valid loss  0.455 in Step 300\n",
      "Valid loss  0.458 in Step 310\n",
      "Valid loss  0.465 in Step 320\n",
      "Valid loss  0.453 in Step 330\n",
      "Valid loss  0.447 in Step 340\n",
      "Valid loss  0.480 in Step 350\n",
      "Valid loss  0.450 in Step 360\n",
      "Valid loss  0.450 in Step 370\n",
      "Valid loss  0.469 in Step 380\n",
      "Valid loss  0.458 in Step 390\n",
      "Valid loss  0.457 in Step 400\n",
      "Valid loss  0.469 in Step 410\n",
      "Valid loss  0.461 in Step 420\n",
      "Valid loss  0.459 in Step 430\n",
      "Valid loss  0.447 in Step 440\n",
      "Valid loss  0.460\n",
      "Epoch 17\n",
      "Training loss  0.626 in Step 0\n",
      "Training loss  0.623 in Step 100\n",
      "Training loss  0.620 in Step 200\n",
      "Training loss  0.645 in Step 300\n",
      "Training loss  0.630 in Step 400\n",
      "Training loss  0.632 in Step 500\n",
      "Training loss  0.630 in Step 600\n",
      "Training loss  0.620 in Step 700\n",
      "Training loss  0.631 in Step 800\n",
      "Training loss  0.636 in Step 900\n",
      "Training loss  0.627 in Step 1000\n",
      "Training loss  0.626 in Step 1100\n",
      "Training loss  0.628 in Step 1200\n",
      "Training loss  0.612 in Step 1300\n",
      "Training loss  0.618 in Step 1400\n",
      "Training loss  0.628 in Step 1500\n",
      "Training loss  0.628 in Step 1600\n",
      "Training loss  0.638 in Step 1700\n",
      "Training loss  0.632\n",
      "Training timepoint saved\n",
      "Valid loss  0.469 in Step 0\n",
      "Valid loss  0.458 in Step 10\n",
      "Valid loss  0.475 in Step 20\n",
      "Valid loss  0.468 in Step 30\n",
      "Valid loss  0.449 in Step 40\n",
      "Valid loss  0.464 in Step 50\n",
      "Valid loss  0.473 in Step 60\n",
      "Valid loss  0.456 in Step 70\n",
      "Valid loss  0.470 in Step 80\n",
      "Valid loss  0.471 in Step 90\n",
      "Valid loss  0.473 in Step 100\n",
      "Valid loss  0.467 in Step 110\n",
      "Valid loss  0.470 in Step 120\n",
      "Valid loss  0.458 in Step 130\n",
      "Valid loss  0.463 in Step 140\n",
      "Valid loss  0.466 in Step 150\n",
      "Valid loss  0.470 in Step 160\n",
      "Valid loss  0.468 in Step 170\n",
      "Valid loss  0.452 in Step 180\n",
      "Valid loss  0.452 in Step 190\n",
      "Valid loss  0.460 in Step 200\n",
      "Valid loss  0.464 in Step 210\n",
      "Valid loss  0.464 in Step 220\n",
      "Valid loss  0.466 in Step 230\n",
      "Valid loss  0.465 in Step 240\n",
      "Valid loss  0.480 in Step 250\n",
      "Valid loss  0.472 in Step 260\n",
      "Valid loss  0.471 in Step 270\n",
      "Valid loss  0.458 in Step 280\n",
      "Valid loss  0.467 in Step 290\n",
      "Valid loss  0.460 in Step 300\n",
      "Valid loss  0.462 in Step 310\n",
      "Valid loss  0.469 in Step 320\n",
      "Valid loss  0.459 in Step 330\n",
      "Valid loss  0.451 in Step 340\n",
      "Valid loss  0.485 in Step 350\n",
      "Valid loss  0.454 in Step 360\n",
      "Valid loss  0.454 in Step 370\n",
      "Valid loss  0.474 in Step 380\n",
      "Valid loss  0.462 in Step 390\n",
      "Valid loss  0.462 in Step 400\n",
      "Valid loss  0.474 in Step 410\n",
      "Valid loss  0.466 in Step 420\n",
      "Valid loss  0.463 in Step 430\n",
      "Valid loss  0.451 in Step 440\n",
      "Valid loss  0.464\n",
      "Epoch 18\n",
      "Training loss  0.626 in Step 0\n",
      "Training loss  0.625 in Step 100\n",
      "Training loss  0.632 in Step 200\n",
      "Training loss  0.632 in Step 300\n",
      "Training loss  0.634 in Step 400\n",
      "Training loss  0.621 in Step 500\n",
      "Training loss  0.641 in Step 600\n",
      "Training loss  0.633 in Step 700\n",
      "Training loss  0.633 in Step 800\n",
      "Training loss  0.628 in Step 900\n",
      "Training loss  0.623 in Step 1000\n",
      "Training loss  0.631 in Step 1100\n",
      "Training loss  0.626 in Step 1200\n",
      "Training loss  0.635 in Step 1300\n",
      "Training loss  0.627 in Step 1400\n",
      "Training loss  0.632 in Step 1500\n",
      "Training loss  0.627 in Step 1600\n",
      "Training loss  0.628 in Step 1700\n",
      "Training loss  0.632\n",
      "Training timepoint saved\n",
      "Valid loss  0.469 in Step 0\n",
      "Valid loss  0.460 in Step 10\n",
      "Valid loss  0.476 in Step 20\n",
      "Valid loss  0.469 in Step 30\n",
      "Valid loss  0.451 in Step 40\n",
      "Valid loss  0.465 in Step 50\n",
      "Valid loss  0.475 in Step 60\n",
      "Valid loss  0.456 in Step 70\n",
      "Valid loss  0.472 in Step 80\n",
      "Valid loss  0.472 in Step 90\n",
      "Valid loss  0.473 in Step 100\n",
      "Valid loss  0.468 in Step 110\n",
      "Valid loss  0.470 in Step 120\n",
      "Valid loss  0.459 in Step 130\n",
      "Valid loss  0.465 in Step 140\n",
      "Valid loss  0.468 in Step 150\n",
      "Valid loss  0.470 in Step 160\n",
      "Valid loss  0.468 in Step 170\n",
      "Valid loss  0.454 in Step 180\n",
      "Valid loss  0.453 in Step 190\n",
      "Valid loss  0.461 in Step 200\n",
      "Valid loss  0.465 in Step 210\n",
      "Valid loss  0.465 in Step 220\n",
      "Valid loss  0.467 in Step 230\n",
      "Valid loss  0.466 in Step 240\n",
      "Valid loss  0.482 in Step 250\n",
      "Valid loss  0.474 in Step 260\n",
      "Valid loss  0.472 in Step 270\n",
      "Valid loss  0.460 in Step 280\n",
      "Valid loss  0.468 in Step 290\n",
      "Valid loss  0.461 in Step 300\n",
      "Valid loss  0.463 in Step 310\n",
      "Valid loss  0.471 in Step 320\n",
      "Valid loss  0.460 in Step 330\n",
      "Valid loss  0.452 in Step 340\n",
      "Valid loss  0.486 in Step 350\n",
      "Valid loss  0.455 in Step 360\n",
      "Valid loss  0.455 in Step 370\n",
      "Valid loss  0.475 in Step 380\n",
      "Valid loss  0.463 in Step 390\n",
      "Valid loss  0.463 in Step 400\n",
      "Valid loss  0.474 in Step 410\n",
      "Valid loss  0.467 in Step 420\n",
      "Valid loss  0.464 in Step 430\n",
      "Valid loss  0.453 in Step 440\n",
      "Valid loss  0.465\n",
      "Epoch 19\n",
      "Training loss  0.631 in Step 0\n",
      "Training loss  0.625 in Step 100\n",
      "Training loss  0.647 in Step 200\n",
      "Training loss  0.639 in Step 300\n",
      "Training loss  0.625 in Step 400\n",
      "Training loss  0.631 in Step 500\n",
      "Training loss  0.629 in Step 600\n",
      "Training loss  0.628 in Step 700\n",
      "Training loss  0.622 in Step 800\n",
      "Training loss  0.635 in Step 900\n",
      "Training loss  0.635 in Step 1000\n",
      "Training loss  0.638 in Step 1100\n",
      "Training loss  0.650 in Step 1200\n",
      "Training loss  0.635 in Step 1300\n",
      "Training loss  0.638 in Step 1400\n",
      "Training loss  0.643 in Step 1500\n",
      "Training loss  0.633 in Step 1600\n",
      "Training loss  0.633 in Step 1700\n",
      "Training loss  0.631\n",
      "Training timepoint saved\n",
      "Valid loss  0.474 in Step 0\n",
      "Valid loss  0.465 in Step 10\n",
      "Valid loss  0.481 in Step 20\n",
      "Valid loss  0.475 in Step 30\n",
      "Valid loss  0.455 in Step 40\n",
      "Valid loss  0.470 in Step 50\n",
      "Valid loss  0.480 in Step 60\n",
      "Valid loss  0.462 in Step 70\n",
      "Valid loss  0.478 in Step 80\n",
      "Valid loss  0.477 in Step 90\n",
      "Valid loss  0.478 in Step 100\n",
      "Valid loss  0.474 in Step 110\n",
      "Valid loss  0.475 in Step 120\n",
      "Valid loss  0.465 in Step 130\n",
      "Valid loss  0.470 in Step 140\n",
      "Valid loss  0.472 in Step 150\n",
      "Valid loss  0.477 in Step 160\n",
      "Valid loss  0.474 in Step 170\n",
      "Valid loss  0.458 in Step 180\n",
      "Valid loss  0.458 in Step 190\n",
      "Valid loss  0.465 in Step 200\n",
      "Valid loss  0.471 in Step 210\n",
      "Valid loss  0.471 in Step 220\n",
      "Valid loss  0.473 in Step 230\n",
      "Valid loss  0.471 in Step 240\n",
      "Valid loss  0.486 in Step 250\n",
      "Valid loss  0.479 in Step 260\n",
      "Valid loss  0.477 in Step 270\n",
      "Valid loss  0.465 in Step 280\n",
      "Valid loss  0.474 in Step 290\n",
      "Valid loss  0.466 in Step 300\n",
      "Valid loss  0.468 in Step 310\n",
      "Valid loss  0.476 in Step 320\n",
      "Valid loss  0.466 in Step 330\n",
      "Valid loss  0.458 in Step 340\n",
      "Valid loss  0.492 in Step 350\n",
      "Valid loss  0.460 in Step 360\n",
      "Valid loss  0.460 in Step 370\n",
      "Valid loss  0.481 in Step 380\n",
      "Valid loss  0.468 in Step 390\n",
      "Valid loss  0.468 in Step 400\n",
      "Valid loss  0.480 in Step 410\n",
      "Valid loss  0.472 in Step 420\n",
      "Valid loss  0.468 in Step 430\n",
      "Valid loss  0.458 in Step 440\n",
      "Valid loss  0.470\n",
      "Epoch 20\n",
      "Training loss  0.614 in Step 0\n",
      "Training loss  0.630 in Step 100\n",
      "Training loss  0.635 in Step 200\n",
      "Training loss  0.635 in Step 300\n",
      "Training loss  0.639 in Step 400\n",
      "Training loss  0.629 in Step 500\n",
      "Training loss  0.625 in Step 600\n",
      "Training loss  0.627 in Step 700\n",
      "Training loss  0.616 in Step 800\n",
      "Training loss  0.630 in Step 900\n",
      "Training loss  0.615 in Step 1000\n",
      "Training loss  0.631 in Step 1100\n",
      "Training loss  0.640 in Step 1200\n",
      "Training loss  0.645 in Step 1300\n",
      "Training loss  0.633 in Step 1400\n",
      "Training loss  0.628 in Step 1500\n",
      "Training loss  0.619 in Step 1600\n",
      "Training loss  0.631 in Step 1700\n",
      "Training loss  0.631\n",
      "Training timepoint saved\n",
      "Valid loss  0.476 in Step 0\n",
      "Valid loss  0.467 in Step 10\n",
      "Valid loss  0.484 in Step 20\n",
      "Valid loss  0.477 in Step 30\n",
      "Valid loss  0.457 in Step 40\n",
      "Valid loss  0.473 in Step 50\n",
      "Valid loss  0.483 in Step 60\n",
      "Valid loss  0.464 in Step 70\n",
      "Valid loss  0.480 in Step 80\n",
      "Valid loss  0.479 in Step 90\n",
      "Valid loss  0.480 in Step 100\n",
      "Valid loss  0.477 in Step 110\n",
      "Valid loss  0.476 in Step 120\n",
      "Valid loss  0.466 in Step 130\n",
      "Valid loss  0.472 in Step 140\n",
      "Valid loss  0.473 in Step 150\n",
      "Valid loss  0.480 in Step 160\n",
      "Valid loss  0.476 in Step 170\n",
      "Valid loss  0.459 in Step 180\n",
      "Valid loss  0.462 in Step 190\n",
      "Valid loss  0.468 in Step 200\n",
      "Valid loss  0.473 in Step 210\n",
      "Valid loss  0.473 in Step 220\n",
      "Valid loss  0.474 in Step 230\n",
      "Valid loss  0.473 in Step 240\n",
      "Valid loss  0.488 in Step 250\n",
      "Valid loss  0.481 in Step 260\n",
      "Valid loss  0.479 in Step 270\n",
      "Valid loss  0.467 in Step 280\n",
      "Valid loss  0.476 in Step 290\n",
      "Valid loss  0.469 in Step 300\n",
      "Valid loss  0.470 in Step 310\n",
      "Valid loss  0.479 in Step 320\n",
      "Valid loss  0.469 in Step 330\n",
      "Valid loss  0.460 in Step 340\n",
      "Valid loss  0.494 in Step 350\n",
      "Valid loss  0.462 in Step 360\n",
      "Valid loss  0.462 in Step 370\n",
      "Valid loss  0.483 in Step 380\n",
      "Valid loss  0.469 in Step 390\n",
      "Valid loss  0.470 in Step 400\n",
      "Valid loss  0.481 in Step 410\n",
      "Valid loss  0.474 in Step 420\n",
      "Valid loss  0.470 in Step 430\n",
      "Valid loss  0.461 in Step 440\n",
      "Valid loss  0.472\n",
      "Epoch 21\n",
      "Training loss  0.640 in Step 0\n",
      "Training loss  0.624 in Step 100\n",
      "Training loss  0.622 in Step 200\n",
      "Training loss  0.626 in Step 300\n",
      "Training loss  0.624 in Step 400\n",
      "Training loss  0.620 in Step 500\n",
      "Training loss  0.628 in Step 600\n",
      "Training loss  0.626 in Step 700\n",
      "Training loss  0.642 in Step 800\n",
      "Training loss  0.629 in Step 900\n",
      "Training loss  0.635 in Step 1000\n",
      "Training loss  0.649 in Step 1100\n",
      "Training loss  0.632 in Step 1200\n",
      "Training loss  0.633 in Step 1300\n",
      "Training loss  0.628 in Step 1400\n",
      "Training loss  0.627 in Step 1500\n",
      "Training loss  0.631 in Step 1600\n",
      "Training loss  0.624 in Step 1700\n",
      "Training loss  0.631\n",
      "Training timepoint saved\n",
      "Valid loss  0.476 in Step 0\n",
      "Valid loss  0.467 in Step 10\n",
      "Valid loss  0.485 in Step 20\n",
      "Valid loss  0.477 in Step 30\n",
      "Valid loss  0.458 in Step 40\n",
      "Valid loss  0.474 in Step 50\n",
      "Valid loss  0.483 in Step 60\n",
      "Valid loss  0.465 in Step 70\n",
      "Valid loss  0.481 in Step 80\n",
      "Valid loss  0.479 in Step 90\n",
      "Valid loss  0.481 in Step 100\n",
      "Valid loss  0.477 in Step 110\n",
      "Valid loss  0.477 in Step 120\n",
      "Valid loss  0.467 in Step 130\n",
      "Valid loss  0.472 in Step 140\n",
      "Valid loss  0.474 in Step 150\n",
      "Valid loss  0.480 in Step 160\n",
      "Valid loss  0.476 in Step 170\n",
      "Valid loss  0.460 in Step 180\n",
      "Valid loss  0.461 in Step 190\n",
      "Valid loss  0.468 in Step 200\n",
      "Valid loss  0.473 in Step 210\n",
      "Valid loss  0.473 in Step 220\n",
      "Valid loss  0.474 in Step 230\n",
      "Valid loss  0.474 in Step 240\n",
      "Valid loss  0.490 in Step 250\n",
      "Valid loss  0.480 in Step 260\n",
      "Valid loss  0.480 in Step 270\n",
      "Valid loss  0.468 in Step 280\n",
      "Valid loss  0.476 in Step 290\n",
      "Valid loss  0.469 in Step 300\n",
      "Valid loss  0.470 in Step 310\n",
      "Valid loss  0.480 in Step 320\n",
      "Valid loss  0.469 in Step 330\n",
      "Valid loss  0.461 in Step 340\n",
      "Valid loss  0.496 in Step 350\n",
      "Valid loss  0.462 in Step 360\n",
      "Valid loss  0.463 in Step 370\n",
      "Valid loss  0.483 in Step 380\n",
      "Valid loss  0.469 in Step 390\n",
      "Valid loss  0.470 in Step 400\n",
      "Valid loss  0.481 in Step 410\n",
      "Valid loss  0.474 in Step 420\n",
      "Valid loss  0.471 in Step 430\n",
      "Valid loss  0.461 in Step 440\n",
      "Valid loss  0.473\n",
      "Epoch 22\n",
      "Training loss  0.638 in Step 0\n",
      "Training loss  0.634 in Step 100\n",
      "Training loss  0.638 in Step 200\n",
      "Training loss  0.614 in Step 300\n",
      "Training loss  0.625 in Step 400\n",
      "Training loss  0.621 in Step 500\n",
      "Training loss  0.628 in Step 600\n",
      "Training loss  0.624 in Step 700\n",
      "Training loss  0.615 in Step 800\n",
      "Training loss  0.621 in Step 900\n",
      "Training loss  0.620 in Step 1000\n",
      "Training loss  0.624 in Step 1100\n",
      "Training loss  0.630 in Step 1200\n",
      "Training loss  0.642 in Step 1300\n",
      "Training loss  0.627 in Step 1400\n",
      "Training loss  0.633 in Step 1500\n",
      "Training loss  0.616 in Step 1600\n",
      "Training loss  0.617 in Step 1700\n",
      "Training loss  0.631\n",
      "Training timepoint saved\n",
      "Valid loss  0.482 in Step 0\n",
      "Valid loss  0.473 in Step 10\n",
      "Valid loss  0.491 in Step 20\n",
      "Valid loss  0.485 in Step 30\n",
      "Valid loss  0.463 in Step 40\n",
      "Valid loss  0.480 in Step 50\n",
      "Valid loss  0.489 in Step 60\n",
      "Valid loss  0.470 in Step 70\n",
      "Valid loss  0.488 in Step 80\n",
      "Valid loss  0.485 in Step 90\n",
      "Valid loss  0.486 in Step 100\n",
      "Valid loss  0.484 in Step 110\n",
      "Valid loss  0.482 in Step 120\n",
      "Valid loss  0.472 in Step 130\n",
      "Valid loss  0.478 in Step 140\n",
      "Valid loss  0.479 in Step 150\n",
      "Valid loss  0.487 in Step 160\n",
      "Valid loss  0.482 in Step 170\n",
      "Valid loss  0.465 in Step 180\n",
      "Valid loss  0.469 in Step 190\n",
      "Valid loss  0.475 in Step 200\n",
      "Valid loss  0.479 in Step 210\n",
      "Valid loss  0.479 in Step 220\n",
      "Valid loss  0.481 in Step 230\n",
      "Valid loss  0.479 in Step 240\n",
      "Valid loss  0.496 in Step 250\n",
      "Valid loss  0.487 in Step 260\n",
      "Valid loss  0.485 in Step 270\n",
      "Valid loss  0.474 in Step 280\n",
      "Valid loss  0.482 in Step 290\n",
      "Valid loss  0.474 in Step 300\n",
      "Valid loss  0.476 in Step 310\n",
      "Valid loss  0.486 in Step 320\n",
      "Valid loss  0.476 in Step 330\n",
      "Valid loss  0.467 in Step 340\n",
      "Valid loss  0.501 in Step 350\n",
      "Valid loss  0.467 in Step 360\n",
      "Valid loss  0.469 in Step 370\n",
      "Valid loss  0.489 in Step 380\n",
      "Valid loss  0.476 in Step 390\n",
      "Valid loss  0.477 in Step 400\n",
      "Valid loss  0.487 in Step 410\n",
      "Valid loss  0.481 in Step 420\n",
      "Valid loss  0.476 in Step 430\n",
      "Valid loss  0.468 in Step 440\n",
      "Valid loss  0.479\n",
      "Epoch 23\n",
      "Training loss  0.642 in Step 0\n",
      "Training loss  0.639 in Step 100\n",
      "Training loss  0.646 in Step 200\n",
      "Training loss  0.635 in Step 300\n",
      "Training loss  0.631 in Step 400\n",
      "Training loss  0.631 in Step 500\n",
      "Training loss  0.618 in Step 600\n",
      "Training loss  0.631 in Step 700\n",
      "Training loss  0.620 in Step 800\n",
      "Training loss  0.633 in Step 900\n",
      "Training loss  0.622 in Step 1000\n",
      "Training loss  0.636 in Step 1100\n",
      "Training loss  0.630 in Step 1200\n",
      "Training loss  0.634 in Step 1300\n",
      "Training loss  0.635 in Step 1400\n",
      "Training loss  0.634 in Step 1500\n",
      "Training loss  0.617 in Step 1600\n",
      "Training loss  0.629 in Step 1700\n",
      "Training loss  0.630\n",
      "Training timepoint saved\n",
      "Valid loss  0.489 in Step 0\n",
      "Valid loss  0.481 in Step 10\n",
      "Valid loss  0.499 in Step 20\n",
      "Valid loss  0.492 in Step 30\n",
      "Valid loss  0.471 in Step 40\n",
      "Valid loss  0.488 in Step 50\n",
      "Valid loss  0.498 in Step 60\n",
      "Valid loss  0.479 in Step 70\n",
      "Valid loss  0.496 in Step 80\n",
      "Valid loss  0.492 in Step 90\n",
      "Valid loss  0.494 in Step 100\n",
      "Valid loss  0.493 in Step 110\n",
      "Valid loss  0.490 in Step 120\n",
      "Valid loss  0.480 in Step 130\n",
      "Valid loss  0.486 in Step 140\n",
      "Valid loss  0.487 in Step 150\n",
      "Valid loss  0.496 in Step 160\n",
      "Valid loss  0.491 in Step 170\n",
      "Valid loss  0.472 in Step 180\n",
      "Valid loss  0.477 in Step 190\n",
      "Valid loss  0.483 in Step 200\n",
      "Valid loss  0.488 in Step 210\n",
      "Valid loss  0.488 in Step 220\n",
      "Valid loss  0.488 in Step 230\n",
      "Valid loss  0.487 in Step 240\n",
      "Valid loss  0.504 in Step 250\n",
      "Valid loss  0.494 in Step 260\n",
      "Valid loss  0.493 in Step 270\n",
      "Valid loss  0.482 in Step 280\n",
      "Valid loss  0.490 in Step 290\n",
      "Valid loss  0.483 in Step 300\n",
      "Valid loss  0.484 in Step 310\n",
      "Valid loss  0.494 in Step 320\n",
      "Valid loss  0.485 in Step 330\n",
      "Valid loss  0.475 in Step 340\n",
      "Valid loss  0.509 in Step 350\n",
      "Valid loss  0.475 in Step 360\n",
      "Valid loss  0.476 in Step 370\n",
      "Valid loss  0.498 in Step 380\n",
      "Valid loss  0.483 in Step 390\n",
      "Valid loss  0.485 in Step 400\n",
      "Valid loss  0.495 in Step 410\n",
      "Valid loss  0.488 in Step 420\n",
      "Valid loss  0.485 in Step 430\n",
      "Valid loss  0.476 in Step 440\n",
      "Valid loss  0.487\n",
      "Epoch 24\n",
      "Training loss  0.642 in Step 0\n",
      "Training loss  0.625 in Step 100\n",
      "Training loss  0.627 in Step 200\n",
      "Training loss  0.627 in Step 300\n",
      "Training loss  0.634 in Step 400\n",
      "Training loss  0.633 in Step 500\n",
      "Training loss  0.641 in Step 600\n",
      "Training loss  0.627 in Step 700\n",
      "Training loss  0.636 in Step 800\n",
      "Training loss  0.627 in Step 900\n",
      "Training loss  0.651 in Step 1000\n",
      "Training loss  0.637 in Step 1100\n",
      "Training loss  0.635 in Step 1200\n",
      "Training loss  0.636 in Step 1300\n",
      "Training loss  0.632 in Step 1400\n",
      "Training loss  0.636 in Step 1500\n",
      "Training loss  0.637 in Step 1600\n",
      "Training loss  0.606 in Step 1700\n",
      "Training loss  0.630\n",
      "Training timepoint saved\n",
      "Valid loss  0.491 in Step 0\n",
      "Valid loss  0.482 in Step 10\n",
      "Valid loss  0.499 in Step 20\n",
      "Valid loss  0.493 in Step 30\n",
      "Valid loss  0.472 in Step 40\n",
      "Valid loss  0.489 in Step 50\n",
      "Valid loss  0.498 in Step 60\n",
      "Valid loss  0.479 in Step 70\n",
      "Valid loss  0.496 in Step 80\n",
      "Valid loss  0.493 in Step 90\n",
      "Valid loss  0.494 in Step 100\n",
      "Valid loss  0.494 in Step 110\n",
      "Valid loss  0.491 in Step 120\n",
      "Valid loss  0.480 in Step 130\n",
      "Valid loss  0.487 in Step 140\n",
      "Valid loss  0.487 in Step 150\n",
      "Valid loss  0.497 in Step 160\n",
      "Valid loss  0.492 in Step 170\n",
      "Valid loss  0.472 in Step 180\n",
      "Valid loss  0.479 in Step 190\n",
      "Valid loss  0.483 in Step 200\n",
      "Valid loss  0.489 in Step 210\n",
      "Valid loss  0.488 in Step 220\n",
      "Valid loss  0.489 in Step 230\n",
      "Valid loss  0.488 in Step 240\n",
      "Valid loss  0.504 in Step 250\n",
      "Valid loss  0.495 in Step 260\n",
      "Valid loss  0.493 in Step 270\n",
      "Valid loss  0.483 in Step 280\n",
      "Valid loss  0.491 in Step 290\n",
      "Valid loss  0.484 in Step 300\n",
      "Valid loss  0.485 in Step 310\n",
      "Valid loss  0.495 in Step 320\n",
      "Valid loss  0.484 in Step 330\n",
      "Valid loss  0.477 in Step 340\n",
      "Valid loss  0.510 in Step 350\n",
      "Valid loss  0.476 in Step 360\n",
      "Valid loss  0.477 in Step 370\n",
      "Valid loss  0.499 in Step 380\n",
      "Valid loss  0.484 in Step 390\n",
      "Valid loss  0.486 in Step 400\n",
      "Valid loss  0.497 in Step 410\n",
      "Valid loss  0.488 in Step 420\n",
      "Valid loss  0.485 in Step 430\n",
      "Valid loss  0.478 in Step 440\n",
      "Valid loss  0.487\n",
      "Epoch 25\n",
      "Training loss  0.640 in Step 0\n",
      "Training loss  0.626 in Step 100\n",
      "Training loss  0.619 in Step 200\n",
      "Training loss  0.628 in Step 300\n",
      "Training loss  0.630 in Step 400\n",
      "Training loss  0.633 in Step 500\n",
      "Training loss  0.632 in Step 600\n",
      "Training loss  0.631 in Step 700\n",
      "Training loss  0.637 in Step 800\n",
      "Training loss  0.629 in Step 900\n",
      "Training loss  0.625 in Step 1000\n",
      "Training loss  0.638 in Step 1100\n",
      "Training loss  0.621 in Step 1200\n",
      "Training loss  0.638 in Step 1300\n",
      "Training loss  0.634 in Step 1400\n",
      "Training loss  0.618 in Step 1500\n",
      "Training loss  0.620 in Step 1600\n",
      "Training loss  0.630 in Step 1700\n",
      "Training loss  0.630\n",
      "Training timepoint saved\n",
      "Valid loss  0.493 in Step 0\n",
      "Valid loss  0.483 in Step 10\n",
      "Valid loss  0.502 in Step 20\n",
      "Valid loss  0.496 in Step 30\n",
      "Valid loss  0.473 in Step 40\n",
      "Valid loss  0.492 in Step 50\n",
      "Valid loss  0.500 in Step 60\n",
      "Valid loss  0.481 in Step 70\n",
      "Valid loss  0.497 in Step 80\n",
      "Valid loss  0.495 in Step 90\n",
      "Valid loss  0.496 in Step 100\n",
      "Valid loss  0.497 in Step 110\n",
      "Valid loss  0.493 in Step 120\n",
      "Valid loss  0.482 in Step 130\n",
      "Valid loss  0.489 in Step 140\n",
      "Valid loss  0.489 in Step 150\n",
      "Valid loss  0.499 in Step 160\n",
      "Valid loss  0.494 in Step 170\n",
      "Valid loss  0.474 in Step 180\n",
      "Valid loss  0.481 in Step 190\n",
      "Valid loss  0.485 in Step 200\n",
      "Valid loss  0.491 in Step 210\n",
      "Valid loss  0.490 in Step 220\n",
      "Valid loss  0.491 in Step 230\n",
      "Valid loss  0.490 in Step 240\n",
      "Valid loss  0.506 in Step 250\n",
      "Valid loss  0.497 in Step 260\n",
      "Valid loss  0.495 in Step 270\n",
      "Valid loss  0.485 in Step 280\n",
      "Valid loss  0.494 in Step 290\n",
      "Valid loss  0.486 in Step 300\n",
      "Valid loss  0.486 in Step 310\n",
      "Valid loss  0.497 in Step 320\n",
      "Valid loss  0.487 in Step 330\n",
      "Valid loss  0.480 in Step 340\n",
      "Valid loss  0.512 in Step 350\n",
      "Valid loss  0.478 in Step 360\n",
      "Valid loss  0.479 in Step 370\n",
      "Valid loss  0.501 in Step 380\n",
      "Valid loss  0.485 in Step 390\n",
      "Valid loss  0.487 in Step 400\n",
      "Valid loss  0.498 in Step 410\n",
      "Valid loss  0.490 in Step 420\n",
      "Valid loss  0.487 in Step 430\n",
      "Valid loss  0.480 in Step 440\n",
      "Valid loss  0.489\n",
      "Epoch 26\n",
      "Training loss  0.610 in Step 0\n",
      "Training loss  0.630 in Step 100\n",
      "Training loss  0.633 in Step 200\n",
      "Training loss  0.630 in Step 300\n",
      "Training loss  0.636 in Step 400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train()\n",
      "\u001b[1;32m/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m recon_x, attn_weight \u001b[39m=\u001b[39m model(x, x_lens, x_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m model_loss\u001b[39m.\u001b[39mget_loss(recon_x, y, x_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ldlmdl/Documents/wavln/scripts/A_03.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wavln/scripts/model.py:438\u001b[0m, in \u001b[0;36mLHYPhxLearner.forward\u001b[0;34m(self, inputs, input_lens, in_mask)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, input_lens, in_mask):\n\u001b[1;32m    435\u001b[0m     \u001b[39m# inputs : batch_size * time_steps * in_size\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     batch_size \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 438\u001b[0m     enc_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(inputs, input_lens, in_mask)\n\u001b[1;32m    439\u001b[0m     dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(enc_out, in_mask, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, input_lens)\n\u001b[1;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m dec_out, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wavln/scripts/model.py:354\u001b[0m, in \u001b[0;36mLHYEncoder.forward\u001b[0;34m(self, inputs, inputs_lens, in_mask, hidden)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[39m    inputs: input data (B, L, I)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m    hidden: HM_LSTM, abolished\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m enc_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(inputs) \u001b[39m# (B, L, I2) -> (B, L, I3)\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m enc_x \u001b[39m=\u001b[39m pack_padded_sequence(enc_x, inputs_lens, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, enforce_sorted\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    356\u001b[0m enc_x, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(enc_x)  \u001b[39m# (B, L, I1) -> (B, L, I2)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m enc_x, _ \u001b[39m=\u001b[39m pad_packed_sequence(enc_x, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/utils/rnn.py:263\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    259\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    260\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    262\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 263\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[1;32m    264\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "train_losses.save()\n",
    "\n",
    "valid_losses.save()\n",
    "\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9df8776f50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This model should converge to loss around 0.49x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
