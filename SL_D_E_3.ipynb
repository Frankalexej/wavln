{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English\n",
    "Version 1: In this version we make the model \"simple\": make the encoder RNN into normal RNN first and try to see the result.  \n",
    "Version 2: Learning is not very much. Following Dr Coupe's advice we try simpler model structure.   \n",
    "Version 3: A simple trial training with Mel spectrogram instead of MFCC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PhxLearner, SimplerPhxLearner\n",
    "from my_dataset import DS_Tools\n",
    "from dataset import SeqDataset, MelSpecTransform\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_DIM = 64\n",
    "OUTPUT_DIM = 64\n",
    "\n",
    "INTER_DIM_0 = 32\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 3\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): RLEncoder(\n",
       "    (rnn): LSTM(64, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RALDecoder(\n",
       "    (rnn): LSTM(64, 3, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "# ts = \"0908015948\"\n",
    "# stop_epoch = \"149\"\n",
    "ts = str(get_timestamp())\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    model_raw_name = \"PT_{}_{}_full\".format(ts, stop_epoch)\n",
    "    model_name = model_raw_name + \".pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MelSpecTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)\n",
    "ds = SeqDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "\n",
    "if READ: \n",
    "    valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)))\n",
    "    all_indices = list(range(len(ds)))\n",
    "    train_ds_indices = list(set(all_indices).difference(set(valid_ds_indices)))\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(ds, train_ds_indices)\n",
    "    valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "else: \n",
    "    train_len = int(0.8 * len(ds))\n",
    "    valid_len = len(ds) - train_len\n",
    "\n",
    "    # Randomly split the dataset into train and validation sets\n",
    "    train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "    DS_Tools.save_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(ts)), valid_ds.indices)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=SeqDataset.collate_fn)\n",
    "valid_num = len(valid_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BASE = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y = x \n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            # 这个函数计算的是全局梯度范数\n",
    "            # torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "            # parameters: an iterable of Variables that will have gradients normalized\n",
    "            # max_norm: max norm of the gradients(阈值设定)\n",
    "            # norm_type: type of the used p-norm. Can be'inf'for infinity norm(定义范数类型)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            y = x    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss  0.713 in Step 0\n",
      "Training loss  0.703 in Step 100\n",
      "Training loss  0.724 in Step 200\n",
      "Training loss  0.694 in Step 300\n",
      "Training loss  0.703 in Step 400\n",
      "Training loss  0.699 in Step 500\n",
      "Training loss  0.722 in Step 600\n",
      "Training loss  0.717 in Step 700\n",
      "Training loss  0.703 in Step 800\n",
      "Training loss  0.711 in Step 900\n",
      "Training loss  0.687 in Step 1000\n",
      "Training loss  0.687 in Step 1100\n",
      "Training loss  0.693 in Step 1200\n",
      "Training loss  0.704 in Step 1300\n",
      "Training loss  0.694 in Step 1400\n",
      "Training loss  0.674 in Step 1500\n",
      "Training loss  0.692 in Step 1600\n",
      "Training loss  0.701 in Step 1700\n",
      "※※※Training loss  0.702※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.690 in Step 0\n",
      "Valid loss  0.699 in Step 100\n",
      "Valid loss  0.696 in Step 200\n",
      "Valid loss  0.725 in Step 300\n",
      "Valid loss  0.728 in Step 400\n",
      "※※※Valid loss  0.707※※※\n",
      "Epoch 51\n",
      "Training loss  0.673 in Step 0\n",
      "Training loss  0.691 in Step 100\n",
      "Training loss  0.693 in Step 200\n",
      "Training loss  0.702 in Step 300\n",
      "Training loss  0.706 in Step 400\n",
      "Training loss  0.703 in Step 500\n",
      "Training loss  0.696 in Step 600\n",
      "Training loss  0.718 in Step 700\n",
      "Training loss  0.720 in Step 800\n",
      "Training loss  0.698 in Step 900\n",
      "Training loss  0.691 in Step 1000\n",
      "Training loss  0.699 in Step 1100\n",
      "Training loss  0.696 in Step 1200\n",
      "Training loss  0.712 in Step 1300\n",
      "Training loss  0.699 in Step 1400\n",
      "Training loss  0.694 in Step 1500\n",
      "Training loss  0.696 in Step 1600\n",
      "Training loss  0.730 in Step 1700\n",
      "※※※Training loss  0.702※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.684 in Step 0\n",
      "Valid loss  0.698 in Step 100\n",
      "Valid loss  0.693 in Step 200\n",
      "Valid loss  0.717 in Step 300\n",
      "Valid loss  0.726 in Step 400\n",
      "※※※Valid loss  0.703※※※\n",
      "Epoch 52\n",
      "Training loss  0.688 in Step 0\n",
      "Training loss  0.710 in Step 100\n",
      "Training loss  0.704 in Step 200\n",
      "Training loss  0.703 in Step 300\n",
      "Training loss  0.691 in Step 400\n",
      "Training loss  0.709 in Step 500\n",
      "Training loss  0.706 in Step 600\n",
      "Training loss  0.717 in Step 700\n",
      "Training loss  0.705 in Step 800\n",
      "Training loss  0.701 in Step 900\n",
      "Training loss  0.699 in Step 1000\n",
      "Training loss  0.674 in Step 1100\n",
      "Training loss  0.703 in Step 1200\n",
      "Training loss  0.695 in Step 1300\n",
      "Training loss  0.720 in Step 1400\n",
      "Training loss  0.726 in Step 1500\n",
      "Training loss  0.689 in Step 1600\n",
      "Training loss  0.687 in Step 1700\n",
      "※※※Training loss  0.703※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.680 in Step 0\n",
      "Valid loss  0.693 in Step 100\n",
      "Valid loss  0.691 in Step 200\n",
      "Valid loss  0.718 in Step 300\n",
      "Valid loss  0.722 in Step 400\n",
      "※※※Valid loss  0.700※※※\n",
      "Epoch 53\n",
      "Training loss  0.721 in Step 0\n",
      "Training loss  0.718 in Step 100\n",
      "Training loss  0.705 in Step 200\n",
      "Training loss  0.735 in Step 300\n",
      "Training loss  0.689 in Step 400\n",
      "Training loss  0.701 in Step 500\n",
      "Training loss  0.710 in Step 600\n",
      "Training loss  0.680 in Step 700\n",
      "Training loss  0.711 in Step 800\n",
      "Training loss  0.688 in Step 900\n",
      "Training loss  0.688 in Step 1000\n",
      "Training loss  0.702 in Step 1100\n",
      "Training loss  0.708 in Step 1200\n",
      "Training loss  0.715 in Step 1300\n",
      "Training loss  0.683 in Step 1400\n",
      "Training loss  0.678 in Step 1500\n",
      "Training loss  0.694 in Step 1600\n",
      "Training loss  0.706 in Step 1700\n",
      "※※※Training loss  0.704※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.681 in Step 0\n",
      "Valid loss  0.694 in Step 100\n",
      "Valid loss  0.692 in Step 200\n",
      "Valid loss  0.717 in Step 300\n",
      "Valid loss  0.718 in Step 400\n",
      "※※※Valid loss  0.699※※※\n",
      "Epoch 54\n",
      "Training loss  0.703 in Step 0\n",
      "Training loss  0.695 in Step 100\n",
      "Training loss  0.722 in Step 200\n",
      "Training loss  0.691 in Step 300\n",
      "Training loss  0.686 in Step 400\n",
      "Training loss  0.686 in Step 500\n",
      "Training loss  0.684 in Step 600\n",
      "Training loss  0.704 in Step 700\n",
      "Training loss  0.714 in Step 800\n",
      "Training loss  0.673 in Step 900\n",
      "Training loss  0.687 in Step 1000\n",
      "Training loss  0.697 in Step 1100\n",
      "Training loss  0.699 in Step 1200\n",
      "Training loss  0.703 in Step 1300\n",
      "Training loss  0.691 in Step 1400\n",
      "Training loss  0.698 in Step 1500\n",
      "Training loss  0.726 in Step 1600\n",
      "Training loss  0.730 in Step 1700\n",
      "※※※Training loss  0.701※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.683 in Step 0\n",
      "Valid loss  0.696 in Step 100\n",
      "Valid loss  0.694 in Step 200\n",
      "Valid loss  0.716 in Step 300\n",
      "Valid loss  0.724 in Step 400\n",
      "※※※Valid loss  0.701※※※\n",
      "Epoch 55\n",
      "Training loss  0.694 in Step 0\n",
      "Training loss  0.708 in Step 100\n",
      "Training loss  0.679 in Step 200\n",
      "Training loss  0.709 in Step 300\n",
      "Training loss  0.704 in Step 400\n",
      "Training loss  0.704 in Step 500\n",
      "Training loss  0.698 in Step 600\n",
      "Training loss  0.684 in Step 700\n",
      "Training loss  0.698 in Step 800\n",
      "Training loss  0.699 in Step 900\n",
      "Training loss  0.701 in Step 1000\n",
      "Training loss  0.689 in Step 1100\n",
      "Training loss  0.715 in Step 1200\n",
      "Training loss  0.694 in Step 1300\n",
      "Training loss  0.705 in Step 1400\n",
      "Training loss  0.704 in Step 1500\n",
      "Training loss  0.707 in Step 1600\n",
      "Training loss  0.708 in Step 1700\n",
      "※※※Training loss  0.700※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.678 in Step 0\n",
      "Valid loss  0.692 in Step 100\n",
      "Valid loss  0.692 in Step 200\n",
      "Valid loss  0.717 in Step 300\n",
      "Valid loss  0.721 in Step 400\n",
      "※※※Valid loss  0.699※※※\n",
      "Epoch 56\n",
      "Training loss  0.669 in Step 0\n",
      "Training loss  0.700 in Step 100\n",
      "Training loss  0.688 in Step 200\n",
      "Training loss  0.720 in Step 300\n",
      "Training loss  0.717 in Step 400\n",
      "Training loss  0.690 in Step 500\n",
      "Training loss  0.705 in Step 600\n",
      "Training loss  0.701 in Step 700\n",
      "Training loss  0.705 in Step 800\n",
      "Training loss  0.702 in Step 900\n",
      "Training loss  0.688 in Step 1000\n",
      "Training loss  0.713 in Step 1100\n",
      "Training loss  0.708 in Step 1200\n",
      "Training loss  0.704 in Step 1300\n",
      "Training loss  0.682 in Step 1400\n",
      "Training loss  0.682 in Step 1500\n",
      "Training loss  0.719 in Step 1600\n",
      "Training loss  0.715 in Step 1700\n",
      "※※※Training loss  0.699※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.677 in Step 0\n",
      "Valid loss  0.693 in Step 100\n",
      "Valid loss  0.693 in Step 200\n",
      "Valid loss  0.709 in Step 300\n",
      "Valid loss  0.721 in Step 400\n",
      "※※※Valid loss  0.699※※※\n",
      "Epoch 57\n",
      "Training loss  0.682 in Step 0\n",
      "Training loss  0.700 in Step 100\n",
      "Training loss  0.692 in Step 200\n",
      "Training loss  0.691 in Step 300\n",
      "Training loss  0.690 in Step 400\n",
      "Training loss  0.710 in Step 500\n",
      "Training loss  0.694 in Step 600\n",
      "Training loss  0.701 in Step 700\n",
      "Training loss  0.707 in Step 800\n",
      "Training loss  0.705 in Step 900\n",
      "Training loss  0.694 in Step 1000\n",
      "Training loss  0.677 in Step 1100\n",
      "Training loss  0.685 in Step 1200\n",
      "Training loss  0.677 in Step 1300\n",
      "Training loss  0.698 in Step 1400\n",
      "Training loss  0.691 in Step 1500\n",
      "Training loss  0.687 in Step 1600\n",
      "Training loss  0.697 in Step 1700\n",
      "※※※Training loss  0.699※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.677 in Step 0\n",
      "Valid loss  0.694 in Step 100\n",
      "Valid loss  0.690 in Step 200\n",
      "Valid loss  0.710 in Step 300\n",
      "Valid loss  0.720 in Step 400\n",
      "※※※Valid loss  0.698※※※\n",
      "Epoch 58\n",
      "Training loss  0.698 in Step 0\n",
      "Training loss  0.686 in Step 100\n",
      "Training loss  0.711 in Step 200\n",
      "Training loss  0.720 in Step 300\n",
      "Training loss  0.684 in Step 400\n",
      "Training loss  0.702 in Step 500\n",
      "Training loss  0.717 in Step 600\n",
      "Training loss  0.688 in Step 700\n",
      "Training loss  0.699 in Step 800\n",
      "Training loss  0.715 in Step 900\n",
      "Training loss  0.695 in Step 1000\n",
      "Training loss  0.690 in Step 1100\n",
      "Training loss  0.697 in Step 1200\n",
      "Training loss  0.677 in Step 1300\n",
      "Training loss  0.698 in Step 1400\n",
      "Training loss  0.714 in Step 1500\n",
      "Training loss  0.707 in Step 1600\n",
      "Training loss  0.709 in Step 1700\n",
      "※※※Training loss  0.698※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.677 in Step 0\n",
      "Valid loss  0.691 in Step 100\n",
      "Valid loss  0.688 in Step 200\n",
      "Valid loss  0.715 in Step 300\n",
      "Valid loss  0.719 in Step 400\n",
      "※※※Valid loss  0.697※※※\n",
      "Epoch 59\n",
      "Training loss  0.684 in Step 0\n",
      "Training loss  0.689 in Step 100\n",
      "Training loss  0.677 in Step 200\n",
      "Training loss  0.685 in Step 300\n",
      "Training loss  0.717 in Step 400\n",
      "Training loss  0.682 in Step 500\n",
      "Training loss  0.697 in Step 600\n",
      "Training loss  0.700 in Step 700\n",
      "Training loss  0.690 in Step 800\n",
      "Training loss  0.709 in Step 900\n",
      "Training loss  0.694 in Step 1000\n",
      "Training loss  0.711 in Step 1100\n",
      "Training loss  0.678 in Step 1200\n",
      "Training loss  0.688 in Step 1300\n",
      "Training loss  0.702 in Step 1400\n",
      "Training loss  0.688 in Step 1500\n",
      "Training loss  0.713 in Step 1600\n",
      "Training loss  0.692 in Step 1700\n",
      "※※※Training loss  0.698※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.676 in Step 0\n",
      "Valid loss  0.691 in Step 100\n",
      "Valid loss  0.689 in Step 200\n",
      "Valid loss  0.717 in Step 300\n",
      "Valid loss  0.720 in Step 400\n",
      "※※※Valid loss  0.696※※※\n",
      "Epoch 60\n",
      "Training loss  0.684 in Step 0\n",
      "Training loss  0.697 in Step 100\n",
      "Training loss  0.680 in Step 200\n",
      "Training loss  0.720 in Step 300\n",
      "Training loss  0.697 in Step 400\n",
      "Training loss  0.682 in Step 500\n",
      "Training loss  0.671 in Step 600\n",
      "Training loss  0.706 in Step 700\n",
      "Training loss  0.704 in Step 800\n",
      "Training loss  0.724 in Step 900\n",
      "Training loss  0.703 in Step 1000\n",
      "Training loss  0.707 in Step 1100\n",
      "Training loss  0.718 in Step 1200\n",
      "Training loss  0.701 in Step 1300\n",
      "Training loss  0.718 in Step 1400\n",
      "Training loss  0.699 in Step 1500\n",
      "Training loss  0.691 in Step 1600\n",
      "Training loss  0.705 in Step 1700\n",
      "※※※Training loss  0.698※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.676 in Step 0\n",
      "Valid loss  0.689 in Step 100\n",
      "Valid loss  0.689 in Step 200\n",
      "Valid loss  0.715 in Step 300\n",
      "Valid loss  0.715 in Step 400\n",
      "※※※Valid loss  0.695※※※\n",
      "Epoch 61\n",
      "Training loss  0.689 in Step 0\n",
      "Training loss  0.720 in Step 100\n",
      "Training loss  0.695 in Step 200\n",
      "Training loss  0.677 in Step 300\n",
      "Training loss  0.700 in Step 400\n",
      "Training loss  0.708 in Step 500\n",
      "Training loss  0.716 in Step 600\n",
      "Training loss  0.697 in Step 700\n",
      "Training loss  0.693 in Step 800\n",
      "Training loss  0.718 in Step 900\n",
      "Training loss  0.672 in Step 1000\n",
      "Training loss  0.690 in Step 1100\n",
      "Training loss  0.723 in Step 1200\n",
      "Training loss  0.698 in Step 1300\n",
      "Training loss  0.706 in Step 1400\n",
      "Training loss  0.693 in Step 1500\n",
      "Training loss  0.705 in Step 1600\n",
      "Training loss  0.703 in Step 1700\n",
      "※※※Training loss  0.700※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.682 in Step 0\n",
      "Valid loss  0.694 in Step 100\n",
      "Valid loss  0.688 in Step 200\n",
      "Valid loss  0.712 in Step 300\n",
      "Valid loss  0.718 in Step 400\n",
      "※※※Valid loss  0.697※※※\n",
      "Epoch 62\n",
      "Training loss  0.708 in Step 0\n",
      "Training loss  0.688 in Step 100\n",
      "Training loss  0.696 in Step 200\n",
      "Training loss  0.688 in Step 300\n",
      "Training loss  0.700 in Step 400\n",
      "Training loss  0.698 in Step 500\n",
      "Training loss  0.698 in Step 600\n",
      "Training loss  0.695 in Step 700\n",
      "Training loss  0.686 in Step 800\n",
      "Training loss  0.702 in Step 900\n",
      "Training loss  0.718 in Step 1000\n",
      "Training loss  0.684 in Step 1100\n",
      "Training loss  0.732 in Step 1200\n",
      "Training loss  0.689 in Step 1300\n",
      "Training loss  0.690 in Step 1400\n",
      "Training loss  0.701 in Step 1500\n",
      "Training loss  0.696 in Step 1600\n",
      "Training loss  0.715 in Step 1700\n",
      "※※※Training loss  0.697※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.679 in Step 0\n",
      "Valid loss  0.693 in Step 100\n",
      "Valid loss  0.691 in Step 200\n",
      "Valid loss  0.713 in Step 300\n",
      "Valid loss  0.718 in Step 400\n",
      "※※※Valid loss  0.699※※※\n",
      "Epoch 63\n",
      "Training loss  0.691 in Step 0\n",
      "Training loss  0.683 in Step 100\n",
      "Training loss  0.697 in Step 200\n",
      "Training loss  0.697 in Step 300\n",
      "Training loss  0.680 in Step 400\n",
      "Training loss  0.710 in Step 500\n",
      "Training loss  0.715 in Step 600\n",
      "Training loss  0.684 in Step 700\n",
      "Training loss  0.708 in Step 800\n",
      "Training loss  0.696 in Step 900\n",
      "Training loss  0.696 in Step 1000\n",
      "Training loss  0.682 in Step 1100\n",
      "Training loss  0.679 in Step 1200\n",
      "Training loss  0.698 in Step 1300\n",
      "Training loss  0.712 in Step 1400\n",
      "Training loss  0.696 in Step 1500\n",
      "Training loss  0.690 in Step 1600\n",
      "Training loss  0.718 in Step 1700\n",
      "※※※Training loss  0.696※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.675 in Step 0\n",
      "Valid loss  0.692 in Step 100\n",
      "Valid loss  0.689 in Step 200\n",
      "Valid loss  0.711 in Step 300\n",
      "Valid loss  0.717 in Step 400\n",
      "※※※Valid loss  0.696※※※\n",
      "Epoch 64\n",
      "Training loss  0.729 in Step 0\n",
      "Training loss  0.684 in Step 100\n",
      "Training loss  0.676 in Step 200\n",
      "Training loss  0.694 in Step 300\n",
      "Training loss  0.689 in Step 400\n",
      "Training loss  0.693 in Step 500\n",
      "Training loss  0.713 in Step 600\n",
      "Training loss  0.691 in Step 700\n",
      "Training loss  0.695 in Step 800\n",
      "Training loss  0.700 in Step 900\n",
      "Training loss  0.726 in Step 1000\n",
      "Training loss  0.692 in Step 1100\n",
      "Training loss  0.716 in Step 1200\n",
      "Training loss  0.689 in Step 1300\n",
      "Training loss  0.694 in Step 1400\n",
      "Training loss  0.704 in Step 1500\n",
      "Training loss  0.676 in Step 1600\n",
      "Training loss  0.684 in Step 1700\n",
      "※※※Training loss  0.696※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.675 in Step 0\n",
      "Valid loss  0.691 in Step 100\n",
      "Valid loss  0.684 in Step 200\n",
      "Valid loss  0.706 in Step 300\n",
      "Valid loss  0.714 in Step 400\n",
      "※※※Valid loss  0.694※※※\n",
      "Epoch 65\n",
      "Training loss  0.669 in Step 0\n",
      "Training loss  0.686 in Step 100\n",
      "Training loss  0.735 in Step 200\n",
      "Training loss  0.686 in Step 300\n",
      "Training loss  0.695 in Step 400\n",
      "Training loss  0.698 in Step 500\n",
      "Training loss  0.717 in Step 600\n",
      "Training loss  0.694 in Step 700\n",
      "Training loss  0.689 in Step 800\n",
      "Training loss  0.675 in Step 900\n",
      "Training loss  0.691 in Step 1000\n",
      "Training loss  0.689 in Step 1100\n",
      "Training loss  0.692 in Step 1200\n",
      "Training loss  0.694 in Step 1300\n",
      "Training loss  0.665 in Step 1400\n",
      "Training loss  0.721 in Step 1500\n",
      "Training loss  0.694 in Step 1600\n",
      "Training loss  0.719 in Step 1700\n",
      "※※※Training loss  0.696※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.676 in Step 0\n",
      "Valid loss  0.690 in Step 100\n",
      "Valid loss  0.690 in Step 200\n",
      "Valid loss  0.714 in Step 300\n",
      "Valid loss  0.715 in Step 400\n",
      "※※※Valid loss  0.696※※※\n",
      "Epoch 66\n",
      "Training loss  0.700 in Step 0\n",
      "Training loss  0.703 in Step 100\n",
      "Training loss  0.715 in Step 200\n",
      "Training loss  0.706 in Step 300\n",
      "Training loss  0.692 in Step 400\n",
      "Training loss  0.688 in Step 500\n",
      "Training loss  0.691 in Step 600\n",
      "Training loss  0.672 in Step 700\n",
      "Training loss  0.680 in Step 800\n",
      "Training loss  0.681 in Step 900\n",
      "Training loss  0.691 in Step 1000\n",
      "Training loss  0.707 in Step 1100\n",
      "Training loss  0.702 in Step 1200\n",
      "Training loss  0.686 in Step 1300\n",
      "Training loss  0.698 in Step 1400\n",
      "Training loss  0.703 in Step 1500\n",
      "Training loss  0.684 in Step 1600\n",
      "Training loss  0.691 in Step 1700\n",
      "※※※Training loss  0.695※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.676 in Step 0\n",
      "Valid loss  0.690 in Step 100\n",
      "Valid loss  0.687 in Step 200\n",
      "Valid loss  0.709 in Step 300\n",
      "Valid loss  0.715 in Step 400\n",
      "※※※Valid loss  0.694※※※\n",
      "Epoch 67\n",
      "Training loss  0.688 in Step 0\n",
      "Training loss  0.708 in Step 100\n",
      "Training loss  0.662 in Step 200\n",
      "Training loss  0.692 in Step 300\n",
      "Training loss  0.676 in Step 400\n",
      "Training loss  0.685 in Step 500\n",
      "Training loss  0.702 in Step 600\n",
      "Training loss  0.655 in Step 700\n",
      "Training loss  0.705 in Step 800\n",
      "Training loss  0.687 in Step 900\n",
      "Training loss  0.706 in Step 1000\n",
      "Training loss  0.690 in Step 1100\n",
      "Training loss  0.711 in Step 1200\n",
      "Training loss  0.688 in Step 1300\n",
      "Training loss  0.689 in Step 1400\n",
      "Training loss  0.693 in Step 1500\n",
      "Training loss  0.683 in Step 1600\n",
      "Training loss  0.685 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.676 in Step 0\n",
      "Valid loss  0.693 in Step 100\n",
      "Valid loss  0.690 in Step 200\n",
      "Valid loss  0.710 in Step 300\n",
      "Valid loss  0.716 in Step 400\n",
      "※※※Valid loss  0.696※※※\n",
      "Epoch 68\n",
      "Training loss  0.698 in Step 0\n",
      "Training loss  0.718 in Step 100\n",
      "Training loss  0.689 in Step 200\n",
      "Training loss  0.681 in Step 300\n",
      "Training loss  0.691 in Step 400\n",
      "Training loss  0.693 in Step 500\n",
      "Training loss  0.718 in Step 600\n",
      "Training loss  0.697 in Step 700\n",
      "Training loss  0.673 in Step 800\n",
      "Training loss  0.694 in Step 900\n",
      "Training loss  0.680 in Step 1000\n",
      "Training loss  0.694 in Step 1100\n",
      "Training loss  0.698 in Step 1200\n",
      "Training loss  0.694 in Step 1300\n",
      "Training loss  0.707 in Step 1400\n",
      "Training loss  0.695 in Step 1500\n",
      "Training loss  0.706 in Step 1600\n",
      "Training loss  0.691 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.674 in Step 0\n",
      "Valid loss  0.688 in Step 100\n",
      "Valid loss  0.685 in Step 200\n",
      "Valid loss  0.704 in Step 300\n",
      "Valid loss  0.712 in Step 400\n",
      "※※※Valid loss  0.693※※※\n",
      "Epoch 69\n",
      "Training loss  0.707 in Step 0\n",
      "Training loss  0.694 in Step 100\n",
      "Training loss  0.689 in Step 200\n",
      "Training loss  0.701 in Step 300\n",
      "Training loss  0.698 in Step 400\n",
      "Training loss  0.686 in Step 500\n",
      "Training loss  0.719 in Step 600\n",
      "Training loss  0.712 in Step 700\n",
      "Training loss  0.700 in Step 800\n",
      "Training loss  0.704 in Step 900\n",
      "Training loss  0.697 in Step 1000\n",
      "Training loss  0.685 in Step 1100\n",
      "Training loss  0.686 in Step 1200\n",
      "Training loss  0.703 in Step 1300\n",
      "Training loss  0.709 in Step 1400\n",
      "Training loss  0.711 in Step 1500\n",
      "Training loss  0.707 in Step 1600\n",
      "Training loss  0.683 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.675 in Step 0\n",
      "Valid loss  0.685 in Step 100\n",
      "Valid loss  0.685 in Step 200\n",
      "Valid loss  0.712 in Step 300\n",
      "Valid loss  0.713 in Step 400\n",
      "※※※Valid loss  0.692※※※\n",
      "Epoch 70\n",
      "Training loss  0.707 in Step 0\n",
      "Training loss  0.689 in Step 100\n",
      "Training loss  0.684 in Step 200\n",
      "Training loss  0.686 in Step 300\n",
      "Training loss  0.697 in Step 400\n",
      "Training loss  0.682 in Step 500\n",
      "Training loss  0.688 in Step 600\n",
      "Training loss  0.674 in Step 700\n",
      "Training loss  0.706 in Step 800\n",
      "Training loss  0.693 in Step 900\n",
      "Training loss  0.696 in Step 1000\n",
      "Training loss  0.697 in Step 1100\n",
      "Training loss  0.707 in Step 1200\n",
      "Training loss  0.702 in Step 1300\n",
      "Training loss  0.701 in Step 1400\n",
      "Training loss  0.700 in Step 1500\n",
      "Training loss  0.711 in Step 1600\n",
      "Training loss  0.690 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.677 in Step 0\n",
      "Valid loss  0.694 in Step 100\n",
      "Valid loss  0.688 in Step 200\n",
      "Valid loss  0.712 in Step 300\n",
      "Valid loss  0.715 in Step 400\n",
      "※※※Valid loss  0.697※※※\n",
      "Epoch 71\n",
      "Training loss  0.708 in Step 0\n",
      "Training loss  0.715 in Step 100\n",
      "Training loss  0.694 in Step 200\n",
      "Training loss  0.685 in Step 300\n",
      "Training loss  0.701 in Step 400\n",
      "Training loss  0.683 in Step 500\n",
      "Training loss  0.696 in Step 600\n",
      "Training loss  0.694 in Step 700\n",
      "Training loss  0.700 in Step 800\n",
      "Training loss  0.684 in Step 900\n",
      "Training loss  0.694 in Step 1000\n",
      "Training loss  0.696 in Step 1100\n",
      "Training loss  0.682 in Step 1200\n",
      "Training loss  0.679 in Step 1300\n",
      "Training loss  0.680 in Step 1400\n",
      "Training loss  0.692 in Step 1500\n",
      "Training loss  0.693 in Step 1600\n",
      "Training loss  0.707 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.674 in Step 0\n",
      "Valid loss  0.686 in Step 100\n",
      "Valid loss  0.685 in Step 200\n",
      "Valid loss  0.713 in Step 300\n",
      "Valid loss  0.714 in Step 400\n",
      "※※※Valid loss  0.692※※※\n",
      "Epoch 72\n",
      "Training loss  0.700 in Step 0\n",
      "Training loss  0.707 in Step 100\n",
      "Training loss  0.689 in Step 200\n",
      "Training loss  0.686 in Step 300\n",
      "Training loss  0.682 in Step 400\n",
      "Training loss  0.678 in Step 500\n",
      "Training loss  0.710 in Step 600\n",
      "Training loss  0.699 in Step 700\n",
      "Training loss  0.693 in Step 800\n",
      "Training loss  0.677 in Step 900\n",
      "Training loss  0.681 in Step 1000\n",
      "Training loss  0.704 in Step 1100\n",
      "Training loss  0.693 in Step 1200\n",
      "Training loss  0.702 in Step 1300\n",
      "Training loss  0.705 in Step 1400\n",
      "Training loss  0.697 in Step 1500\n",
      "Training loss  0.696 in Step 1600\n",
      "Training loss  0.722 in Step 1700\n",
      "※※※Training loss  0.694※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.679 in Step 0\n",
      "Valid loss  0.689 in Step 100\n",
      "Valid loss  0.688 in Step 200\n",
      "Valid loss  0.702 in Step 300\n",
      "Valid loss  0.714 in Step 400\n",
      "※※※Valid loss  0.694※※※\n",
      "Epoch 73\n",
      "Training loss  0.680 in Step 0\n",
      "Training loss  0.691 in Step 100\n",
      "Training loss  0.684 in Step 200\n",
      "Training loss  0.690 in Step 300\n",
      "Training loss  0.692 in Step 400\n",
      "Training loss  0.692 in Step 500\n",
      "Training loss  0.677 in Step 600\n",
      "Training loss  0.717 in Step 700\n",
      "Training loss  0.702 in Step 800\n",
      "Training loss  0.723 in Step 900\n",
      "Training loss  0.693 in Step 1000\n",
      "Training loss  0.695 in Step 1100\n",
      "Training loss  0.681 in Step 1200\n",
      "Training loss  0.706 in Step 1300\n",
      "Training loss  0.688 in Step 1400\n",
      "Training loss  0.711 in Step 1500\n",
      "Training loss  0.674 in Step 1600\n",
      "Training loss  0.717 in Step 1700\n",
      "※※※Training loss  0.692※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.675 in Step 0\n",
      "Valid loss  0.686 in Step 100\n",
      "Valid loss  0.686 in Step 200\n",
      "Valid loss  0.714 in Step 300\n",
      "Valid loss  0.714 in Step 400\n",
      "※※※Valid loss  0.692※※※\n",
      "Epoch 74\n",
      "Training loss  0.720 in Step 0\n",
      "Training loss  0.683 in Step 100\n",
      "Training loss  0.692 in Step 200\n",
      "Training loss  0.703 in Step 300\n",
      "Training loss  0.717 in Step 400\n",
      "Training loss  0.724 in Step 500\n",
      "Training loss  0.686 in Step 600\n",
      "Training loss  0.694 in Step 700\n",
      "Training loss  0.691 in Step 800\n",
      "Training loss  0.694 in Step 900\n",
      "Training loss  0.688 in Step 1000\n",
      "Training loss  0.689 in Step 1100\n",
      "Training loss  0.664 in Step 1200\n",
      "Training loss  0.697 in Step 1300\n",
      "Training loss  0.687 in Step 1400\n",
      "Training loss  0.675 in Step 1500\n",
      "Training loss  0.684 in Step 1600\n",
      "Training loss  0.703 in Step 1700\n",
      "※※※Training loss  0.693※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.673 in Step 0\n",
      "Valid loss  0.682 in Step 100\n",
      "Valid loss  0.682 in Step 200\n",
      "Valid loss  0.705 in Step 300\n",
      "Valid loss  0.713 in Step 400\n",
      "※※※Valid loss  0.690※※※\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "train_losses.save()\n",
    "\n",
    "valid_losses.save()\n",
    "\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe036c85290>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This model should converge to loss around 0.78. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
