{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English\n",
    "Version 1: In this version we make the model \"simple\": make the encoder RNN into normal RNN first and try to see the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from loss import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PhxLearner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范用语；规定两种方式：全加载；按rec加载（舍弃了按chunk加载，处理起来更简单）\n",
    "# RandomPhoneDataset; AnnoPhoneDataset; AnnoSeqDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset that loads cutted wave files from disk and returns input-output pairs for\n",
    "    training autoencoder. \n",
    "    \n",
    "    Version 3: wav -> mel\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, load_dir, load_control_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the class by reading a CSV file and merging the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        The function reads the CSV file from the provided control path, extracts the \"rec\" and \"idx\" columns,\n",
    "        and concatenates the values from these columns using an underscore. It then appends the \".wav\" extension\n",
    "        to each of the merged strings and converts the merged pandas Series to a list, which is assigned to\n",
    "        the 'dataset' attribute of the class.\n",
    "\n",
    "        Args:\n",
    "        load_dir (str): The directory containing the files to load.\n",
    "        load_control_path (str): The path to the CSV file containing the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        Attributes:\n",
    "        dataset (list): A list of merged strings from the \"rec\" and \"idx\" columns, with the \".wav\" extension.\n",
    "        \"\"\"\n",
    "        control_file = pd.read_csv(load_control_path)\n",
    "        control_file = control_file[control_file['n_frames'] > 400]\n",
    "        control_file = control_file[control_file['duration'] <= 2.0]\n",
    "        \n",
    "        # Extract the \"rec\" and \"idx\" columns\n",
    "        rec_col = control_file['rec'].astype(str)\n",
    "        idx_col = control_file['idx'].astype(str).str.zfill(8)\n",
    "        \n",
    "        # Merge the two columns by concatenating the strings with '_' and append extension name\n",
    "        merged_col = rec_col + '_' + idx_col + \".wav\"\n",
    "        \n",
    "        self.dataset = merged_col.tolist()\n",
    "        self.load_dir = load_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: The number of input-output pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input_data, output_data) for the given index.\n",
    "\n",
    "        The function first checks if the provided index is a tensor, and if so, converts it to a list.\n",
    "        It then constructs the file path for the .wav file using the dataset attribute and the provided index.\n",
    "        The .wav file is loaded using torchaudio, and its data is normalized. If a transform is provided,\n",
    "        the data is transformed using the specified transform. Finally, the input_data and output_data are\n",
    "        set to the same data (creating a tuple), and the tuple is returned.\n",
    "\n",
    "        Args:\n",
    "        idx (int or torch.Tensor): The index of the desired data.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing input_data and output_data, both of which are the audio data\n",
    "               from the .wav file at the specified index.\n",
    "\n",
    "        Note: \n",
    "        This function assumes that the class has the following attributes:\n",
    "        - self.load_dir (str): The directory containing the .wav files.\n",
    "        - self.dataset (list): A list of .wav file names.\n",
    "        - self.transform (callable, optional): An optional transform to apply to the audio data.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        wav_name = os.path.join(self.load_dir,\n",
    "                                self.dataset[idx])\n",
    "        \n",
    "        data, sample_rate = torchaudio.load(wav_name, normalize=True)\n",
    "        if self.transform:\n",
    "            data = self.transform(data, sr=sample_rate)\n",
    "        \n",
    "        # # Prepare for possible in-out discrepencies in the future\n",
    "        # input_data = data\n",
    "        # output_data = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "def collate_fn(xx):\n",
    "    # only working for one data at the moment\n",
    "    batch_first = True\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=batch_first, padding_value=0)\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "\n",
    "class MyTransform(nn.Module): \n",
    "    def __init__(self, sample_rate, n_fft): \n",
    "        super().__init__()\n",
    "        # self.transform = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, n_mels=64)\n",
    "        # self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        # self.transform = torchaudio.transforms.MFCC(n_mfcc=13)\n",
    "    \n",
    "    def forward(self, waveform, sr=16000): \n",
    "        # extract mfcc\n",
    "        feature = torchaudio.compliance.kaldi.mfcc(waveform, sample_frequency=sr)\n",
    "\n",
    "        # add deltas\n",
    "        d1 = torchaudio.functional.compute_deltas(feature)\n",
    "        d2 = torchaudio.functional.compute_deltas(d1)\n",
    "        feature = torch.cat([feature, d1, d2], dim=-1)\n",
    "\n",
    "        # Apply normalization (CMVN)\n",
    "        eps = 1e-9\n",
    "        mean = feature.mean(0, keepdim=True)\n",
    "        std = feature.std(0, keepdim=True, unbiased=False)\n",
    "        # print(feature.shape)\n",
    "        # print(mean, std)\n",
    "        feature = (feature - mean) / (std + eps)\n",
    "\n",
    "        # mel_spec = self.transform(waveform)\n",
    "        # # mel_spec = self.to_db(mel_spec)\n",
    "        # mel_spec = mel_spec.squeeze()\n",
    "        # mel_spec = mel_spec.permute(1, 0) # (F, L) -> (L, F)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_DIM = 39\n",
    "OUTPUT_DIM = 13\n",
    "\n",
    "INTER_DIM_0 = 16\n",
    "INTER_DIM_1 = 8\n",
    "INTER_DIM_2 = 3\n",
    "# INTER_DIM_3 = 3\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 16\n",
    "# LOADER_WORKER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = PhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhxLearner(\n",
       "  (encoder): SimpleEncoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=39, out_features=16, bias=True)\n",
       "    )\n",
       "    (rnn): LSTM(16, 8, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=8, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): SimpleDecoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=13, out_features=16, bias=True)\n",
       "    )\n",
       "    (rnn): LSTM(16, 8, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=8, out_features=3, bias=True)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=13, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "ts = str(get_timestamp())\n",
    "# ts = \"0623152604\"\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "# save_train1hist_name = \"train_hist_recon{}.hst\".format(ts)\n",
    "# save_train2hist_name = \"train_hist_reg{}.hst\".format(ts)\n",
    "\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)\n",
    "# save_val1hist_name = \"val_hist_recon{}.hst\".format(ts)\n",
    "# save_val2hist_name = \"val_hist_reg{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "# train_recon_losses = LossRecorder(model_save_dir + save_train1hist_name)\n",
    "# train_reg_losses = LossRecorder(model_save_dir + save_train2hist_name)\n",
    "\n",
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "# valid_recon_losses = LossRecorder(model_save_dir + save_val1hist_name)\n",
    "# valid_reg_losses = LossRecorder(model_save_dir + save_val2hist_name)\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "READ = False\n",
    "# READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    # model_name = last_model_namec\n",
    "    model_name = \"PT_0623152604_29_full.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model = PhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=1)\n",
    "    \n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = PhoneDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "# this is to reduce the size of the dataset when the training power is not sufficient\n",
    "small_len = int(0.1 * len(ds))\n",
    "other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "valid_len = len(ds) - train_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BASE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, attn_weight = model(x, x_lens, x_mask)\n",
    "\n",
    "            loss = model_loss.get_loss(recon_x, y, x_mask)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss  1.235 in Step 0\n",
      "Training loss  1.230 in Step 10\n",
      "Training loss  1.239 in Step 20\n",
      "Training loss  1.235 in Step 30\n",
      "Training loss  1.234 in Step 40\n",
      "Training loss  1.234 in Step 50\n",
      "Training loss  1.228 in Step 60\n",
      "Training loss  1.238 in Step 70\n",
      "Training loss  1.231 in Step 80\n",
      "Training loss  1.237 in Step 90\n",
      "Training loss  1.230 in Step 100\n",
      "Training loss  1.225 in Step 110\n",
      "Training loss  1.230 in Step 120\n",
      "Training loss  1.239 in Step 130\n",
      "Training loss  1.235 in Step 140\n",
      "Training loss  1.235 in Step 150\n",
      "Training loss  1.225 in Step 160\n",
      "Training loss  1.227 in Step 170\n",
      "※※※Training loss  1.231※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.113 in Step 0\n",
      "※※※Valid loss  1.113※※※\n",
      "Epoch 1\n",
      "Training loss  1.223 in Step 0\n",
      "Training loss  1.226 in Step 10\n",
      "Training loss  1.234 in Step 20\n",
      "Training loss  1.228 in Step 30\n",
      "Training loss  1.227 in Step 40\n",
      "Training loss  1.224 in Step 50\n",
      "Training loss  1.222 in Step 60\n",
      "Training loss  1.230 in Step 70\n",
      "Training loss  1.228 in Step 80\n",
      "Training loss  1.223 in Step 90\n",
      "Training loss  1.227 in Step 100\n",
      "Training loss  1.223 in Step 110\n",
      "Training loss  1.220 in Step 120\n",
      "Training loss  1.230 in Step 130\n",
      "Training loss  1.219 in Step 140\n",
      "Training loss  1.225 in Step 150\n",
      "Training loss  1.227 in Step 160\n",
      "Training loss  1.218 in Step 170\n",
      "※※※Training loss  1.225※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.110 in Step 0\n",
      "※※※Valid loss  1.109※※※\n",
      "Epoch 2\n",
      "Training loss  1.213 in Step 0\n",
      "Training loss  1.223 in Step 10\n",
      "Training loss  1.225 in Step 20\n",
      "Training loss  1.224 in Step 30\n",
      "Training loss  1.221 in Step 40\n",
      "Training loss  1.221 in Step 50\n",
      "Training loss  1.219 in Step 60\n",
      "Training loss  1.214 in Step 70\n",
      "Training loss  1.220 in Step 80\n",
      "Training loss  1.216 in Step 90\n",
      "Training loss  1.220 in Step 100\n",
      "Training loss  1.224 in Step 110\n",
      "Training loss  1.219 in Step 120\n",
      "Training loss  1.216 in Step 130\n",
      "Training loss  1.219 in Step 140\n",
      "Training loss  1.219 in Step 150\n",
      "Training loss  1.218 in Step 160\n",
      "Training loss  1.208 in Step 170\n",
      "※※※Training loss  1.219※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.107 in Step 0\n",
      "※※※Valid loss  1.106※※※\n",
      "Epoch 3\n",
      "Training loss  1.219 in Step 0\n",
      "Training loss  1.209 in Step 10\n",
      "Training loss  1.215 in Step 20\n",
      "Training loss  1.219 in Step 30\n",
      "Training loss  1.213 in Step 40\n",
      "Training loss  1.216 in Step 50\n",
      "Training loss  1.211 in Step 60\n",
      "Training loss  1.217 in Step 70\n",
      "Training loss  1.210 in Step 80\n",
      "Training loss  1.212 in Step 90\n",
      "Training loss  1.212 in Step 100\n",
      "Training loss  1.216 in Step 110\n",
      "Training loss  1.216 in Step 120\n",
      "Training loss  1.205 in Step 130\n",
      "Training loss  1.208 in Step 140\n",
      "Training loss  1.205 in Step 150\n",
      "Training loss  1.212 in Step 160\n",
      "Training loss  1.213 in Step 170\n",
      "※※※Training loss  1.213※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.104 in Step 0\n",
      "※※※Valid loss  1.103※※※\n",
      "Epoch 4\n",
      "Training loss  1.214 in Step 0\n",
      "Training loss  1.212 in Step 10\n",
      "Training loss  1.209 in Step 20\n",
      "Training loss  1.202 in Step 30\n",
      "Training loss  1.206 in Step 40\n",
      "Training loss  1.209 in Step 50\n",
      "Training loss  1.205 in Step 60\n",
      "Training loss  1.209 in Step 70\n",
      "Training loss  1.205 in Step 80\n",
      "Training loss  1.208 in Step 90\n",
      "Training loss  1.205 in Step 100\n",
      "Training loss  1.207 in Step 110\n",
      "Training loss  1.207 in Step 120\n",
      "Training loss  1.204 in Step 130\n",
      "Training loss  1.200 in Step 140\n",
      "Training loss  1.213 in Step 150\n",
      "Training loss  1.203 in Step 160\n",
      "Training loss  1.203 in Step 170\n",
      "※※※Training loss  1.207※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.101 in Step 0\n",
      "※※※Valid loss  1.100※※※\n",
      "Epoch 5\n",
      "Training loss  1.203 in Step 0\n",
      "Training loss  1.204 in Step 10\n",
      "Training loss  1.198 in Step 20\n",
      "Training loss  1.197 in Step 30\n",
      "Training loss  1.203 in Step 40\n",
      "Training loss  1.203 in Step 50\n",
      "Training loss  1.205 in Step 60\n",
      "Training loss  1.202 in Step 70\n",
      "Training loss  1.194 in Step 80\n",
      "Training loss  1.205 in Step 90\n",
      "Training loss  1.203 in Step 100\n",
      "Training loss  1.196 in Step 110\n",
      "Training loss  1.203 in Step 120\n",
      "Training loss  1.199 in Step 130\n",
      "Training loss  1.196 in Step 140\n",
      "Training loss  1.200 in Step 150\n",
      "Training loss  1.198 in Step 160\n",
      "Training loss  1.196 in Step 170\n",
      "※※※Training loss  1.201※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.098 in Step 0\n",
      "※※※Valid loss  1.097※※※\n",
      "Epoch 6\n",
      "Training loss  1.197 in Step 0\n",
      "Training loss  1.196 in Step 10\n",
      "Training loss  1.192 in Step 20\n",
      "Training loss  1.202 in Step 30\n",
      "Training loss  1.193 in Step 40\n",
      "Training loss  1.197 in Step 50\n",
      "Training loss  1.197 in Step 60\n",
      "Training loss  1.194 in Step 70\n",
      "Training loss  1.199 in Step 80\n",
      "Training loss  1.191 in Step 90\n",
      "Training loss  1.190 in Step 100\n",
      "Training loss  1.194 in Step 110\n",
      "Training loss  1.200 in Step 120\n",
      "Training loss  1.194 in Step 130\n",
      "Training loss  1.192 in Step 140\n",
      "Training loss  1.195 in Step 150\n",
      "Training loss  1.199 in Step 160\n",
      "Training loss  1.192 in Step 170\n",
      "※※※Training loss  1.195※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.095 in Step 0\n",
      "※※※Valid loss  1.095※※※\n",
      "Epoch 7\n",
      "Training loss  1.190 in Step 0\n",
      "Training loss  1.196 in Step 10\n",
      "Training loss  1.194 in Step 20\n",
      "Training loss  1.189 in Step 30\n",
      "Training loss  1.196 in Step 40\n",
      "Training loss  1.192 in Step 50\n",
      "Training loss  1.187 in Step 60\n",
      "Training loss  1.191 in Step 70\n",
      "Training loss  1.192 in Step 80\n",
      "Training loss  1.190 in Step 90\n",
      "Training loss  1.190 in Step 100\n",
      "Training loss  1.189 in Step 110\n",
      "Training loss  1.192 in Step 120\n",
      "Training loss  1.189 in Step 130\n",
      "Training loss  1.185 in Step 140\n",
      "Training loss  1.186 in Step 150\n",
      "Training loss  1.188 in Step 160\n",
      "Training loss  1.190 in Step 170\n",
      "※※※Training loss  1.189※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.092 in Step 0\n",
      "※※※Valid loss  1.092※※※\n",
      "Epoch 8\n",
      "Training loss  1.192 in Step 0\n",
      "Training loss  1.186 in Step 10\n",
      "Training loss  1.188 in Step 20\n",
      "Training loss  1.194 in Step 30\n",
      "Training loss  1.186 in Step 40\n",
      "Training loss  1.187 in Step 50\n",
      "Training loss  1.187 in Step 60\n",
      "Training loss  1.184 in Step 70\n",
      "Training loss  1.185 in Step 80\n",
      "Training loss  1.180 in Step 90\n",
      "Training loss  1.186 in Step 100\n",
      "Training loss  1.178 in Step 110\n",
      "Training loss  1.186 in Step 120\n",
      "Training loss  1.179 in Step 130\n",
      "Training loss  1.172 in Step 140\n",
      "Training loss  1.183 in Step 150\n",
      "Training loss  1.180 in Step 160\n",
      "Training loss  1.187 in Step 170\n",
      "※※※Training loss  1.184※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.089 in Step 0\n",
      "※※※Valid loss  1.089※※※\n",
      "Epoch 9\n",
      "Training loss  1.179 in Step 0\n",
      "Training loss  1.186 in Step 10\n",
      "Training loss  1.181 in Step 20\n",
      "Training loss  1.178 in Step 30\n",
      "Training loss  1.184 in Step 40\n",
      "Training loss  1.179 in Step 50\n",
      "Training loss  1.178 in Step 60\n",
      "Training loss  1.178 in Step 70\n",
      "Training loss  1.178 in Step 80\n",
      "Training loss  1.178 in Step 90\n",
      "Training loss  1.180 in Step 100\n",
      "Training loss  1.180 in Step 110\n",
      "Training loss  1.178 in Step 120\n",
      "Training loss  1.180 in Step 130\n",
      "Training loss  1.175 in Step 140\n",
      "Training loss  1.180 in Step 150\n",
      "Training loss  1.172 in Step 160\n",
      "Training loss  1.173 in Step 170\n",
      "※※※Training loss  1.178※※※\n",
      "Training timepoint saved\n",
      "Valid loss  1.087 in Step 0\n",
      "※※※Valid loss  1.086※※※\n",
      "Epoch 10\n",
      "Training loss  1.180 in Step 0\n",
      "Training loss  1.180 in Step 10\n",
      "Training loss  1.171 in Step 20\n",
      "Training loss  1.177 in Step 30\n",
      "Training loss  1.177 in Step 40\n",
      "Training loss  1.175 in Step 50\n",
      "Training loss  1.175 in Step 60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[0;32m----> 2\u001b[0m     train()\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m recon_x, attn_weight \u001b[39m=\u001b[39m model(x, x_lens, x_mask)\n\u001b[1;32m     19\u001b[0m loss \u001b[39m=\u001b[39m model_loss\u001b[39m.\u001b[39mget_loss(recon_x, y, x_mask)\n\u001b[1;32m     21\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wavln/scripts/model.py:215\u001b[0m, in \u001b[0;36mPhxLearner.forward\u001b[0;34m(self, inputs, input_lens, in_mask)\u001b[0m\n\u001b[1;32m    212\u001b[0m dec_hid, init_in \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39minits(batch_size\u001b[39m=\u001b[39mbatch_size, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    214\u001b[0m enc_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(inputs, input_lens, in_mask)\n\u001b[0;32m--> 215\u001b[0m dec_out, attn_w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(enc_out, in_mask, init_in, dec_hid)\n\u001b[1;32m    217\u001b[0m \u001b[39mreturn\u001b[39;00m dec_out, attn_w\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wavln/scripts/model.py:180\u001b[0m, in \u001b[0;36mSimpleDecoder.forward\u001b[0;34m(self, hid_r, in_mask, init_in, hidden)\u001b[0m\n\u001b[1;32m    178\u001b[0m attention_weights \u001b[39m=\u001b[39m []\n\u001b[1;32m    179\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length):\n\u001b[0;32m--> 180\u001b[0m     dec_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_1(dec_in_token)\n\u001b[1;32m    181\u001b[0m     dec_x, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(dec_x, hidden)\n\u001b[1;32m    182\u001b[0m     dec_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_2(dec_x)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wavln/scripts/layers.py:146\u001b[0m, in \u001b[0;36mLinearPack.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 146\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(x)\n\u001b[1;32m    147\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    148\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/wavln/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "train_losses.save()\n",
    "\n",
    "valid_losses.save()\n",
    "\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb9fbc9f4d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPWgjpid7PR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
