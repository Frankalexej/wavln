{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e0ce91-a6d9-44dd-b3f8-18f79b0defd8",
   "metadata": {},
   "source": [
    "# Alignment Extraction (English)\n",
    "\n",
    "This Jupyter Notebook is designed to extract annotations from alignment files (in either .phones or .words format) and prepare for sound cutting. Specifically, the notebook will:\n",
    "\n",
    "- Open .phones or .words alignment files\n",
    "- Extract the annotations from these files\n",
    "- Write the entries into a Pandas dataframe\n",
    "- Save the dataframe as an Excel file\n",
    "- Define classes and functions to prepare for sound cutting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e1295-d68d-4144-87ea-73810f268e91",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3929f9c3-70db-4600-b2b3-ac6b6fdc5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a36551-264c-409f-8f1f-7009902daf2a",
   "metadata": {},
   "source": [
    "## Path Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8839ae0-03d6-4682-98d4-4fe21992c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "bsc_path = root_path + \"/src/bsc/\"\n",
    "wav_path = bsc_path + \"wav/\"\n",
    "phones_path = bsc_path + \"phones/\"\n",
    "words_path = bsc_path + \"words/\"\n",
    "\n",
    "phones_extract_path = bsc_path + \"phones_extract/\"\n",
    "words_extract_path = bsc_path + \"words_extract/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21a8b3-5132-4cad-8313-039cc197903b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013fb234-54ed-41e9-86ea-1e2fc73db202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_semicolon(s):\n",
    "    \"\"\"\n",
    "    Removes the trailing semicolon from a given string.\n",
    "    If the string does not end with a semicolon, it is returned unchanged.\n",
    "\n",
    "    Args:\n",
    "        my_string: A string to be processed.\n",
    "\n",
    "    Returns:\n",
    "        The same string with the trailing semicolon removed (if there was one).\n",
    "    \"\"\"\n",
    "    if s.endswith(\";\"):\n",
    "        s = s[:-1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ebe43b-cfe5-4fc1-a3b3-7b229fea19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_starts_with_semicolon(line):\n",
    "    \"\"\"Determines whether a line starts with `;`.\n",
    "\n",
    "    Args:\n",
    "        line (str): A string representing a line of text.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the line starts with `;`, False otherwise.\n",
    "    \"\"\"\n",
    "    return line.strip().startswith(';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de02fc28-3713-490e-8162-595b88f0d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    \"\"\"\n",
    "    Extracts end times and tokens from a file.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing a list of end times and a list of corresponding tokens.\n",
    "    \"\"\"\n",
    "    f = open(path)\n",
    "    lines = f.readlines()\n",
    "    end_times = []\n",
    "    tokens = []\n",
    "    putin = False\n",
    "    for line in lines:\n",
    "        if putin:\n",
    "            if line_starts_with_semicolon(line): \n",
    "                continue\n",
    "            splitted = line.split() \n",
    "            if len(splitted) == 0: \n",
    "                continue\n",
    "            elif len(splitted) < 3: \n",
    "                end_times.append(float(splitted[0]))\n",
    "                tokens.append(\"\")\n",
    "            else: \n",
    "                end_times.append(float(splitted[0]))\n",
    "                tokens.append(remove_semicolon(splitted[2]))\n",
    "                if splitted[2] == \"{E_TRANS}\": \n",
    "                    break   # time to stop\n",
    "                    \n",
    "        if \"#\" in line:\n",
    "            putin = True\n",
    "\n",
    "    f.close()\n",
    "    return end_times, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb7af40-934b-4b53-b317-5e1b4d91b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(end_times, tokens):\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe from lists of token end times and tokens.\n",
    "    Calculates start times and durations for each token and adds these to the dataframe.\n",
    "\n",
    "    Args:\n",
    "        end_times (list): A list of token end times in seconds.\n",
    "        tokens (list): A list of tokens.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe with columns for start time, end time, token, and duration.\n",
    "    \"\"\"\n",
    "    # Calculate start times\n",
    "    start_times = [0.0] + end_times[:-1]\n",
    "    \n",
    "    # Calculate durations\n",
    "    durations = [e - s for s, e in zip(start_times, end_times)]\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'start_time': start_times,\n",
    "        'end_time': end_times,\n",
    "        'token': tokens,\n",
    "        'duration': durations\n",
    "    })\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78af694-e7c3-4618-bd22-1c0080b24d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_create_dataframe(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Extracts token information from all .phones or .words files in a given input path,\n",
    "    creates a pandas dataframe for each file, and outputs each dataframe to the corresponding\n",
    "    filename in a given output path.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): The path to the directory containing the .phones or .words files.\n",
    "        output_path (str): The path to the directory where the resulting dataframes will be saved.\n",
    "    \"\"\"\n",
    "    # Loop through all files in input path\n",
    "    for file_name in os.listdir(input_path):\n",
    "        if file_name.endswith('.phones') or file_name.endswith('.words'):\n",
    "            # Extract token information\n",
    "            end_times, tokens = extract(os.path.join(input_path, file_name))\n",
    "\n",
    "            # Create dataframe\n",
    "            df = create_dataframe(end_times, tokens)\n",
    "\n",
    "            # Output dataframe to file in output path\n",
    "            output_file_name = os.path.splitext(file_name)[0] + '.csv'\n",
    "            df.to_csv(os.path.join(output_path, output_file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7977510-6960-4c44-b45f-c15d5ac57de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_and_create_dataframe(phones_path, phones_extract_path)\n",
    "extract_and_create_dataframe(words_path, words_extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378cca5-1135-4e1e-8a77-e7f452c33a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
