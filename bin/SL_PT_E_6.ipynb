{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Phone Training - English\n",
    "Version 2:  This version has a core structure using HM-RNN. Unlike traditional approaches, our model can automatically detect boundaries. It is trainable and updates the upper layer only upon detecting boundaries. This makes our model suitable for detecting boundaries and capturing the representations of sub-segments based on these detected boundaries. In essence, our model performs boundary detection and representation learning simultaneously.\n",
    "\n",
    "Version 3: this version completed the coding of the core model structure as well as the dataloading, preprocessing, padding and loss calculation processes. At present we only try mel->model -> mel structure, since wav <> wav would introduce extra complexion. In addition, our model will process padded multi-batch tensors as normal but count for the paddings (ignore paddings) during calculation. \n",
    "\n",
    "Version 4: this version is testing whether our hmrnn is not working. It imports a modified version of model: model_test\n",
    "\n",
    "Version 5: this version is testing phase two, mainly working on preprocessing modifications. \n",
    "\n",
    "Version 6: this version deletes lin2, as this will destroy the predicted segmental boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import pickle\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from recorder import *\n",
    "from padding import generate_mask_from_lengths_mat, mask_it, masked_loss\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import PhonLearn_Net\n",
    "from model import PhonLearn_Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "# random_data:phone_seg_random_path\n",
    "# anno_data: phone_seg_anno_path\n",
    "\n",
    "# random_log_path = phone_seg_random_log_path + \"log.csv\"\n",
    "random_log_path = word_seg_anno_log_path\n",
    "random_path = word_seg_anno_path\n",
    "anno_log_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范用语；规定两种方式：全加载；按rec加载（舍弃了按chunk加载，处理起来更简单）\n",
    "# RandomPhoneDataset; AnnoPhoneDataset; AnnoSeqDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset that loads cutted wave files from disk and returns input-output pairs for\n",
    "    training autoencoder. \n",
    "    \n",
    "    Version 3: wav -> mel\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, load_dir, load_control_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the class by reading a CSV file and merging the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        The function reads the CSV file from the provided control path, extracts the \"rec\" and \"idx\" columns,\n",
    "        and concatenates the values from these columns using an underscore. It then appends the \".wav\" extension\n",
    "        to each of the merged strings and converts the merged pandas Series to a list, which is assigned to\n",
    "        the 'dataset' attribute of the class.\n",
    "\n",
    "        Args:\n",
    "        load_dir (str): The directory containing the files to load.\n",
    "        load_control_path (str): The path to the CSV file containing the \"rec\" and \"idx\" columns.\n",
    "\n",
    "        Attributes:\n",
    "        dataset (list): A list of merged strings from the \"rec\" and \"idx\" columns, with the \".wav\" extension.\n",
    "        \"\"\"\n",
    "        control_file = pd.read_csv(load_control_path)\n",
    "        control_file = control_file[control_file['n_frames'] > 400]\n",
    "        control_file = control_file[control_file['duration'] <= 2.0]\n",
    "        \n",
    "        # Extract the \"rec\" and \"idx\" columns\n",
    "        rec_col = control_file['rec'].astype(str)\n",
    "        idx_col = control_file['idx'].astype(str).str.zfill(8)\n",
    "        \n",
    "        # Merge the two columns by concatenating the strings with '_' and append extension name\n",
    "        merged_col = rec_col + '_' + idx_col + \".wav\"\n",
    "        \n",
    "        self.dataset = merged_col.tolist()\n",
    "        self.load_dir = load_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: The number of input-output pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input_data, output_data) for the given index.\n",
    "\n",
    "        The function first checks if the provided index is a tensor, and if so, converts it to a list.\n",
    "        It then constructs the file path for the .wav file using the dataset attribute and the provided index.\n",
    "        The .wav file is loaded using torchaudio, and its data is normalized. If a transform is provided,\n",
    "        the data is transformed using the specified transform. Finally, the input_data and output_data are\n",
    "        set to the same data (creating a tuple), and the tuple is returned.\n",
    "\n",
    "        Args:\n",
    "        idx (int or torch.Tensor): The index of the desired data.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing input_data and output_data, both of which are the audio data\n",
    "               from the .wav file at the specified index.\n",
    "\n",
    "        Note: \n",
    "        This function assumes that the class has the following attributes:\n",
    "        - self.load_dir (str): The directory containing the .wav files.\n",
    "        - self.dataset (list): A list of .wav file names.\n",
    "        - self.transform (callable, optional): An optional transform to apply to the audio data.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        wav_name = os.path.join(self.load_dir,\n",
    "                                self.dataset[idx])\n",
    "        \n",
    "        data, sample_rate = torchaudio.load(wav_name, normalize=True)\n",
    "        if self.transform:\n",
    "            data = self.transform(data, sr=sample_rate)\n",
    "        \n",
    "        # # Prepare for possible in-out discrepencies in the future\n",
    "        # input_data = data\n",
    "        # output_data = data\n",
    "        \n",
    "        return data\n",
    "\n",
    "def collate_fn(xx):\n",
    "    # only working for one data at the moment\n",
    "    batch_first = True\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=batch_first, padding_value=0)\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "\n",
    "class MyTransform(nn.Module): \n",
    "    def __init__(self, sample_rate, n_fft): \n",
    "        super().__init__()\n",
    "        # self.transform = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, n_mels=64)\n",
    "        # self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        # self.transform = torchaudio.transforms.MFCC(n_mfcc=13)\n",
    "    \n",
    "    def forward(self, waveform, sr=16000): \n",
    "        # extract mfcc\n",
    "        feature = torchaudio.compliance.kaldi.mfcc(waveform, sample_frequency=sr)\n",
    "\n",
    "        # add deltas\n",
    "        d1 = torchaudio.functional.compute_deltas(feature)\n",
    "        d2 = torchaudio.functional.compute_deltas(d1)\n",
    "        feature = torch.cat([feature, d1, d2], dim=-1)\n",
    "\n",
    "        # Apply normalization (CMVN)\n",
    "        eps = 1e-9\n",
    "        mean = feature.mean(0, keepdim=True)\n",
    "        std = feature.std(0, keepdim=True, unbiased=False)\n",
    "        # print(feature.shape)\n",
    "        # print(mean, std)\n",
    "        feature = (feature - mean) / (std + eps)\n",
    "\n",
    "        # mel_spec = self.transform(waveform)\n",
    "        # # mel_spec = self.to_db(mel_spec)\n",
    "        # mel_spec = mel_spec.squeeze()\n",
    "        # mel_spec = mel_spec.permute(1, 0) # (F, L) -> (L, F)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# INPUT_DIM = 128\n",
    "# OUTPUT_DIM = 128\n",
    "\n",
    "INPUT_DIM = 39\n",
    "OUTPUT_DIM = 13\n",
    "\n",
    "INTER_DIM_0 = 16\n",
    "INTER_DIM_1 = 8\n",
    "INTER_DIM_2 = 3\n",
    "INTER_DIM_3 = 3\n",
    "\n",
    "SIZE_LIST = [INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "\n",
    "LOADER_WORKER = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "# model = TwoRNNAttn(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "#                       in2_size=INTER_DIM_0, hid_size=INTER_DIM_3, out_size=OUTPUT_DIM)\n",
    "model = PhonLearn_Net(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "                      in2_size=INTER_DIM_0, hid_size=SIZE_LIST[1], out_size=OUTPUT_DIM)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZBCTRw3iXys",
    "outputId": "7947acdb-1a95-49a4-8b1d-93f442cf41d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhonLearn_Net(\n",
       "  (encoder): Encoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=39, out_features=16, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (rnn): HM_LSTM(\n",
       "      (cell_1): HM_LSTMCell()\n",
       "      (cell_2): HM_LSTMCell()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lin_1): LinearPack(\n",
       "      (linear): Linear(in_features=13, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (rnn): LSTM(3, 16, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=16, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=16, bias=True)\n",
       "    )\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=13, bias=True)\n",
       "      (relu): Tanh()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ofsEE6OaoyPh"
   },
   "outputs": [],
   "source": [
    "# Just for keeping records of training hists. \n",
    "# ts = str(get_timestamp())\n",
    "ts = \"0623152604\"\n",
    "save_txt_name = \"train_txt_{}.hst\".format(ts)\n",
    "save_trainhist_name = \"train_hist_{}.hst\".format(ts)\n",
    "save_valhist_name = \"val_hist_{}.hst\".format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xUHYarigvT64"
   },
   "outputs": [],
   "source": [
    "valid_losses = LossRecorder(model_save_dir + save_valhist_name)\n",
    "train_losses = LossRecorder(model_save_dir + save_trainhist_name)\n",
    "text_hist = HistRecorder(model_save_dir + save_txt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-T4OYaoXsxe_"
   },
   "outputs": [],
   "source": [
    "# READ = False\n",
    "READ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVvnpUk5sWxb"
   },
   "outputs": [],
   "source": [
    "if READ: \n",
    "    valid_losses.read()\n",
    "    train_losses.read()\n",
    "\n",
    "    # model_name = last_model_namec\n",
    "    model_name = \"PT_0623152604_29_full.pt\"\n",
    "    model_path = os.path.join(model_save_dir, model_name)\n",
    "    state = torch.load(model_path)\n",
    "    model = PhonLearn_Net(1.0, SIZE_LIST, in_size=INPUT_DIM, \n",
    "                      in2_size=INTER_DIM_0, hid_size=SIZE_LIST[1], out_size=OUTPUT_DIM)\n",
    "    model.load_state_dict(state)\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MyTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT)\n",
    "ds = PhoneDataset(random_path, os.path.join(random_log_path, \"log.csv\"), transform=mytrans)\n",
    "# small_len = int(0.1 * len(ds))\n",
    "# other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "# ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "train_len = int(0.8 * len(ds))\n",
    "valid_len = len(ds) - train_len\n",
    "\n",
    "# Randomly split the dataset into train and validation sets\n",
    "train_ds, valid_ds = random_split(ds, [train_len, valid_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "train_num = len(train_loader.dataset)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 120\n",
    "BASE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2n7doAD1uRi",
    "outputId": "e9c5bcb7-72db-4238-e83f-36e4dbe35748"
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in range(BASE, BASE + EPOCHS):\n",
    "        text_hist.print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_num = len(train_loader)    # train_loader\n",
    "        for idx, (x, x_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch = x.size(0)\n",
    "            batch, length, dim = x.shape\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            \n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, _ = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "\n",
    "            # print(y)\n",
    "            # print(recon_x)\n",
    "            # raise Exception\n",
    "\n",
    "            \n",
    "            loss = masked_loss(recon_loss, recon_x, y, x_mask)\n",
    "            # loss = recon_loss(recon_x, x)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            # loss = loss / batch\n",
    "\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                text_hist.print(f\"Training loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        train_losses.append(train_loss / train_num)\n",
    "        text_hist.print(f\"※※※Training loss {train_loss / train_num: .3f}※※※\")\n",
    "\n",
    "        last_model_name = \"PT_{}_{}_full.pt\".format(ts, epoch)\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, last_model_name))\n",
    "        text_hist.print(\"Training timepoint saved\")\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_num = len(valid_loader)\n",
    "        for idx, (x, x_lens) in enumerate(valid_loader):\n",
    "            # batch = x.size(0)\n",
    "            y = x[:, :, :13]    # extract MFCC-only data\n",
    "            x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            recon_x, _ = model(x, x_mask) # _ = hidden, z_1, z_2\n",
    "\n",
    "            loss = masked_loss(recon_loss, recon_x, y, x_mask)\n",
    "            # loss = recon_loss(recon_x, x)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # \\t Recon {recon / batch: .3f} \\t KL {kl / batch: .3f}\n",
    "                text_hist.print(f\"Valid loss {loss: .3f} in Step {idx}\")\n",
    "\n",
    "        valid_losses.append(valid_loss / valid_num)\n",
    "        text_hist.print(f\"※※※Valid loss {valid_loss / valid_num: .3f}※※※\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Training loss  0.915 in Step 0\n",
      "Training loss  0.916 in Step 100\n",
      "Training loss  0.910 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.924 in Step 400\n",
      "Training loss  0.912 in Step 500\n",
      "Training loss  0.921 in Step 600\n",
      "Training loss  0.912 in Step 700\n",
      "Training loss  0.929 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.912 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.909 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.925 in Step 1500\n",
      "Training loss  0.917 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 31\n",
      "Training loss  0.927 in Step 0\n",
      "Training loss  0.924 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.927 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.909 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.901 in Step 1200\n",
      "Training loss  0.911 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.927 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 32\n",
      "Training loss  0.924 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.910 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.925 in Step 600\n",
      "Training loss  0.927 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.921 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.924 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.909 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 33\n",
      "Training loss  0.926 in Step 0\n",
      "Training loss  0.924 in Step 100\n",
      "Training loss  0.927 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.926 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.923 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.922 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.926 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.913 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 34\n",
      "Training loss  0.925 in Step 0\n",
      "Training loss  0.916 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.926 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.909 in Step 900\n",
      "Training loss  0.918 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.909 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 35\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.923 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.926 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.923 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.909 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.921 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.924 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.922 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 36\n",
      "Training loss  0.915 in Step 0\n",
      "Training loss  0.924 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.918 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.913 in Step 600\n",
      "Training loss  0.906 in Step 700\n",
      "Training loss  0.923 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.911 in Step 1300\n",
      "Training loss  0.914 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.923 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 37\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.909 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.911 in Step 500\n",
      "Training loss  0.909 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.909 in Step 1000\n",
      "Training loss  0.922 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.922 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 38\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.910 in Step 200\n",
      "Training loss  0.928 in Step 300\n",
      "Training loss  0.918 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.923 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.917 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 39\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.902 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.925 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.924 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.919 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 40\n",
      "Training loss  0.911 in Step 0\n",
      "Training loss  0.913 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.910 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.907 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.927 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 41\n",
      "Training loss  0.916 in Step 0\n",
      "Training loss  0.910 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.920 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.912 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.924 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.923 in Step 1500\n",
      "Training loss  0.907 in Step 1600\n",
      "Training loss  0.911 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 42\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.930 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.925 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.927 in Step 1200\n",
      "Training loss  0.908 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 43\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.909 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 44\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.909 in Step 100\n",
      "Training loss  0.925 in Step 200\n",
      "Training loss  0.912 in Step 300\n",
      "Training loss  0.914 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.911 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.925 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.923 in Step 1400\n",
      "Training loss  0.905 in Step 1500\n",
      "Training loss  0.913 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 45\n",
      "Training loss  0.907 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.912 in Step 200\n",
      "Training loss  0.928 in Step 300\n",
      "Training loss  0.910 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.910 in Step 600\n",
      "Training loss  0.913 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.909 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.923 in Step 1300\n",
      "Training loss  0.925 in Step 1400\n",
      "Training loss  0.907 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 46\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.930 in Step 500\n",
      "Training loss  0.912 in Step 600\n",
      "Training loss  0.908 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.923 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.920 in Step 1500\n",
      "Training loss  0.913 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 47\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.926 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.922 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.912 in Step 1100\n",
      "Training loss  0.922 in Step 1200\n",
      "Training loss  0.918 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 48\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.910 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.929 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.910 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.925 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.925 in Step 1200\n",
      "Training loss  0.918 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.925 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 49\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.927 in Step 500\n",
      "Training loss  0.907 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.909 in Step 800\n",
      "Training loss  0.923 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.921 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 50\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.926 in Step 400\n",
      "Training loss  0.924 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.912 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.905 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 51\n",
      "Training loss  0.920 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.923 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.904 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.921 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.914 in Step 1400\n",
      "Training loss  0.922 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 52\n",
      "Training loss  0.923 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.932 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.913 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.916 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.929 in Step 1400\n",
      "Training loss  0.925 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 53\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.924 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.921 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.932 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 54\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.910 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.907 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.924 in Step 1000\n",
      "Training loss  0.928 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.923 in Step 1500\n",
      "Training loss  0.923 in Step 1600\n",
      "Training loss  0.907 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 55\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.917 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.913 in Step 700\n",
      "Training loss  0.929 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.923 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.925 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 56\n",
      "Training loss  0.915 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.925 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.924 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.921 in Step 600\n",
      "Training loss  0.913 in Step 700\n",
      "Training loss  0.928 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.909 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 57\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.909 in Step 500\n",
      "Training loss  0.920 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.910 in Step 1100\n",
      "Training loss  0.926 in Step 1200\n",
      "Training loss  0.910 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.911 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 58\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.924 in Step 100\n",
      "Training loss  0.915 in Step 200\n",
      "Training loss  0.919 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.925 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.923 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.930 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.927 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.926 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 59\n",
      "Training loss  0.918 in Step 0\n",
      "Training loss  0.922 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.912 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 60\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.928 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.913 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.909 in Step 1000\n",
      "Training loss  0.912 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 61\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.907 in Step 100\n",
      "Training loss  0.923 in Step 200\n",
      "Training loss  0.923 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.904 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.926 in Step 700\n",
      "Training loss  0.913 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.922 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.923 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.918 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 62\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.909 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.925 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 63\n",
      "Training loss  0.905 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.907 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.914 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.901 in Step 600\n",
      "Training loss  0.925 in Step 700\n",
      "Training loss  0.901 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.910 in Step 1300\n",
      "Training loss  0.905 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.910 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 64\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.927 in Step 200\n",
      "Training loss  0.909 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.919 in Step 600\n",
      "Training loss  0.917 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.930 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 65\n",
      "Training loss  0.928 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.917 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.911 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.924 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.922 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.912 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 66\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.910 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.907 in Step 700\n",
      "Training loss  0.923 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.931 in Step 1600\n",
      "Training loss  0.925 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 67\n",
      "Training loss  0.920 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.915 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.914 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.912 in Step 700\n",
      "Training loss  0.922 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.912 in Step 1100\n",
      "Training loss  0.910 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.926 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 68\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.922 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.902 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.924 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.903 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.928 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 69\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.927 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.911 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.908 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.924 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 70\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.910 in Step 400\n",
      "Training loss  0.912 in Step 500\n",
      "Training loss  0.919 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.904 in Step 900\n",
      "Training loss  0.922 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 71\n",
      "Training loss  0.923 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.915 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.910 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.908 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.911 in Step 1300\n",
      "Training loss  0.914 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 72\n",
      "Training loss  0.911 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.911 in Step 500\n",
      "Training loss  0.919 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.914 in Step 800\n",
      "Training loss  0.925 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.929 in Step 1100\n",
      "Training loss  0.928 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 73\n",
      "Training loss  0.916 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.908 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.910 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 74\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.919 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.919 in Step 600\n",
      "Training loss  0.905 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 75\n",
      "Training loss  0.911 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.911 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.923 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 76\n",
      "Training loss  0.923 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.907 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.931 in Step 600\n",
      "Training loss  0.917 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.916 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.907 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 77\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.905 in Step 400\n",
      "Training loss  0.926 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.926 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.927 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 78\n",
      "Training loss  0.918 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.910 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.925 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.921 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.923 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.911 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.928 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 79\n",
      "Training loss  0.924 in Step 0\n",
      "Training loss  0.916 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.919 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.911 in Step 600\n",
      "Training loss  0.917 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.910 in Step 1100\n",
      "Training loss  0.916 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.907 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 80\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.926 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.907 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.911 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.927 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 81\n",
      "Training loss  0.909 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.925 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.910 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.927 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.928 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.912 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 82\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.923 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.906 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.926 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.908 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 83\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.912 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.924 in Step 500\n",
      "Training loss  0.910 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.908 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.926 in Step 1300\n",
      "Training loss  0.926 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 84\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.923 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.914 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.918 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 85\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.923 in Step 100\n",
      "Training loss  0.923 in Step 200\n",
      "Training loss  0.924 in Step 300\n",
      "Training loss  0.927 in Step 400\n",
      "Training loss  0.912 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.913 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.932 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 86\n",
      "Training loss  0.928 in Step 0\n",
      "Training loss  0.908 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.912 in Step 300\n",
      "Training loss  0.912 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.908 in Step 600\n",
      "Training loss  0.907 in Step 700\n",
      "Training loss  0.923 in Step 800\n",
      "Training loss  0.912 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.923 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.909 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 87\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.925 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.913 in Step 800\n",
      "Training loss  0.927 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 88\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.907 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.896 in Step 600\n",
      "Training loss  0.908 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.912 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.922 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 89\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.917 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.924 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.906 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 90\n",
      "Training loss  0.909 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.930 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.924 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.909 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 91\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.927 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.918 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.908 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.909 in Step 1400\n",
      "Training loss  0.911 in Step 1500\n",
      "Training loss  0.917 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 92\n",
      "Training loss  0.924 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.914 in Step 400\n",
      "Training loss  0.908 in Step 500\n",
      "Training loss  0.925 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.910 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.916 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.910 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.930 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 93\n",
      "Training loss  0.909 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.917 in Step 700\n",
      "Training loss  0.924 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.912 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.903 in Step 1300\n",
      "Training loss  0.914 in Step 1400\n",
      "Training loss  0.924 in Step 1500\n",
      "Training loss  0.924 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 94\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.919 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.924 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.907 in Step 800\n",
      "Training loss  0.924 in Step 900\n",
      "Training loss  0.930 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.928 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 95\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.910 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.925 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.924 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.910 in Step 1400\n",
      "Training loss  0.911 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 96\n",
      "Training loss  0.915 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.915 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.923 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 97\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.927 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.924 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.909 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 98\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.930 in Step 200\n",
      "Training loss  0.924 in Step 300\n",
      "Training loss  0.927 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.909 in Step 800\n",
      "Training loss  0.912 in Step 900\n",
      "Training loss  0.924 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.909 in Step 1400\n",
      "Training loss  0.922 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.916 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 99\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.929 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.909 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.922 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.906 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.922 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.923 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 100\n",
      "Training loss  0.918 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.921 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.926 in Step 900\n",
      "Training loss  0.922 in Step 1000\n",
      "Training loss  0.916 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 101\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.929 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.907 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.930 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.920 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.918 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.908 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 102\n",
      "Training loss  0.923 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.904 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.929 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.909 in Step 1400\n",
      "Training loss  0.918 in Step 1500\n",
      "Training loss  0.911 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 103\n",
      "Training loss  0.925 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.912 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.920 in Step 600\n",
      "Training loss  0.910 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.926 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 104\n",
      "Training loss  0.918 in Step 0\n",
      "Training loss  0.916 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.924 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.926 in Step 1200\n",
      "Training loss  0.921 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.922 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.907 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 105\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.923 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.912 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.907 in Step 800\n",
      "Training loss  0.910 in Step 900\n",
      "Training loss  0.927 in Step 1000\n",
      "Training loss  0.921 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.924 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 106\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.907 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.919 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 107\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.917 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.923 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.927 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.924 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.913 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 108\n",
      "Training loss  0.924 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.927 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.913 in Step 1000\n",
      "Training loss  0.924 in Step 1100\n",
      "Training loss  0.922 in Step 1200\n",
      "Training loss  0.929 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 109\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.927 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.925 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.914 in Step 800\n",
      "Training loss  0.932 in Step 900\n",
      "Training loss  0.904 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.919 in Step 1200\n",
      "Training loss  0.918 in Step 1300\n",
      "Training loss  0.927 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.925 in Step 1600\n",
      "Training loss  0.917 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 110\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.925 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.923 in Step 800\n",
      "Training loss  0.921 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.926 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 111\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.931 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.930 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.921 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.922 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 112\n",
      "Training loss  0.920 in Step 0\n",
      "Training loss  0.927 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.921 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.922 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 113\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.917 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.926 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.923 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.916 in Step 1200\n",
      "Training loss  0.908 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.913 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 114\n",
      "Training loss  0.916 in Step 0\n",
      "Training loss  0.920 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.924 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.905 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 115\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.928 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.912 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.907 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.905 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.925 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 116\n",
      "Training loss  0.923 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.926 in Step 400\n",
      "Training loss  0.907 in Step 500\n",
      "Training loss  0.919 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.925 in Step 900\n",
      "Training loss  0.918 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 117\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.917 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.905 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.915 in Step 1000\n",
      "Training loss  0.913 in Step 1100\n",
      "Training loss  0.906 in Step 1200\n",
      "Training loss  0.923 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.922 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.906 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 118\n",
      "Training loss  0.909 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.910 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.921 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.913 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.914 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.915 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.923 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 119\n",
      "Training loss  0.921 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.917 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.912 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.920 in Step 600\n",
      "Training loss  0.913 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.921 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.922 in Step 1200\n",
      "Training loss  0.905 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.931 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 120\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.923 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.912 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.925 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.924 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.923 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 121\n",
      "Training loss  0.908 in Step 0\n",
      "Training loss  0.910 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.910 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.922 in Step 1100\n",
      "Training loss  0.927 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.911 in Step 1500\n",
      "Training loss  0.927 in Step 1600\n",
      "Training loss  0.926 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 122\n",
      "Training loss  0.912 in Step 0\n",
      "Training loss  0.918 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.912 in Step 500\n",
      "Training loss  0.927 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.924 in Step 800\n",
      "Training loss  0.910 in Step 900\n",
      "Training loss  0.911 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.911 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.924 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 123\n",
      "Training loss  0.920 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.928 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.923 in Step 600\n",
      "Training loss  0.911 in Step 700\n",
      "Training loss  0.906 in Step 800\n",
      "Training loss  0.927 in Step 900\n",
      "Training loss  0.909 in Step 1000\n",
      "Training loss  0.916 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.912 in Step 1400\n",
      "Training loss  0.920 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 124\n",
      "Training loss  0.925 in Step 0\n",
      "Training loss  0.916 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.909 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.922 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.924 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.930 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 125\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.909 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.912 in Step 400\n",
      "Training loss  0.913 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.917 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 126\n",
      "Training loss  0.914 in Step 0\n",
      "Training loss  0.919 in Step 100\n",
      "Training loss  0.925 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.915 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.921 in Step 700\n",
      "Training loss  0.914 in Step 800\n",
      "Training loss  0.908 in Step 900\n",
      "Training loss  0.919 in Step 1000\n",
      "Training loss  0.922 in Step 1100\n",
      "Training loss  0.920 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.927 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.915 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 127\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.909 in Step 100\n",
      "Training loss  0.912 in Step 200\n",
      "Training loss  0.922 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.918 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.911 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.912 in Step 1200\n",
      "Training loss  0.928 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.925 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 128\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.916 in Step 400\n",
      "Training loss  0.928 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.907 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.918 in Step 1000\n",
      "Training loss  0.910 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.926 in Step 1300\n",
      "Training loss  0.927 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 129\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.917 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.926 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.922 in Step 900\n",
      "Training loss  0.913 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.906 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.918 in Step 1400\n",
      "Training loss  0.926 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.930 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 130\n",
      "Training loss  0.907 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.925 in Step 500\n",
      "Training loss  0.909 in Step 600\n",
      "Training loss  0.915 in Step 700\n",
      "Training loss  0.924 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.913 in Step 1000\n",
      "Training loss  0.919 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.919 in Step 1300\n",
      "Training loss  0.914 in Step 1400\n",
      "Training loss  0.908 in Step 1500\n",
      "Training loss  0.911 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 131\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.911 in Step 200\n",
      "Training loss  0.914 in Step 300\n",
      "Training loss  0.924 in Step 400\n",
      "Training loss  0.924 in Step 500\n",
      "Training loss  0.927 in Step 600\n",
      "Training loss  0.909 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.907 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.912 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.909 in Step 1500\n",
      "Training loss  0.925 in Step 1600\n",
      "Training loss  0.913 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 132\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.913 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.935 in Step 500\n",
      "Training loss  0.909 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.913 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.918 in Step 1300\n",
      "Training loss  0.911 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.921 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 133\n",
      "Training loss  0.908 in Step 0\n",
      "Training loss  0.908 in Step 100\n",
      "Training loss  0.916 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.914 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.924 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.913 in Step 1200\n",
      "Training loss  0.919 in Step 1300\n",
      "Training loss  0.923 in Step 1400\n",
      "Training loss  0.920 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 134\n",
      "Training loss  0.919 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.913 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.905 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.903 in Step 800\n",
      "Training loss  0.912 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.913 in Step 1400\n",
      "Training loss  0.920 in Step 1500\n",
      "Training loss  0.928 in Step 1600\n",
      "Training loss  0.914 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 135\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.923 in Step 100\n",
      "Training loss  0.909 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.910 in Step 500\n",
      "Training loss  0.916 in Step 600\n",
      "Training loss  0.919 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.911 in Step 900\n",
      "Training loss  0.926 in Step 1000\n",
      "Training loss  0.915 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.902 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.914 in Step 1500\n",
      "Training loss  0.919 in Step 1600\n",
      "Training loss  0.912 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 136\n",
      "Training loss  0.910 in Step 0\n",
      "Training loss  0.921 in Step 100\n",
      "Training loss  0.921 in Step 200\n",
      "Training loss  0.910 in Step 300\n",
      "Training loss  0.918 in Step 400\n",
      "Training loss  0.920 in Step 500\n",
      "Training loss  0.918 in Step 600\n",
      "Training loss  0.923 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.909 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.914 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 137\n",
      "Training loss  0.922 in Step 0\n",
      "Training loss  0.909 in Step 100\n",
      "Training loss  0.906 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.923 in Step 600\n",
      "Training loss  0.916 in Step 700\n",
      "Training loss  0.912 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.901 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.909 in Step 1200\n",
      "Training loss  0.922 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.921 in Step 1500\n",
      "Training loss  0.912 in Step 1600\n",
      "Training loss  0.906 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 138\n",
      "Training loss  0.927 in Step 0\n",
      "Training loss  0.932 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.929 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.922 in Step 600\n",
      "Training loss  0.909 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.916 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.921 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.919 in Step 1400\n",
      "Training loss  0.920 in Step 1500\n",
      "Training loss  0.916 in Step 1600\n",
      "Training loss  0.922 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 139\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.914 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.912 in Step 300\n",
      "Training loss  0.920 in Step 400\n",
      "Training loss  0.910 in Step 500\n",
      "Training loss  0.912 in Step 600\n",
      "Training loss  0.913 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.914 in Step 900\n",
      "Training loss  0.917 in Step 1000\n",
      "Training loss  0.911 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.923 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.924 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 140\n",
      "Training loss  0.920 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.926 in Step 200\n",
      "Training loss  0.916 in Step 300\n",
      "Training loss  0.921 in Step 400\n",
      "Training loss  0.921 in Step 500\n",
      "Training loss  0.913 in Step 600\n",
      "Training loss  0.920 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.905 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.918 in Step 1300\n",
      "Training loss  0.928 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.917 in Step 1600\n",
      "Training loss  0.910 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 141\n",
      "Training loss  0.927 in Step 0\n",
      "Training loss  0.926 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.911 in Step 300\n",
      "Training loss  0.909 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.913 in Step 600\n",
      "Training loss  0.918 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.917 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.925 in Step 1200\n",
      "Training loss  0.929 in Step 1300\n",
      "Training loss  0.921 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.921 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 142\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.912 in Step 100\n",
      "Training loss  0.918 in Step 200\n",
      "Training loss  0.917 in Step 300\n",
      "Training loss  0.911 in Step 400\n",
      "Training loss  0.915 in Step 500\n",
      "Training loss  0.905 in Step 600\n",
      "Training loss  0.925 in Step 700\n",
      "Training loss  0.920 in Step 800\n",
      "Training loss  0.905 in Step 900\n",
      "Training loss  0.913 in Step 1000\n",
      "Training loss  0.917 in Step 1100\n",
      "Training loss  0.915 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.917 in Step 1400\n",
      "Training loss  0.909 in Step 1500\n",
      "Training loss  0.918 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 143\n",
      "Training loss  0.907 in Step 0\n",
      "Training loss  0.908 in Step 100\n",
      "Training loss  0.919 in Step 200\n",
      "Training loss  0.915 in Step 300\n",
      "Training loss  0.922 in Step 400\n",
      "Training loss  0.916 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.921 in Step 800\n",
      "Training loss  0.918 in Step 900\n",
      "Training loss  0.923 in Step 1000\n",
      "Training loss  0.925 in Step 1100\n",
      "Training loss  0.930 in Step 1200\n",
      "Training loss  0.911 in Step 1300\n",
      "Training loss  0.923 in Step 1400\n",
      "Training loss  0.916 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.918 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 144\n",
      "Training loss  0.917 in Step 0\n",
      "Training loss  0.913 in Step 100\n",
      "Training loss  0.922 in Step 200\n",
      "Training loss  0.921 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.913 in Step 600\n",
      "Training loss  0.909 in Step 700\n",
      "Training loss  0.919 in Step 800\n",
      "Training loss  0.919 in Step 900\n",
      "Training loss  0.910 in Step 1000\n",
      "Training loss  0.923 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.920 in Step 1400\n",
      "Training loss  0.910 in Step 1500\n",
      "Training loss  0.905 in Step 1600\n",
      "Training loss  0.911 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 145\n",
      "Training loss  0.925 in Step 0\n",
      "Training loss  0.917 in Step 100\n",
      "Training loss  0.923 in Step 200\n",
      "Training loss  0.923 in Step 300\n",
      "Training loss  0.919 in Step 400\n",
      "Training loss  0.914 in Step 500\n",
      "Training loss  0.925 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.911 in Step 800\n",
      "Training loss  0.915 in Step 900\n",
      "Training loss  0.918 in Step 1000\n",
      "Training loss  0.916 in Step 1100\n",
      "Training loss  0.918 in Step 1200\n",
      "Training loss  0.913 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.913 in Step 1500\n",
      "Training loss  0.911 in Step 1600\n",
      "Training loss  0.925 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 146\n",
      "Training loss  0.932 in Step 0\n",
      "Training loss  0.922 in Step 100\n",
      "Training loss  0.920 in Step 200\n",
      "Training loss  0.918 in Step 300\n",
      "Training loss  0.928 in Step 400\n",
      "Training loss  0.919 in Step 500\n",
      "Training loss  0.920 in Step 600\n",
      "Training loss  0.914 in Step 700\n",
      "Training loss  0.916 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.924 in Step 1000\n",
      "Training loss  0.920 in Step 1100\n",
      "Training loss  0.924 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.915 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.914 in Step 1600\n",
      "Training loss  0.920 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 147\n",
      "Training loss  0.916 in Step 0\n",
      "Training loss  0.913 in Step 100\n",
      "Training loss  0.914 in Step 200\n",
      "Training loss  0.912 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.924 in Step 500\n",
      "Training loss  0.927 in Step 600\n",
      "Training loss  0.912 in Step 700\n",
      "Training loss  0.917 in Step 800\n",
      "Training loss  0.913 in Step 900\n",
      "Training loss  0.907 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.917 in Step 1200\n",
      "Training loss  0.916 in Step 1300\n",
      "Training loss  0.916 in Step 1400\n",
      "Training loss  0.917 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.922 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 148\n",
      "Training loss  0.913 in Step 0\n",
      "Training loss  0.911 in Step 100\n",
      "Training loss  0.923 in Step 200\n",
      "Training loss  0.920 in Step 300\n",
      "Training loss  0.917 in Step 400\n",
      "Training loss  0.917 in Step 500\n",
      "Training loss  0.910 in Step 600\n",
      "Training loss  0.911 in Step 700\n",
      "Training loss  0.915 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.916 in Step 1000\n",
      "Training loss  0.914 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.917 in Step 1300\n",
      "Training loss  0.922 in Step 1400\n",
      "Training loss  0.919 in Step 1500\n",
      "Training loss  0.922 in Step 1600\n",
      "Training loss  0.907 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n",
      "Epoch 149\n",
      "Training loss  0.916 in Step 0\n",
      "Training loss  0.915 in Step 100\n",
      "Training loss  0.924 in Step 200\n",
      "Training loss  0.913 in Step 300\n",
      "Training loss  0.913 in Step 400\n",
      "Training loss  0.918 in Step 500\n",
      "Training loss  0.917 in Step 600\n",
      "Training loss  0.922 in Step 700\n",
      "Training loss  0.922 in Step 800\n",
      "Training loss  0.920 in Step 900\n",
      "Training loss  0.920 in Step 1000\n",
      "Training loss  0.918 in Step 1100\n",
      "Training loss  0.914 in Step 1200\n",
      "Training loss  0.915 in Step 1300\n",
      "Training loss  0.925 in Step 1400\n",
      "Training loss  0.912 in Step 1500\n",
      "Training loss  0.920 in Step 1600\n",
      "Training loss  0.915 in Step 1700\n",
      "※※※Training loss  0.917※※※\n",
      "Training timepoint saved\n",
      "Valid loss  0.875 in Step 0\n",
      "Valid loss  0.862 in Step 100\n",
      "Valid loss  0.860 in Step 200\n",
      "Valid loss  0.869 in Step 300\n",
      "Valid loss  0.872 in Step 400\n",
      "※※※Valid loss  0.868※※※\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KSTTwi31xAvh"
   },
   "outputs": [],
   "source": [
    "### Save\n",
    "valid_losses.save()\n",
    "train_losses.save()\n",
    "text_hist.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "3yaMyIzH12RD",
    "outputId": "1426c24a-c60c-48c2-8690-f3a07bb9ba7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8422aa7050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGxCAYAAABBZ+3pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVsElEQVR4nO3deVxU9f4/8NeZfdhRlEUQsEUxt8QdNe0aXlPT/HVTu2qm3rSsJG+LprbYNy27mt0SygrTNrl1zZtlGZWWhoailVuuKIoQggoIzH5+fxxmZFhnEGaG4fV8NI+ZOXNm5v0ZCF/z+XzO5wiiKIogIiIi8mAydxdARERE1BAGFiIiIvJ4DCxERETk8RhYiIiIyOMxsBAREZHHY2AhIiIij8fAQkRERB6PgYWIiIg8HgMLEREReTwGFqIW5P3334cgCNi3b5+7S3HasGHDMGzYMLe9v8ViwQcffIARI0YgJCQESqUS7du3x5gxY7BlyxZYLBa31UZEDVO4uwAiah2Sk5Pd9t46nQ7jx4/Ht99+i0mTJiElJQVhYWG4ePEivvnmG/ztb39DWloaxo0b57Yaiah+DCxE5DRRFKHT6aDVah1+TteuXZuxovrNnz8f27Ztw/r16zFt2jS7xyZMmIAnn3wSFRUVTfJe5eXl8PHxaZLXIqJrOCRE5IVOnDiB++67D+3bt4darUZcXBzWrFljt49Op8M///lP9OrVC4GBgWjTpg0GDhyI//3vfzVeTxAEPPLII3jrrbcQFxcHtVqN9evX24aotm/fjoceegghISFo27YtJkyYgAsXLti9RvUhoTNnzkAQBPzrX//CqlWrEBsbCz8/PwwcOBB79uypUcM777yDm2++GWq1Gl27dsXHH3+M6dOnIyYmpt7PIj8/H++++y5GjhxZI6xY3XTTTejRoweAa8NuZ86csdtnx44dEAQBO3bssGtTt27d8NNPP2HQoEHw8fHBjBkzMH78eERHR9c6zNS/f3/07t3bdl8URSQnJ6NXr17QarUIDg7GPffcg9OnT9fbLqLWhoGFyMscOXIEffv2xaFDh7By5Up8+eWXGD16NB577DG88MILtv30ej0uXbqEJ554Aps3b8Ynn3yCwYMHY8KECdiwYUON1928eTNSUlLw7LPPYtu2bRgyZIjtsVmzZkGpVOLjjz/GihUrsGPHDkyZMsWhetesWYP09HSsXr0aH330EcrKynDnnXeiuLjYts/atWvx4IMPokePHti0aRMWL16MF154wS481GX79u0wGo0YP368Q/U4Ky8vD1OmTMF9992HrVu34uGHH8aMGTOQk5ODH374wW7fP/74A5mZmXjggQds22bPno2kpCSMGDECmzdvRnJyMg4fPoxBgwbhzz//bJaaiVokkYhajHXr1okAxL1799a5z8iRI8XIyEixuLjYbvsjjzwiajQa8dKlS7U+z2QyiUajUZw5c6Z466232j0GQAwMDKzxXGs9Dz/8sN32FStWiADEvLw827bbbrtNvO2222z3s7OzRQBi9+7dRZPJZNuemZkpAhA/+eQTURRF0Ww2i2FhYWL//v3t3uPs2bOiUqkUo6Oj6/wsRFEUX375ZRGA+M0339S7X/U2ZWdn223fvn27CEDcvn27XZsAiN9//73dvkajUQwNDRXvu+8+u+1PPfWUqFKpxMLCQlEURXH37t0iAHHlypV2+507d07UarXiU0895VDNRK0Be1iIvIhOp8P333+Pu+++Gz4+PjCZTLbLnXfeCZ1OZzfc8umnnyIhIQF+fn5QKBRQKpV47733cPTo0RqvffvttyM4OLjW973rrrvs7luHV86ePdtgzaNHj4ZcLq/zuceOHUN+fj7uvfdeu+d17NgRCQkJDb5+cwsODsbtt99ut02hUGDKlCnYtGmTrafIbDbjgw8+wLhx49C2bVsAwJdffglBEDBlyhS7n1VYWBh69uzpUA8SUWvBwELkRYqKimAymfDGG29AqVTaXe68804AQGFhIQBg06ZNuPfee9GhQwd8+OGH2L17N/bu3YsZM2ZAp9PVeO3w8PA639f6D7CVWq0GAIcmsjb03KKiIgBAaGhojefWtq26jh07AgCys7Mb3Lcx6vpcrJ/jxo0bAQDbtm1DXl6e3XDQn3/+CVEUERoaWuPntWfPHtvPioh4lBCRVwkODoZcLsfUqVMxd+7cWveJjY0FAHz44YeIjY1FWloaBEGwPa7X62t9XtV9XMkaaGqbz5Gfn9/g84cPHw6lUonNmzdjzpw5De6v0WgA1Pwc6goPdX0uXbt2Rb9+/bBu3TrMnj0b69atQ0REBBITE237hISEQBAE7Ny50xbUqqptG1FrxR4WIi/i4+OD4cOH48CBA+jRowf69OlT42INAIIgQKVS2f2Dm5+fX+tRQu7UuXNnhIWF4T//+Y/d9pycHGRkZDT4/LCwMMyaNQvbtm2rdTIxAJw6dQq///47ANiOOrLet/riiy+crv2BBx7AL7/8gl27dmHLli24//777Ya/xowZA1EUkZubW+vPqnv37k6/J5G3Yg8LUQv0ww8/1DjsFgDuvPNOvP766xg8eDCGDBmChx56CDExMSgtLcXJkyexZcsW25ErY8aMwaZNm/Dwww/jnnvuwblz5/Diiy8iPDwcJ06ccHGL6iaTyfDCCy9g9uzZuOeeezBjxgxcuXIFL7zwAsLDwyGTNfy9a9WqVTh9+jSmT5+Obdu24e6770ZoaCgKCwuRnp6OdevWYePGjejRowf69u2Lzp0744knnoDJZEJwcDA+//xz7Nq1y+naJ0+ejPnz52Py5MnQ6/WYPn263eMJCQl48MEH8cADD2Dfvn0YOnQofH19kZeXh127dqF79+546KGHnH5fIm/EwELUAj399NO1bs/OzkbXrl2xf/9+vPjii1i8eDEKCgoQFBSEm266yTaPBZC+/RcUFOCtt95CamoqOnXqhAULFuD8+fN2hz97ggcffBCCIGDFihW4++67ERMTgwULFuB///sfcnJyGny+RqPBV199hY8++gjr16/H7NmzUVJSguDgYPTp0wepqakYO3YsAEAul2PLli145JFHMGfOHKjVakyaNAlvvvkmRo8e7VTdgYGBuPvuu/Hxxx8jISEBN998c4193n77bQwYMABvv/02kpOTYbFYEBERgYSEBPTr18+p9yPyZoIoiqK7iyAictaVK1dw8803Y/z48Vi7dq27yyGiZsYeFiLyePn5+XjppZcwfPhwtG3bFmfPnsVrr72G0tJSzJs3z93lEZELMLAQkcdTq9U4c+YMHn74YVy6dAk+Pj4YMGAA3nrrLdxyyy3uLo+IXIBDQkREROTxeFgzEREReTwGFiIiIvJ4DCxERETk8bxm0q3FYsGFCxfg7+/vtiXEiYiIyDmiKKK0tBQRERH1LgTpNYHlwoULiIqKcncZRERE1Ajnzp1DZGRknY97TWDx9/cHIDU4ICDAzdUQERGRI0pKShAVFWX7d7wuXhNYrMNAAQEBDCxEREQtTEPTOTjploiIiDweAwsRERF5PAYWIiIi8nheM4eFiIioqYmiCJPJBLPZ7O5SWiy5XA6FQnHdS44wsBAREdXCYDAgLy8P5eXl7i6lxfPx8UF4eDhUKlWjX4OBhYiIqBqLxYLs7GzI5XJERERApVJxUdJGEEURBoMBFy9eRHZ2Nm666aZ6F4erDwMLERFRNQaDARaLBVFRUfDx8XF3OS2aVquFUqnE2bNnYTAYoNFoGvU6nHRLRERUh8b2BpC9pvgc+ZMgIiIij8fAQkRERB6PgYWIiIjqNWzYMCQlJbm1Bk66JSIi8hINHcl0//334/3333f6dTdt2gSlUtnIqpoGA0sDUndlI7uwDFMHRuPm0PrPJElEROROeXl5tttpaWl49tlncezYMds2rVZrt7/RaHQoiLRp06bpimwkDgk1YMvvF/DBnrM4U1jm7lKIiMiNRFFEucHk8osoig7XGBYWZrsEBgZCEATbfZ1Oh6CgIPznP//BsGHDoNFo8OGHH6KoqAiTJ09GZGQkfHx80L17d3zyySd2r1t9SCgmJgbLli3DjBkz4O/vj44dO2Lt2rVN9VHXij0sDfBTSx9RmcHk5kqIiMidKoxmdH12m8vf98jSkfBRNd0/108//TRWrlyJdevWQa1WQ6fTIT4+Hk8//TQCAgLw1VdfYerUqejUqRP69+9f5+usXLkSL774Ip555hl89tlneOihhzB06FB06dKlyWqtioGlAb6VvyRX9TyPBBERtXxJSUmYMGGC3bYnnnjCdvvRRx/FN998g08//bTewHLnnXfi4YcfBiCFoNdeew07duxgYHEXX2sPi549LERErZlWKceRpSPd8r5NqU+fPnb3zWYzXn75ZaSlpSE3Nxd6vR56vR6+vr71vk6PHj1st61DTwUFBU1aa1UMLA3wU0u/KAwsREStmyAITTo04y7Vg8jKlSvx2muvYfXq1ejevTt8fX2RlJQEg8FQ7+tUn6wrCAIsFkuT12vV8j/5ZmbtYbnKwEJERF5o586dGDduHKZMmQJAOvHjiRMnEBcX5+bK7PEooQZwSIiIiLzZjTfeiPT0dGRkZODo0aOYPXs28vPz3V1WDQwsDbAdJcRJt0RE5IWWLFmC3r17Y+TIkRg2bBjCwsIwfvx4d5dVA4eEGsAhISIiaommT5+O6dOn2+7HxMTUuqZLmzZtsHnz5npfa8eOHXb3z5w5U2OfX3/91fkincAelgZw0i0REZH7MbA0gD0sRERE7sfA0gBfrnRLRETkdgwsDeCkWyIiIvdjYGkAh4SIiIjcj4GlAX6VqxoaTBYYzc23gh8RERHVjYGlAb7qa+dw4JFCRERE7sHA0gCFXAa1QvqYOCxERETkHgwsDvDlxFsiIiK3YmBxgHVYiD0sRETk7YYNG4akpCTb/ZiYGKxevbre5wiC0OBqudeLgcUBviqeAJGIiDzf2LFjMWLEiFof2717NwRBwP79+516zb179+LBBx9sivKuCwOLA/x4xmYiImoBZs6ciR9++AFnz56t8Vhqaip69eqF3r17O/Wa7dq1g4+PT1OV2GgMLA7gWixERARRBAxlrr/UcsLCuowZMwbt27fH+++/b7e9vLwcaWlpGD9+PCZPnozIyEj4+Pige/fu+OSTT+p9zepDQidOnMDQoUOh0WjQtWtXpKenO/MpNhrP1uwA9rAQERGM5cCyCNe/7zMXAJWvQ7sqFApMmzYN77//Pp599lkIggAA+PTTT2EwGDBr1ix88sknePrppxEQEICvvvoKU6dORadOndC/f/8GX99isWDChAkICQnBnj17UFJSYjffpTmxh8UB1km3ZQYeJURERJ5txowZOHPmDHbs2GHblpqaigkTJqBDhw544okn0KtXL3Tq1AmPPvooRo4ciU8//dSh1/7uu+9w9OhRfPDBB+jVqxeGDh2KZcuWNVNL7LGHxQEcEiIiIih9pN4Od7yvE7p06YJBgwYhNTUVw4cPx6lTp7Bz5058++23MJvNePnll5GWlobc3Fzo9Xro9Xr4+jrWg3P06FF07NgRkZGRtm0DBw50qr7GYmBxAIeEiIgIguDw0Iy7zZw5E4888gjWrFmDdevWITo6Gn/5y1/w6quv4rXXXsPq1avRvXt3+Pr6IikpCQaDwaHXFWuZT2MddmpuHBJyAHtYiIioJbn33nshl8vx8ccfY/369XjggQcgCAJ27tyJcePGYcqUKejZsyc6deqEEydOOPy6Xbt2RU5ODi5cuNbTtHv37uZoQg0MLA7wZQ8LERG1IH5+fpg4cSKeeeYZXLhwAdOnTwcA3HjjjUhPT0dGRgaOHj2K2bNnIz8/3+HXHTFiBDp37oxp06bht99+w86dO7Fo0aJmaoU9BhYH+Fkn3XJpfiIiaiFmzpyJy5cvY8SIEejYsSMAYMmSJejduzdGjhyJYcOGISwsDOPHj3f4NWUyGT7//HPo9Xr069cPs2bNwksvvdRMLbDHOSwOsK50yyEhIiJqKQYOHFhjzkmbNm0aXEK/6tFFAHDmzBm7+zfffDN27txpt622uS1NjT0sDuCkWyIiIvdqVGBJTk5GbGwsNBoN4uPjaySt6tasWYO4uDhotVp07twZGzZsqLHP6tWr0blzZ2i1WkRFReHxxx+HTqdrTHlNjnNYiIiI3MvpIaG0tDQkJSUhOTkZCQkJePvttzFq1CgcOXLENkZWVUpKChYuXIh33nkHffv2RWZmJv7xj38gODgYY8eOBQB89NFHWLBgAVJTUzFo0CAcP37cNkHotddeu74WNgEeJUREROReTvewrFq1CjNnzsSsWbMQFxeH1atXIyoqCikpKbXu/8EHH2D27NmYOHEiOnXqhEmTJmHmzJl45ZVXbPvs3r0bCQkJuO+++xATE4PExERMnjwZ+/bta3zLmpBtSMhgdsk4HREREdlzKrAYDAZkZWUhMTHRbntiYiIyMjJqfY5er4dGo7HbptVqkZmZCaPRCAAYPHgwsrKykJmZCQA4ffo0tm7ditGjR9dZi16vR0lJid2luViX5jdbROhNlmZ7HyIi8iz8kto0muJzdCqwFBYWwmw2IzQ01G57aGhoncdxjxw5Eu+++y6ysrIgiiL27duH1NRUGI1GFBYWAgAmTZqEF198EYMHD4ZSqcQNN9yA4cOHY8GCBXXWsnz5cgQGBtouUVFRzjTFKdajhAAOCxERtQZKpRKAdJZjun7Wz9H6uTZGow5rrr4MryiKdS7Nu2TJEuTn52PAgAEQRRGhoaGYPn06VqxYAblc6rnYsWMHXnrpJSQnJ6N///44efIk5s2bh/DwcCxZsqTW1124cCHmz59vu19SUtJsoUUmE+CjkqPcYEaZ3oQQP3WzvA8REXkGuVyOoKAgFBQUAAB8fHxctgS9NxFFEeXl5SgoKEBQUJDt3/3GcCqwhISEQC6X1+hNKSgoqNHrYqXVapGamoq3334bf/75J8LDw7F27Vr4+/sjJCQEgBRqpk6dilmzZgEAunfvjrKyMjz44INYtGgRZLKaHUFqtRpqteuCg69agXKDmT0sREStRFhYGADYQgs1XlBQkO3zbCynAotKpUJ8fDzS09Nx991327anp6dj3Lhx9T5XqVTazu64ceNGjBkzxhZEysvLa4QSuVwOURQ9ZvzQT63AxVI9V7slImolBEFAeHg42rdvb5tzSc5TKpXX1bNi5fSQ0Pz58zF16lT06dMHAwcOxNq1a5GTk4M5c+YAkIZqcnNzbWutHD9+HJmZmejfvz8uX76MVatW4dChQ1i/fr3tNceOHYtVq1bh1ltvtQ0JLVmyBHfddVeTNLIp+NqW52cPCxFRayKXyz3m36LWzOnAMnHiRBQVFWHp0qXIy8tDt27dsHXrVkRHRwMA8vLykJOTY9vfbDZj5cqVOHbsGJRKJYYPH46MjAzExMTY9lm8eDEEQcDixYuRm5uLdu3aYezYsS47P4EjuDw/ERGR+wiip4y5XKeSkhIEBgaiuLgYAQEBTf76M9/fi+//KMDLE7pjUr+aC+QRERGR8xz995vnEnIQV7slIiJyHwYWB12bw8JJt0RERK7GwOIg6xyWMgN7WIiIiFyNgcVBHBIiIiJyHwYWB1lPgFjOwEJERORyDCwOutbDwjksRERErsbA4iAuHEdEROQ+DCwOsg4JcdItERGR6zGwOIiTbomIiNyHgcVBth4WBhYiIiKXY2BxkK8tsHDSLRERkasxsDjINunWYIKXnH6JiIioxWBgcZB1SEgUgXIDe1mIiIhciYHFQVqlHDJBus15LERERK7FwOIgQRBs5xPikUJERESuxcDiBE68JSIicg+FuwvweIYywFgBqPxsE2/Zw0JERORa7GFpyPujgVdvALJ/5FosREREbsLA0hCFRro26bjaLRERkZswsDREoZauTXpbDwsDCxERkWsxsDREoZWuTToOCREREbkJA0tDrD0sRh38NOxhISIicgcGloZUmcPCISEiIiL3YGBpSJU5LLZJtzoGFiIiIldiYGlIlR4Wfw4JERERuQUDS0OUVQ5r5tL8REREbsHA0pCqc1jYw0JEROQWDCwNsc1h4WHNRERE7sLA0hBbD0uVheM46ZaIiMilGFgawiEhIiIit2NgaYg1sBjt12ERRdGNRREREbUuDCwNqWUOi0UEKoxmNxZFRETUujCwNKTKHBYflRyCIN3lsBAREZHrMLA0pMo6LIIgwE/FibdERESuxsDSkCqTbgHYlucv03NIiIiIyFUYWBpSLbBYjxQq1RvdVREREVGrw8DSkConPwRQZfE49rAQERG5CgNLQxRa6draw2I7tJk9LERERK7CwNIQaw+LsVpg4aRbIiIil2FgaYh1DotZD4iibdLtVQ4JERERuQwDS0OsPSwAYNLDX8MhISIiIldjYGmItYcFqHbGZvawEBERuQoDS0PkSkCo/JhMOtuQUCnnsBAREblMowJLcnIyYmNjodFoEB8fj507d9a7/5o1axAXFwetVovOnTtjw4YNNfa5cuUK5s6di/DwcGg0GsTFxWHr1q2NKa9pCUKtZ2wu49L8RERELqNw9glpaWlISkpCcnIyEhIS8Pbbb2PUqFE4cuQIOnbsWGP/lJQULFy4EO+88w769u2LzMxM/OMf/0BwcDDGjh0LADAYDLjjjjvQvn17fPbZZ4iMjMS5c+fg7+9//S1sCgo1YCwHTHr4qX0B8FxCREREruR0YFm1ahVmzpyJWbNmAQBWr16Nbdu2ISUlBcuXL6+x/wcffIDZs2dj4sSJAIBOnTphz549eOWVV2yBJTU1FZcuXUJGRgaUSiUAIDo6utGNanJVe1jUQQCAUgYWIiIil3FqSMhgMCArKwuJiYl22xMTE5GRkVHrc/R6PTQajd02rVaLzMxMGI3SkTZffPEFBg4ciLlz5yI0NBTdunXDsmXLYDbXPbFVr9ejpKTE7tJsrIHFqIOvWg6AQ0JERESu5FRgKSwshNlsRmhoqN320NBQ5Ofn1/qckSNH4t1330VWVhZEUcS+ffuQmpoKo9GIwsJCAMDp06fx2WefwWw2Y+vWrVi8eDFWrlyJl156qc5ali9fjsDAQNslKirKmaY4p0oPi79a6gHiwnFERESu06hJt4Ig2N0XRbHGNqslS5Zg1KhRGDBgAJRKJcaNG4fp06cDAORyqbfCYrGgffv2WLt2LeLj4zFp0iQsWrQIKSkpddawcOFCFBcX2y7nzp1rTFMcU+V8Qpx0S0RE5HpOBZaQkBDI5fIavSkFBQU1el2stFotUlNTUV5ejjNnziAnJwcxMTHw9/dHSEgIACA8PBw333yzLcAAQFxcHPLz82EwGGp9XbVajYCAALtLs6nSw2IdErpqMMFiEZvvPYmIiMjGqcCiUqkQHx+P9PR0u+3p6ekYNGhQvc9VKpWIjIyEXC7Hxo0bMWbMGMhk0tsnJCTg5MmTsFgstv2PHz+O8PBwqFQqZ0psHkprYNHbhoREESg3cvE4IiIiV3B6SGj+/Pl49913kZqaiqNHj+Lxxx9HTk4O5syZA0Aaqpk2bZpt/+PHj+PDDz/EiRMnkJmZiUmTJuHQoUNYtmyZbZ+HHnoIRUVFmDdvHo4fP46vvvoKy5Ytw9y5c5ugiU3A1sNSAY1SBlnl6BeHhYiIiFzD6cOaJ06ciKKiIixduhR5eXno1q0btm7dajsMOS8vDzk5Obb9zWYzVq5ciWPHjkGpVGL48OHIyMhATEyMbZ+oqCh8++23ePzxx9GjRw906NAB8+bNw9NPP339LWwKVeawCIIAP7UCJToTSnUmhDbjSBQRERFJnA4sAPDwww/j4YcfrvWx999/3+5+XFwcDhw40OBrDhw4EHv27GlMOc2vyhwWALbAwh4WIiIi1+C5hBxRPbDYztjMwEJEROQKDCyOqLJwHADbGZsZWIiIiFyDgcURtjksUmCxnrGZi8cRERG5BgOLIxTXDmsGAH8OCREREbkUA4sjqvewqBhYiIiIXImBxRFKrXTNSbdERERuwcDiiGo9LP5qnk+IiIjIlRhYHFFtDgsn3RIREbkWA4sjuA4LERGRWzGwOILrsBAREbkVA4sjalmaH2BgISIichUGFkdUOfkhUGUOCwMLERGRSzCwOKKuHhZOuiUiInIJBhZHKO0Di3WlWx7WTERE5BoMLI6o1sNiHRIqM5hhsYjuqoqIiKjVYGBxRLU5LNYhIQAoM7CXhYiIqLkxsDiiag+LKEKtkEEhEwBw4i0REZErMLA4whpYAMBsgCAI1xaP48RbIiKiZsfA4oiqgcVYAYBrsRAREbkSA4sj5EoA0hBQ9XksDCxERETNj4HFEYJQ51osPLSZiIio+TGwOKrakUJBPkoAwMVSvbsqIiIiajUYWByl1ErXJmkOS2yILwDg1MUyd1VERETUajCwOKpaD8uN7f0AAKcuXnVXRURERK0GA4ujqs1hsQaWkwV1B5aLpXp8uu8cjGZLs5dHRETkzRhYHFW9h6WdPwAgr1hX55FC/9p2DE9+9jtSdpxySYlERETeioHFUYrKOSyV67AE+igR4ieFmFN19LIcySsBAKTtPcdzDhEREV0HBhZHVethAYAb2kkTb2sbFhJFEWcKpQm5uVcq8POpwuavkYiIyEsxsDiq2hwWoMo8llom3haVGVBaZaho495zzVsfERGRF2NgcZSth6VmYKltSCi7sndFrZA+4vTDf+JymaGZiyQiIvJODCyOsq3D4lgPizWw9I1pg1siAmAwW/D5gdzmr5OIiMgLMbA4qp4elrNF5TCY7A9dts5fiQnxwcS+UQCA/+w7B1Hk5FsiIiJnMbA4yjaH5dqk27AADXxVcpgtIs4W2a94a+1hiQ3xw7ieHaBSyPBHfil+P1/sspKJiIi8BQOLo2rpYREEATfUsYDctcDig0AfJUZ1CwMAfJZ13gXFEhEReRcGFkfZ1mHR2W2+sV3NwCKKIs4WlQMAYtpKhz7/v96RAIAtv1+oMXxERERE9WNgcVQtPSwArvWwVJl4+2eJHhVGM+QyAVFtfAAACTeGoL2/GlfKjdhxrMA1NRMREXkJBhZH1TKHBaj9JIinC6XbUcFaKOXSRyyXCRjXKwIAeLQQERGRkxhYHFVHD8u1tVjKbMvvnymsHA4K8bXb9+5bpWGh748WoLjc2JzVEhEReRUGFkfV0cPSsY0PFDIBFUYzLhRL5xk6U2SdcGsfWOLC/dE51B8GswVfHcxr/pqJiIi8BAOLo2wLx1XYb5bLbD0p1om3py/WHlgEQcDdvTsAADZzWIiIiMhhDCyOquXkh1bdIgIAAF/8dgHAtR4W6xFCVY3rFQFBADLPXMK5S+XNVCwREZF3YWBxVC0nP7SaMTgWgNRrcrLgKnIqD2mu3sMCAOGBWgy6oS0AYOPenGYqloiIyLs0KrAkJycjNjYWGo0G8fHx2LlzZ737r1mzBnFxcdBqtejcuTM2bNhQ574bN26EIAgYP358Y0prPvX0sPSIDMJfurSHRQQWfX4QBrMFKrkMEUHaWl9q6oBoAMCGjLMoruDkWyIiooY4HVjS0tKQlJSERYsW4cCBAxgyZAhGjRqFnJzaewtSUlKwcOFCPP/88zh8+DBeeOEFzJ07F1u2bKmx79mzZ/HEE09gyJAhzrekudkWjquo9eF5I24CAPySfQkA0LGtD+QyodZ9E7uGoXOoP0r1JqzPONPkpRIREXkbpwPLqlWrMHPmTMyaNQtxcXFYvXo1oqKikJKSUuv+H3zwAWbPno2JEyeiU6dOmDRpEmbOnIlXXnnFbj+z2Yy///3veOGFF9CpU6fGtaY51dPDAlzrZbGqbTjISiYTMPf2GwEA7+3KRqmOvSxERET1cSqwGAwGZGVlITEx0W57YmIiMjIyan2OXq+HRqOx26bVapGZmQmj8do/1EuXLkW7du0wc+ZMh2rR6/UoKSmxuzSreuawWFl7WYD6AwsAjO4ejk7tfFFcYcQHe842SYlERETeyqnAUlhYCLPZjNDQULvtoaGhyM/Pr/U5I0eOxLvvvousrCyIooh9+/YhNTUVRqMRhYWFAICff/4Z7733Ht555x2Ha1m+fDkCAwNtl6ioKGea4rwGelgAqZclsav02fSKCqr35eQyAY8Ml3pZ3t2ZjbNFZbhUZoDeZG6ScomIiLxJoybdCoL93AxRFGtss1qyZAlGjRqFAQMGQKlUYty4cZg+fToAQC6Xo7S0FFOmTME777yDkJAQh2tYuHAhiouLbZdz5841pimOq7oOiyjWudu/J9+Kj//R33Z25vrc1TMC0W19cKnMgNte3YHeL6aj23Pb8OXvF5qqaiIiIq/gVGAJCQmBXC6v0ZtSUFBQo9fFSqvVIjU1FeXl5Thz5gxycnIQExMDf39/hISE4NSpUzhz5gzGjh0LhUIBhUKBDRs24IsvvoBCocCpU6dqfV21Wo2AgAC7S7Oy9rAAgNlQ524apRyDbgipM8DZvaRchsWjuyLETw2VQvpRGM0iNuzmEBEREVFVCmd2VqlUiI+PR3p6Ou6++27b9vT0dIwbN67e5yqVSkRGSufS2bhxI8aMGQOZTIYuXbrg4MGDdvsuXrwYpaWleP3115t/qMdRiirzcEw6+wBzHe7oGoo7KoeRzl8ux+BXtmPfmUsovKpHiF/TvAcREVFL51RgAYD58+dj6tSp6NOnDwYOHIi1a9ciJycHc+bMASAN1eTm5trWWjl+/DgyMzPRv39/XL58GatWrcKhQ4ewfv16AIBGo0G3bt3s3iMoKAgAamx3K7kKgABArHcey/WIDPZB9w6BOJhbjO+O/IlJ/To2y/sQERG1NE4HlokTJ6KoqAhLly5FXl4eunXrhq1btyI6WloMLS8vz25NFrPZjJUrV+LYsWNQKpUYPnw4MjIyEBMT02SNcAlBkHpZTBV1rsXSFP7aLQwHc4vxzeF8BhYiIqJKgijWM4O0BSkpKUFgYCCKi4ubbz7Ly9GA7gowdy/Q7uZmeYuTBVcxYtWPUMoFZC25AwEaZbO8DxERkSdw9N9vnkvIGQ6sxXK9bmzvhxvb+8FoFrH9j4Jmex8iIqKWhIHFGQ6sxdIURt4iTcLddrj2tW2IiIhaGwYWZ1Rdi6UZ/fWWcADA9j8uQmfkQnJEREQMLM5wUQ9Ltw4B6BCkRYXRjB+PX2zW9yIiImoJGFic4YI5LIC0kvBfK1fKXbL5EE78Wdqs70dEROTpGFicYR0SMpQ1+1vNHX4juoT5o6BUj4lr9+DwheJmf08iIiJPxcDiDE2gdK1r5jNDA2jjq8In/xiAHpGBuFRmwOS1e3Aol6GFiIhaJwYWZ6grjw/XuyY4BPuq8OGs/ugbE4wSnQmLNh+ClyybQ0RE5BQGFmfYelhc19MRoFEiZUo8NEoZfjt3BTs4CZeIiFohBhZnuHBIqKoQPzWmDYwBAKz+7gR7WYiIqNVhYHGGbUjItYEFAB4c2om9LERE1GoxsDjDDUNCVuxlISKi1oyBxRmayh4WFw8JWVXtZeGy/URE1JowsDjDOiTkhh4WQOplub+yl2XuxwewZvtJWCzsaSEiIu/HwOIM65CQG+awWCWNuBl39YyA2SLi1W3HMDX1F1wsbd5TBRAREbkbA4sz3DwkBABalRyvT+qFFff0gFYpx88ni/B42q+c00JERF6NgcUZ1h4WUwVgMritDEEQcG+fKHw+dxBUchl2nSzEjmM8coiIiLwXA4szrHNYALcOC1l1CQvA9IQYAMBLW4/CZLa4tyAiIqJmwsDiDJkcUPlJt9008ba6ucNvRLCPEicLriJt3zl3l0NERNQsGFic5ca1WGoTqFVi3l9uAgC8ln4cpTqjmysiIiJqegwsznLjard1+fuAaHQK8UXhVQPe/vG0u8shIiJqcgwszvKAI4WqU8pleHpUFwDAe7uyUXiVhzkTEZF3YWBxlocNCVkldg1Fz6ggVBjNSN5+yt3lEBERNSkGFmd54JAQIB3q/ETizQCAD385i7ziCjdXRERE1HQYWJzloT0sADD4xhD0j20Dg8mCf39/0t3lEBERNRkGFmd54BwWK0EQ8MTIzgCAT/edw9miMjdXRERE1DQYWJzloUNCVn1j2uC2m9vBZBGxcNNB6Ixmd5dERER03RhYnOXBQ0JWC+/sAh+VHBmnijDj/b0oN5jcXRIREdF1YWBxVgsILF3CArB+Rj/4VoaW6al7kV+s4wkSiYioxVK4u4AWx8OHhKz6xrTBhpn9MT01E5lnLmHA8u/hq5Ijuq0v/j6gI+7r1xGCILi7TCIiIoewh8VZLaCHxSo+OhgfzuqPzqH+EASgzGDGkbwSLPr8EJ75/CAMJp4skYiIWgb2sDjLg48Sqk3PqCBse3wo9CYzzl+uwDeH8vGvb4/hk8xzOHWxDG9NiUcbX5W7yyQiIqoXe1icVbWHpQXNCVEr5LihnR/mDr8Rqff3hb9agczsS3hgXSZMZva0EBGRZ2NgcZZ1DotoBozl7q2lkYZ3aY9NDw9CgEaB384X452d2e4uiYiIqF4MLM5S+QKCXLrdQoaFanNTqD+eHXsLAOC19OM4WVDq5oqIiIjqxsDiLEGoMo/F8yfe1uf/9e6AYZ3bwWC24MnPfofZ0nKGuIiIqHVhYGmMFnJoc0MEQcDyCd3hr1bgQM4VrP7uOCwMLURE5IEYWBqjhR0pVJ/wQC0Wj4kDALzxw0lMTf0F5y+3zLk5RETkvRhYGkMTJF3rrriziiZzb58oPD+2KzRKGX4+WYSRr/2E/+w75+6yiIiIbBhYGsNLhoSsBEHA9IRYfD1vKPpEB6PMYMZTn/2Opz77rcGTJ4qiiE37zyPjZKGLqiUiotaIgaUxvGhIqKrYEF+kzR6IJxJvhkwA/rPvPCYkZyCnqO4hoh/+KMD8//yGmev3oVRndGG1RETUmjCwNEYLWp7fWXKZgEduvwkbZvRHG18VjuSVYMwbO/HdkT9r7GsyW/Dy138AACqMZmw9mOfqcomIqJVgYGkMLxsSqs3gm0Lw1WODcWvHIJToTJi1YR9e3faH3aHPn2Wdx4mCq7b7/83KdUepRETUCjQqsCQnJyM2NhYajQbx8fHYuXNnvfuvWbMGcXFx0Gq16Ny5MzZs2GD3+DvvvIMhQ4YgODgYwcHBGDFiBDIzMxtTmmt4cQ9LVeGBWqQ9OBDTB8UAANZsP4XJ7+xBdmEZyg0mrEo/DgB4cGgnCAKQeeYSzhaVubFiIiLyVk4HlrS0NCQlJWHRokU4cOAAhgwZglGjRiEnJ6fW/VNSUrBw4UI8//zzOHz4MF544QXMnTsXW7Zsse2zY8cOTJ48Gdu3b8fu3bvRsWNHJCYmIjfXQ7+xe+kcltqoFDI8f9cteH1SL/io5MjMvoS/rv4Js9bvQ0GpHh3b+OCJxM4YfGMIAOC/+6/9zC5cqUBBic5dpRMRkRcRRNG5M/j1798fvXv3RkpKim1bXFwcxo8fj+XLl9fYf9CgQUhISMCrr75q25aUlIR9+/Zh165dtb6H2WxGcHAw3nzzTUybNs2hukpKShAYGIji4mIEBAQ40yTnHd4MfHo/0HEgMOOb5n0vD3LuUjme+fwgdp64dkTQG5NvxdieEfjfr7mYt/FXRAZr8dOTw/HlwTw8nvYrArVKfDf/Np4RmoiIauXov99O9bAYDAZkZWUhMTHRbntiYiIyMjJqfY5er4dGo7HbptVqkZmZCaOx9qNKysvLYTQa0aZNmzpr0ev1KCkpsbu4TCsZEqouqo0PNszoh3/9rSfa+atxe5f2GN09HACQ2DUM/moFzl+uwOL/HcK8jQdgtoi4VGbAv78/4ebKiYiopXMqsBQWFsJsNiM0NNRue2hoKPLz82t9zsiRI/Huu+8iKysLoihi3759SE1NhdFoRGFh7Wt3LFiwAB06dMCIESPqrGX58uUIDAy0XaKiopxpyvVpRUNC1QmCgHviI7F30Qi8d38fyGQCAECrkmN0Dym8fPxLDkQRGHKTNEz04Z6zOH3xap2vSURE1JBGTboVBMHuviiKNbZZLVmyBKNGjcKAAQOgVCoxbtw4TJ8+HQAgl8tr7L9ixQp88skn2LRpU42emaoWLlyI4uJi2+XcOReuzKqu7GHx4qOEHFH9Z35PfKTt9j+GxGLDjH74S5f2MFlE2+HPREREjeFUYAkJCYFcLq/Rm1JQUFCj18VKq9UiNTUV5eXlOHPmDHJychATEwN/f3+EhITY7fuvf/0Ly5Ytw7fffosePXrUW4tarUZAQIDdxWU0VQKLpf6VYFuT+OhgLBzVBS/d3Q3P3BkHQRCw8M4ukMsEfHvkT/xyusjdJRIRUQvlVGBRqVSIj49Henq63fb09HQMGjSo3ucqlUpERkZCLpdj48aNGDNmDGSya2//6quv4sUXX8Q333yDPn36OFOW62mqhCN9qfvq8DCCIGD2bTfg7/2jbb0vN7b3x6S+0nDdgk0H8fXBPJjMFneWSURELZDC2SfMnz8fU6dORZ8+fTBw4ECsXbsWOTk5mDNnDgBpqCY3N9e21srx48eRmZmJ/v374/Lly1i1ahUOHTqE9evX215zxYoVWLJkCT7++GPExMTYenD8/Pzg5+fXFO1sWgo1oNAAJp008VYb5O6KPNrjd9yMrw/lI7uwDA99tB/hgRr8vX9HTOrXESF+aneXR0RELYDTgWXixIkoKirC0qVLkZeXh27dumHr1q2Ijo4GAOTl5dmtyWI2m7Fy5UocO3YMSqUSw4cPR0ZGBmJiYmz7JCcnw2Aw4J577rF7r+eeew7PP/9841rW3NQBUmBp5fNYHBHip8bX84bgg91n8UlmDvKKdfjXt8fx7+9PYkyPcEzsG4Xe0cFQyrnwMhER1c7pdVg8lUvXYQGAN+KBopPA9K1ATELt+1z4FdiXCty+GPBr3/w1tQC6ynMOrd99Fr+du2Lb7qdWYECnNujWIRA+Kjm0SjnkMhnMogiLRYRMJsBXJYePSgG1QgZUzvc1mCwo1ZlQUmGEyWJBgEaJQK0SAVrpOlCrhFohQ6nehKs6E3RGM+QyAXKZAIsoorjCiCvlRlzVmwBIL2sRpXMjlRvMMJot8FHK4aNWSO9fea1SyHBVZ0JxhfRcs0WERQREiNAo5NBWtkGjlG5rFDLIZQKkkTIBMkEaQpMJgADrdkBvMqNML723NJld2l8QpNoEQYBCLkAtl16vqMyAC1cqkF+sg9FsgSBI+/qpFQjUKhHko4JMAIxmCwxmERqFDME+KgT5KGERgTKDCeV6MwQBUCtk0CjluKo3oaBUj4uleoiiCB+VAn5qOQRBkF7HZIFGKUeInxrt/NVQygVcrfx8rZ+z9TPRKOXQKGXXrhVyyGTS60gXUbo2SbcNldsBQKuUw0clh0Iug8Fkgc5ohlkUoVVKn61WVfn5Ku0/b1EUkXulAucvSwsXluqlNppFETe080OXMH9EBGmRXXgVx/KvIvdKOYJ9VGjnr0YbXxXKDWZc1ZtQrjdBJhMgFwQoFTIE+yjRxleNQK0SZXoTLpcbUKozQauUI0CrgK9aAb3RgjKDCWWV74fKP6/qyrb4qhTQ2q5lMJpFVBjN0BnMqDBWXgxmWCqfV/Wvs/WmWPl7Zn1MrLKjaH282v1rt6+9oKzyd0WtkMNfo4C/RgFRBC6XG3Cl3Cj9/FRy+CjlUCpklb9/0s+lvb8G7fzVkMmAvCs65BXrcFVvglohg0ohg1j5/1ZxhRF6owVKhQwqufSYSiGT9pPLoFbKoJLLbdtVchkslT+/C1cqcFVnQodgLaLb+iIsUAOjyQKdyQydUfp9qDCaoTdeu68zmqGr/F0xmCyQCdL/60q5AH+NEgFaBfzUShhMFpQbTNCZLFDIBKjkssoaBSgr/98qN5hRqjOiTG+Gr1qOQK1K+nuilEEpk0EhFypfR3pfEdc+26t6M4orjCipMEIURchlMshlsNUjlwnXbgsCZDLpb4H1Z2J93Pp3Qi4IkMsr65TLcFVvREGJHgWlesgE6UthWz81fNVyCNX/vgjS74DJIsJskf5/M1vEGvflMgEBWiUCNEpolXJYROlxQYD0/69CDrVShja+qib/cunov99O97BQJUfWYvn5deDwJiAwErjtKdfU5eE0Sjkm9I7EhN6R+PXcFXyw+yx++ONPXC434rujBfjuaIG7SyQiojp8Omcg+sbUvUZac2JgaSxNkHRdXs+RL8XnpesLB5q9nJaoV1QQekUFwWIRcSSvBLtOFiLnUrntm5LRLErfLGQCTBbpm0y5QfrmZKWwfnPSKKCQCSip7G0prjCiRFf5Dc9kgZ9aAX+1AprKbw6mym8OQVqpt8FPrbD1cggQKntGpG8zOqO118Nku9abLPDXKBCgUcJPo4BCJoPM1ktikb41V35btn5zFkXAIoq2b8iWymZU3aZRSr1IWqUMssqCrN+Mrd+WTRapl8NoFhHso0REkBbhgZrK3gXALIoo05twpdyIKxXS4owquQCFTIZyoxnF5QZcLjdCLhPgq5beD4Dtm6pWJUc7fzXa+6uhkAm4qjejTG+CCBEqhRxKuQCd0YyLpdI3PJNZtH1D91Mr4KeRPk+5DFW++VqgN0mficki2r5tK+UyKCu/1Vq/PSrkUrsrKn/eJosFaoUcaoUMMplg+/2osH2+FrvP2iKK6BCkRWSwFmGBGvhrlPBVyWERgRMFV/FHXgnyS3SIaeuLm0P9EdVGi5IKEwpKdbhSboSPSg5/jRI+KjlESN8y9SYLrpQbUXRVj+IKI/w0CgT7qOCnVkBnNKNEJ/UsaZQy+KoV8FFJv4/W3ymd0Ywyg1RjmcFka5tSLoNWJavRa6Sw/jJV/kbabgnXtgiVvXPW7VV/fyv/q3xMqHJb2m79XTKLIvRGC0p1RpTqTJDJgGAfqSdBKZeh3GCy9TRaO2fKDCYUlhpQeFUPiyiivb8GYYEaBGiVMJjM0JssEAAEVb6ORimDwST1nhlM0v+/hsqeOoPJAn3Va7P03PBADSKCtPCrXIwy51I5Ckp1UMll0KrkUCuq9txZe9dkUFf2BGiU1p6ea/+/XNVbe0TNUCtk8FFJv1NmC6SePZPFrufPV33t96DcYMaVcgOuVBhhMFlgMkt/Q6ReSakOuUywfUY+Krmtp1cuCLaeYnNlr4W198Jskf7/ly6AxSLa3Ret+4mA2WKBsfJz9FHJERqgQXt/NSyiiMKr0s+jwmCGWPVvSuXrCAKgkEl/A6w9TvLK+4rK2yaziBKd9HdTZ7TY/vZaROn33/r/nUZRczkSV2FgaazgGOn6cnbd+5RckK5z9zd7OS2ZTCagW4dAdOsQ2CyvX986QUTUONZ/XBWce9ZquHsGCX/TGqvtDdJ10cnaH7eYgdI86fbVfKAkzzV1UQ0MK0RNTyYTGFZaGWmOnPv+nvK3rbHa3ihdF52u/fGyi4BYZVE5DgsRERE1GgNLY7Wp7GG5dMp+Kr9VSa79fQYWIiKiRmNgaazgaECQA8bya0M/VVUfArrAeSxERESNxcDSWHKlFFoAoOhUzcetE24DKk8IeOFA7T0xRERE1CAGluvRpp6Jt6WVgeWmEYBMKR3+XOzCM0oTERF5EQaW62GdeHupnh6W4BggtKt0m/NYiIiIGoWB5XrYDm2ub0ioAxBxq3Sb67EQERE1CgPL9WjTSbquL7D4hwMRvaXb7GEhIiJqFK50ez2sQ0KXs6WF4mSVSxaL4rUjhwIirp136MKv0mNcyIyIiMgp7GG5HoGRgFwFmA32E2p1V6TDnQEpsLSPA+RqQF8MXKpjoTkiIiKqEwPL9ZDJax8Wsq7Bog0GlFrpEOiw7tI2zmMhIiJyGgPL9WpTy8TbqhNuraIHSde/vMX1WIiIiJzEwHK92lb2sFQ9tLm0yoRbq4GPAEpfIHcfcPhz19VHRETkBRhYrpftJIi19bBEXNvmHwokPCbd/v4FwKR3TX1ERERegIHletW22q31xIdVAwsg9bL4hQKXzwB733NJeURERN6AgeV6WXtYruQAJoN0u6TKIc1Vqf2A4c9It39aAVRccUmJRERELR0Dy/XyD5Pmpohm4MpZaZtt0biImvv3mgK0iwMqLgP7Ul1XJxERUQvGwHK9BKHKoc2Vw0KltcxhsZIrgL4zpduntzd/fURERF6AgaUphPeQrg/9FzBWSL0nABAQXvv+sbdJ1zm/AEZd89dHRETUwjGwNIX+s6XrQ/8Fzvws3Vb6AJqg2vcPuQnwCwPMeuB8pktKJCIiaskYWJpCeE/gxjsA0QJsq5xU6x9e9zmDBAGIHSrdzv7JNTUSERG1YAwsTWXoE9J14THpurb5K1UxsBARETmMgaWpdBwARA++dt/RwJKbBehLm68uIiIiL8DA0pSG/vPa7YYCS3A0EBQNWExAzp7mrYuIiKiFY2BpSp2GAx3ipdvWQ53rYxsW+rH5aiIiIvICDCxNSRCAez8A/voy0GNiw/tbD2/mPBYiIqJ6MbA0tcAOwICHAIW64X1jh0jXeb8D5Zeaty4iIqIWjIHFnfzDgJDOAETg7M/uroaIiMhjMbC4W6dh0nXmO4AourUUIiIiT8XA4m4DHwbkamni7R9fursaIiIij8TA4m7BMUDCY9Ltbc9I5yIiIiIiOwwsnmDw40BAB+BKDpDxprurISIi8jgMLJ5A5QvcsVS6vWsVUJzr3nqIiIg8DAOLp+j2/4COAwFjObAn2d3VEBEReRQGFk8hCEC/f0i3T+9waylERESehoHFk1hXvv3zEHD1ontrISIi8iAMLJ7ENwQI7Sbd5vmFiIiIbBhYPI3t/EIMLERERFYMLJ7GuvLtaQYWIiIiq0YFluTkZMTGxkKj0SA+Ph47d+6sd/81a9YgLi4OWq0WnTt3xoYNG2rs89///hddu3aFWq1G165d8fnnnzemtJYvehAgUwBXzgKXz7i7GiIiIo/gdGBJS0tDUlISFi1ahAMHDmDIkCEYNWoUcnJyat0/JSUFCxcuxPPPP4/Dhw/jhRdewNy5c7FlyxbbPrt378bEiRMxdepU/Pbbb5g6dSruvfde/PLLL41vWUul9gM69JFus5eFiIgIACCIonNn3Ovfvz969+6NlJQU27a4uDiMHz8ey5cvr7H/oEGDkJCQgFdffdW2LSkpCfv27cOuXbsAABMnTkRJSQm+/vpr2z5//etfERwcjE8++cShukpKShAYGIji4mIEBAQ40yTPs30Z8OMrwC0TgL+tc3c1REREzcbRf7+d6mExGAzIyspCYmKi3fbExERkZGTU+hy9Xg+NRmO3TavVIjMzE0ajEYDUw1L9NUeOHFnna1pft6SkxO7iNazzWLJ/AiwWt5ZCRETkCZwKLIWFhTCbzQgNDbXbHhoaivz8/FqfM3LkSLz77rvIysqCKIrYt28fUlNTYTQaUVhYCADIz8936jUBYPny5QgMDLRdoqKinGmKZ+vQB1D6AOWFQMERd1dDRETkdo2adCsIgt19URRrbLNasmQJRo0ahQEDBkCpVGLcuHGYPn06AEAulzfqNQFg4cKFKC4utl3OnTvXmKZ4JoVKmnwLcNVbIiIiOBlYQkJCIJfLa/R8FBQU1OghsdJqtUhNTUV5eTnOnDmDnJwcxMTEwN/fHyEhIQCAsLAwp14TANRqNQICAuwuXuXGEdL1of+6tw4iIiIP4FRgUalUiI+PR3p6ut329PR0DBo0qN7nKpVKREZGQi6XY+PGjRgzZgxkMuntBw4cWOM1v/322wZf06t1uweQKYEL+4H8Q+6uhoiIyK0Uzj5h/vz5mDp1Kvr06YOBAwdi7dq1yMnJwZw5cwBIQzW5ubm2tVaOHz+OzMxM9O/fH5cvX8aqVatw6NAhrF+/3vaa8+bNw9ChQ/HKK69g3Lhx+N///ofvvvvOdhRRq+TXDug8Cjj6BXDgA2DUK+6uiIiIyG2cnsMyceJErF69GkuXLkWvXr3w008/YevWrYiOjgYA5OXl2a3JYjabsXLlSvTs2RN33HEHdDodMjIyEBMTY9tn0KBB2LhxI9atW4cePXrg/fffR1paGvr373/9LWzJet8vXf+eBhh17q2FiIjIjZxeh8VTedU6LFYWM7C6B1ByHvh/7wHd73F3RURERE2qWdZhIReTyYFe90m3D3zg3lqIiIjciIHF0906BYAgHd58+ay7qyEiInILBhZPFxwNdLpNuv3rR+6thYiIyE0YWFqCW6dK17+nAd4x5YiIiMgpDCwtQec7AZUfcPkMcC7T3dUQERG5HANLS6DyAeLGSrd/T3NvLURERG7AwNJS9LhXuj68CTAZ3FsLERGRizGwtBSxtwF+oUDFZeDkd+6uhoiIyKUYWFoKmRzo/jfpdtVhIbOJE3GJiMjrMbC0JNZhoWNfA8e/BT68B3ixLbAn2b11ERERNTMGlpYkrAfQrgtg1gMf/w04WXmG6z+2urcuIiKiZsbA0pIIQuXKtwDkKuCmkdLtohPuq4mIiMgFFO4ugJw0YC4Q0hkI6y4d7vxyR+Dqn4CuBNB4yUkfiYiIqmEPS0sjkwE3JwIB4YAmEPBtL20vOuneuoiIiJoRA0tL1/ZG6ZqBhYiIvBgDS0sXwsBCRETej4GlpWt7k3RdyIm3RETkvRhYWjoOCRERUSvAwNLShVT2sBSd4oq3RETktRhYWrqgaECQA8YyoDTP3dUQERE1CwaWlk6hAoJjpNucx0JERF6KgcUb2IaFGFiIiMg7MbB4A9vE21PurYOIiKiZMLB4A2tg4ZAQERF5KQYWb8BDm4mIyMsxsHgD6xyWK2cBk969tRARETUDBhZv4BcKqPwA0QJcynZ3NURERE2OgcUbCAKHhYiIyKsxsHgLHtpMRERejIHFW1h7WM5lcol+IiLyOgws3uKGvwAQgGNbgYx/u7saIiKiJsXA4i2i+gIjl0m3058FDm1ybz1ERERNiIHFmwx8GOg/R7r9+Rwg5xf31kNERNREGFi8zchlQJcxgFkPbJ4DmAzuroiIiOi6MbB4G5kcuPstaW2WS6eBzLXuroiIiOi6MbB4I7U/cPsS6faPK4CyQvfWQ0REdJ0YWLxVr/uAsB6AvhjYvszd1RAREV0XBhZvJZMDf10u3c5aB/x5xL31EBERXQcGFm8WMxiIGyudY+iH/3N3NURERI3GwOLtrHNZjn8NFOe6txYiIqJGYmDxdu06A9EJUi/LgQ/dXQ0REVGjMLC0BvHTpev9GwCL2a2lEBERNQYDS2sQdxegCQJKzgMnv3d3NURERE5rVGBJTk5GbGwsNBoN4uPjsXPnznr3/+ijj9CzZ0/4+PggPDwcDzzwAIqKiuz2Wb16NTp37gytVouoqCg8/vjj0Ol0jSmPqlNqpMOcASDrfen6zC5g3Z3AvlS3lUVEROQopwNLWloakpKSsGjRIhw4cABDhgzBqFGjkJOTU+v+u3btwrRp0zBz5kwcPnwYn376Kfbu3YtZs2bZ9vnoo4+wYMECPPfcczh69Cjee+89pKWlYeHChY1vGdnrfb90ffwbYNsiYP1Y4OzPQPpzgLHCvbURERE1wOnAsmrVKsycOROzZs1CXFwcVq9ejaioKKSkpNS6/549exATE4PHHnsMsbGxGDx4MGbPno19+/bZ9tm9ezcSEhJw3333ISYmBomJiZg8ebLdPtXp9XqUlJTYXage7bsAHQcCohnY/aY0CVeuAvQlwLGv3V0dERFRvZwKLAaDAVlZWUhMTLTbnpiYiIyMjFqfM2jQIJw/fx5bt26FKIr4888/8dlnn2H06NG2fQYPHoysrCxkZmYCAE6fPo2tW7fa7VPd8uXLERgYaLtERUU505TWqW9lr5bSF7h7LTDwEen+7/9xX01EREQOUDizc2FhIcxmM0JDQ+22h4aGIj8/v9bnDBo0CB999BEmTpwInU4Hk8mEu+66C2+88YZtn0mTJuHixYsYPHgwRFGEyWTCQw89hAULFtRZy8KFCzF//nzb/ZKSEoaWhnS/B9AGASGdgaAooOAPYNcq4GS6dL4h3xB3V0hERFSrRk26FQTB7r4oijW2WR05cgSPPfYYnn32WWRlZeGbb75BdnY25syZY9tnx44deOmll5CcnIz9+/dj06ZN+PLLL/Hiiy/WWYNarUZAQIDdhRxw4wgprADSMFF4T8BiAg5/7t66iIiI6uFUD0tISAjkcnmN3pSCgoIavS5Wy5cvR0JCAp588kkAQI8ePeDr64shQ4bg//7v/xAeHo4lS5Zg6tSptom43bt3R1lZGR588EEsWrQIMhmPvm42PSYBeb8Bv20E+v3D3dUQERHVyqkkoFKpEB8fj/T0dLvt6enpGDRoUK3PKS8vrxE45HI5AKlnpr59RFG07UPNpNv/AwQZkLsPKDzp7mqIiIhq5XTXxfz58/Huu+8iNTUVR48exeOPP46cnBzbEM/ChQsxbdo02/5jx47Fpk2bkJKSgtOnT+Pnn3/GY489hn79+iEiIsK2T0pKCjZu3Ijs7Gykp6djyZIluOuuu2zhhpqJfyhww+3S7YOcfEtERJ7JqSEhAJg4cSKKioqwdOlS5OXloVu3bti6dSuio6MBAHl5eXZrskyfPh2lpaV488038c9//hNBQUG4/fbb8corr9j2Wbx4MQRBwOLFi5Gbm4t27dph7NixeOmll5qgidSgHhOBk99Ji8oNegxQ+7m7IiIiIjuC6CVjLiUlJQgMDERxcTEn4DrLZADW9AUunwGGLQSG1X10FhERUVNy9N9vzmYlQKEC/vKcdPvn14HS2g9RJyIichcGFpLccjfQoQ9gLAe2L3N3NURERHYYWEgiCEDi/0m3D3wA5O4Hyi8BVy8CDY0aHvqvdDJFIiKiZuL0pFvyYtEDgS5jgD++BN4Zfm37LXcDf3u/9ufk/QZ8NgPQBAJPZQMyHtVFRERNjz0sZO+OpYC2jf22P76SJubW5o+t0rWuGCg83ry1ERFRq8XAQvba3gA8eRJY9CewpEjqOTEbgItHa9//+DfXbl844JoaiYio1WFgoZpkckCpAeQKILyXtO3CrzX3K8kD8qpsz93vguKIiKg1YmCh+kX0kq6rBhMra++KUDlvhT0sRETUTBhYqH62HpZawsjxbdJ1z0nSdf7Buue6EBERXQcGFqqftYflz8P2YcRYAZzeId3uPwdQBwJmfd1zXYiIiK4DAwvVLzi29om32T8BpgogIBII634t2HBYiIiImgEDC9VPEGqfeHvsa+m681+lfTr0lu5z4i0RETUDBhZqWPWJt6J4bf7KzaMq97lVumYPCxERNQMGFmpY9Ym3p74HSi8ASl8gZrC0zRpYCo4ARp3LSyQiIu/GwEINqzrx1qgD0ivP7Bx/v7ReCwAERgE+IYDFBPx5yC1lEhGR92JgoYZVnXj73fNSIFEHAkOfvLaPIHBYiIiImg0DCzWs6sTbX1Kk66H/BHyqnXPIGlg48ZaIiJoYAws5xjosBACBHYF+s2vuYz1S6MS3QPqzwIEPgSs5LimPiIi8m8LdBVALYe1hAYC/LLk2d6WqyL6AXAWUFwI/vy5t82kLzPsNUPu7pEwiIvJO7GEhx8QOBbRtgNjbgG731L6Pbwjw4A5g1KtAvwcBv1CgvAjIet+VlRIRkRcSRFEU3V1EUygpKUFgYCCKi4sREBDg7nK8k9kkXcsd7JjbvwH44lHAP0LqZVGomq82IiJqkRz995s9LOQ4ucLxsAIAPSYC/uHSmi0H/3Nte84v0oWIiMhBDCzUfBRqYMBD0u1dqwGLBdi5CkhNlC5733VreURE1HIwsFDzin9AWrOl6ATw/mjg+xeuPfbVP69NziUiIqoHjxKi5qUJAPrOBHatAnIyAAjAX18Gyi4CO/8lHf6c/RNgKJcOgdaXuLtiIiKqy7TNQId4t7w1Aws1vwEPAftSAZMeuOc9oMtoabvKV+pxOfmde+sjIiLHWCxue2sGFmp+fu2Bh/dIa7T4tr22fch8aUG6vN+AoI5AUDSgDXZbmURE1ICADm57awYWco2A8Nq333C7dCEiIqoHJ90SERGRx2NgISIiIo/HwEJEREQej4GFiIiIPB4DCxEREXk8BhYiIiLyeAwsRERE5PEYWIiIiMjjMbAQERGRx2NgISIiIo/HwEJEREQej4GFiIiIPB4DCxEREXk8rzlbsyiKAICSkhI3V0JERESOsv67bf13vC5eE1hKS0sBAFFRUW6uhIiIiJxVWlqKwMDAOh8XxIYiTQthsVhw4cIF+Pv7QxCEJnvdkpISREVF4dy5cwgICGiy1/Vkra3Nra29QOtrc2trL9D62tza2gt4T5tFUURpaSkiIiIgk9U9U8VrelhkMhkiIyOb7fUDAgJa9C9EY7S2Nre29gKtr82trb1A62tza2sv4B1trq9nxYqTbomIiMjjMbAQERGRx2NgaYBarcZzzz0HtVrt7lJcprW1ubW1F2h9bW5t7QVaX5tbW3uB1tdmr5l0S0RERN6LPSxERETk8RhYiIiIyOMxsBAREZHHY2AhIiIij8fAQkRERB6PgaUBycnJiI2NhUajQXx8PHbu3OnukprE8uXL0bdvX/j7+6N9+/YYP348jh07ZrePKIp4/vnnERERAa1Wi2HDhuHw4cNuqrhpLV++HIIgICkpybbNG9ubm5uLKVOmoG3btvDx8UGvXr2QlZVle9yb2mwymbB48WLExsZCq9WiU6dOWLp0KSwWi22flt7en376CWPHjkVERAQEQcDmzZvtHnekfXq9Ho8++ihCQkLg6+uLu+66C+fPn3dhK5xTX5uNRiOefvppdO/eHb6+voiIiMC0adNw4cIFu9doSW1u6Gdc1ezZsyEIAlavXm23vSW11xkMLPVIS0tDUlISFi1ahAMHDmDIkCEYNWoUcnJy3F3adfvxxx8xd+5c7NmzB+np6TCZTEhMTERZWZltnxUrVmDVqlV48803sXfvXoSFheGOO+6wnWiypdq7dy/Wrl2LHj162G33tvZevnwZCQkJUCqV+Prrr3HkyBGsXLkSQUFBtn28qc2vvPIK3nrrLbz55ps4evQoVqxYgVdffRVvvPGGbZ+W3t6ysjL07NkTb775Zq2PO9K+pKQkfP7559i4cSN27dqFq1evYsyYMTCbza5qhlPqa3N5eTn279+PJUuWYP/+/di0aROOHz+Ou+66y26/ltTmhn7GVps3b8Yvv/yCiIiIGo+1pPY6RaQ69evXT5wzZ47dti5duogLFixwU0XNp6CgQAQg/vjjj6IoiqLFYhHDwsLEl19+2baPTqcTAwMDxbfeestdZV630tJS8aabbhLT09PF2267TZw3b54oit7Z3qefflocPHhwnY97W5tHjx4tzpgxw27bhAkTxClTpoii6H3tBSB+/vnntvuOtO/KlSuiUqkUN27caNsnNzdXlMlk4jfffOOy2hureptrk5mZKQIQz549K4piy25zXe09f/682KFDB/HQoUNidHS0+Nprr9kea8ntbQh7WOpgMBiQlZWFxMREu+2JiYnIyMhwU1XNp7i4GADQpk0bAEB2djby8/Pt2q9Wq3Hbbbe16PbPnTsXo0ePxogRI+y2e2N7v/jiC/Tp0wd/+9vf0L59e9x666145513bI97W5sHDx6M77//HsePHwcA/Pbbb9i1axfuvPNOAN7X3uocaV9WVhaMRqPdPhEREejWrZtXfAaA9LdMEARbT6K3tdlisWDq1Kl48sknccstt9R43NvaW5XXnK25qRUWFsJsNiM0NNRue2hoKPLz891UVfMQRRHz58/H4MGD0a1bNwCwtbG29p89e9blNTaFjRs3Yv/+/di7d2+Nx7yxvadPn0ZKSgrmz5+PZ555BpmZmXjsscegVqsxbdo0r2vz008/jeLiYnTp0gVyuRxmsxkvvfQSJk+eDMA7f8ZVOdK+/Px8qFQqBAcH19jHG/6u6XQ6LFiwAPfdd5/t7MXe1uZXXnkFCoUCjz32WK2Pe1t7q2JgaYAgCHb3RVGssa2le+SRR/D7779j165dNR7zlvafO3cO8+bNw7fffguNRlPnft7SXkD6JtanTx8sW7YMAHDrrbfi8OHDSElJwbRp02z7eUub09LS8OGHH+Ljjz/GLbfcgl9//RVJSUmIiIjA/fffb9vPW9pbl8a0zxs+A6PRiEmTJsFisSA5ObnB/Vtim7OysvD6669j//79TtfeEttbHYeE6hASEgK5XF4jkRYUFNT4BtOSPfroo/jiiy+wfft2REZG2raHhYUBgNe0PysrCwUFBYiPj4dCoYBCocCPP/6If//731AoFLY2eUt7ASA8PBxdu3a12xYXF2ebNO5tP+Mnn3wSCxYswKRJk9C9e3dMnToVjz/+OJYvXw7A+9pbnSPtCwsLg8FgwOXLl+vcpyUyGo249957kZ2djfT0dFvvCuBdbd65cycKCgrQsWNH29+xs2fP4p///CdiYmIAeFd7q2NgqYNKpUJ8fDzS09Pttqenp2PQoEFuqqrpiKKIRx55BJs2bcIPP/yA2NhYu8djY2MRFhZm136DwYAff/yxRbb/L3/5Cw4ePIhff/3VdunTpw/+/ve/49dff0WnTp28qr0AkJCQUONQ9ePHjyM6OhqA9/2My8vLIZPZ/0mTy+W2w5q9rb3VOdK++Ph4KJVKu33y8vJw6NChFvsZWMPKiRMn8N1336Ft27Z2j3tTm6dOnYrff//d7u9YREQEnnzySWzbtg2Ad7W3BjdN9m0RNm7cKCqVSvG9994Tjxw5IiYlJYm+vr7imTNn3F3adXvooYfEwMBAcceOHWJeXp7tUl5ebtvn5ZdfFgMDA8VNmzaJBw8eFCdPniyGh4eLJSUlbqy86VQ9SkgUva+9mZmZokKhEF966SXxxIkT4kcffST6+PiIH374oW0fb2rz/fffL3bo0EH88ssvxezsbHHTpk1iSEiI+NRTT9n2aentLS0tFQ8cOCAeOHBABCCuWrVKPHDggO2IGEfaN2fOHDEyMlL87rvvxP3794u333672LNnT9FkMrmrWfWqr81Go1G86667xMjISPHXX3+1+1um1+ttr9GS2tzQz7i66kcJiWLLaq8zGFgasGbNGjE6OlpUqVRi7969bYf9tnQAar2sW7fOto/FYhGfe+45MSwsTFSr1eLQoUPFgwcPuq/oJlY9sHhje7ds2SJ269ZNVKvVYpcuXcS1a9faPe5NbS4pKRHnzZsnduzYUdRoNGKnTp3ERYsW2f3D1dLbu3379lr/v73//vtFUXSsfRUVFeIjjzwitmnTRtRqteKYMWPEnJwcN7TGMfW1OTs7u86/Zdu3b7e9Rktqc0M/4+pqCywtqb3OEERRFF3Rk0NERETUWJzDQkRERB6PgYWIiIg8HgMLEREReTwGFiIiIvJ4DCxERETk8RhYiIiIyOMxsBAREZHHY2AhIiIij8fAQkRERB6PgYWIiIg8HgMLERERebz/D+1n3FCgFwujAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses.get(), label='Train')\n",
    "plt.plot(valid_losses.get(), label='Valid')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_UcLyHcQMGu0",
    "outputId": "4b56200c-1dc4-4286-b51a-d19e9c75ddd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0613160106'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E6-6g-sW3zeg"
   },
   "source": [
    "We can see that with Sigmoid the model seems to perform slightly worse, but this should not be a big problem. Then the decision might depend more on whether the use of it is common and justifiable. I don't think it's common, and the use of it does not seem to be analytically necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNJ0DAlaWrEE"
   },
   "outputs": [],
   "source": [
    "class ResAECluster(ResAE): \n",
    "    def __init__(self, input_dim=INPUT_DIM, inter_dim1=INTER_DIM_1, inter_dim2=INTER_DIM_2, inter_dim3=INTER_DIM_3, latent_dim=LATENT_DIM, output_dim=OUTPUT_DIM): \n",
    "        super().__init__(input_dim, inter_dim1, inter_dim2, inter_dim3, latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        org_size = x.size()\n",
    "        batch = org_size[0]\n",
    "        x = x.view(batch, -1)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        # mu, logvar = h.chunk(2, dim=1)\n",
    "        # z = self.reparameterise(mu, logvar)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFrvzaGC45Gi"
   },
   "outputs": [],
   "source": [
    "seq = \"_01_05\"\n",
    "tags = pd.read_csv(tags_name + seq + \".csv\")\n",
    "gsds = GroundedSoundDataset(tags, test_name + seq + \".npy\")\n",
    "eval_loader = DataLoader(gsds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QARr-C_qpBLb",
    "outputId": "acd5e8ab-1ef6-4968-c205-b437ecfd7b8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'model_english_0130021416_29_full'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXLqyT3PYFkR"
   },
   "outputs": [],
   "source": [
    "# model_name = last_model_name\n",
    "model_name = \"model_english_0130021416_13_full\"\n",
    "model_path = save_dir + model_name + \".pt\"\n",
    "state = torch.load(model_path)\n",
    "model = ResAECluster()\n",
    "model.load_state_dict(state)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "hiddens = None\n",
    "tags = None\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (s, e, t) in enumerate(eval_loader):\n",
    "        s = s.to(device)\n",
    "        hidden = model(s)\n",
    "        hidden = hidden.cpu().data.numpy()\n",
    "\n",
    "        if hiddens is not None: \n",
    "            hiddens = np.concatenate((hiddens, hidden), axis=0)\n",
    "            tags = np.concatenate((tags, t), axis=0)\n",
    "        else: \n",
    "            hiddens = hidden\n",
    "            tags = t\n",
    "num_phones = np.unique(tags).shape[0]\n",
    "kmeansmodel = KMeans(n_clusters=num_phones) # , random_state=0\n",
    "clusters = kmeansmodel.fit_predict(hiddens)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenclusters.npy\", clusters)\n",
    "np.save(save_dir + model_name + seq + \"_hiddenrepresentation.npy\", hiddens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzTuc2Mz6niT"
   },
   "outputs": [],
   "source": [
    "h, c, v = homogeneity_completeness_v_measure(tags, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ogsEovzEbpc",
    "outputId": "3cd43d32-f30c-4fb3-f5eb-945d6dd0ecc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_01_05 0.30813685860010276 0.2726217590636009 0.2892933823757265\n"
     ]
    }
   ],
   "source": [
    "print(seq, h, c, v) # trained on sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMFbNimpx-iJ"
   },
   "outputs": [],
   "source": [
    "# _17_24 0.3429902101084872 0.329164358854651 0.33593508938856537   # 256+8\n",
    "# _17_24 0.3071758873778334 0.2958512436337788 0.3014072290332542   # 128+4\n",
    "# _17_24 0.3048181747064378 0.303971996633573 0.3043944976042278    # 128+2\n",
    "# _17_24 0.3109960687106377 0.3020004935745723 0.3064322772063619   # 256+2, 2res\n",
    "# _17_24 0.27632046463064963 0.29796767719078493 0.28673608598337974    # 256+64+2, 2res, new model\n",
    "# _17_24 0.29619001674434664 0.30940705212658304 0.30265430485339223    # 256+64+4, 0res\n",
    "# _17_24 0.3394207670351701 0.3356821861468344 0.33754112484613674      # 256+64+4, 2res\n",
    "# _17_24 0.3246121630042821 0.3173438869288583 0.32093687897447765  # 256+3, 2res, not very bad. So we may try this. This is error, decoder only having 1 res\n",
    "# _17_24 0.3227539602867097 0.32256957773330264 0.3226617426690128  # 256+3, 2res\n",
    "# _17_24 0.3403517130774138 0.33762198107176034 0.33898135170147237 # 256+3, 1res\n",
    "# _17_24 0.3202704367215642 0.31097127191607643 0.3155523587925454  # 256+3, 0res\n",
    "\n",
    "\n",
    "# _01_05 0.30784101366300043 0.2717512535534188 0.28867252408265254"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gYDGP0Cdf1o"
   },
   "source": [
    "总的来说分成四个，神经网层来进行降维处理，得到的损失比较大，但是 hcv值倒是接近不过，如果能尽量的接近原作的模型结构，我们就不去动它了，所以可能目前来看最好的是保留两个降为层加上两个残差层，最后从256降到2，也许是最好的结果当然降到4也是可以的，都是比较低的维度，不过如果我们想要直接能够，在，可视的空间中画出这些点来，2或者3可能会比四更好一些。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nTTdgp_HokAn"
   },
   "source": [
    "从使用不同数量残插块儿的实验结果来看，是由一个残渣块，应该是最好的解决方式，使用零个或两个第三个都可能是都会使hcv值相对降低。由此来看在选择，隐性层纬度为三的情况下，我们应该选择适用一个参差款。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdQ9f85WY1K"
   },
   "source": [
    "### Conclusion\n",
    "Adding new data slightly improves the performance of the model in HCV score, in addition, shuffling the training data largely lowers the HGV score perhaps we should discuss this phenomenon and justify use no shuffling during training. Perhaps this is because of some sort of phonotactics or naturalness of sound streams. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kjoJ2fFKpmVC"
   },
   "source": [
    "Good news is that for the English model it performs similar well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjPWgjpid7PR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
