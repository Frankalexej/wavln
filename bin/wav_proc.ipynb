{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da7b2ab-2e43-4a4c-bff7-f1a2fe9cb7f9",
   "metadata": {},
   "source": [
    "# Wav Preprocessing\n",
    "Preproc for wavLearning, including stat, random cutting, aligned cutting, sound2tensor\n",
    "\n",
    "\n",
    "Let's call it wavLearning, but in fact, after checking, I still found that mfcc was the choice for many. \n",
    "\n",
    "No! Direct usage of MFCC does not really work, the problem is that we cannot transfer between MFCC and audio with no information loss, therefore, the mfcc-to-audio output is quite noisy compared with the input. Therefore I referred to other sound autoencoder works for how they dealt with this problem. (the problem to directly work with audio input is that they contain to many frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e058b-c68e-41f6-95fe-7d4e3d1c16a7",
   "metadata": {},
   "source": [
    "- the extraction of alignment infomation done in alignment_extract.ipynb\n",
    "- length stats done in length_stat.ipynb\n",
    "- this notebook will cut sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ed1d9-dce7-473e-8b9f-08e2b3ca91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import os\n",
    "import math\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7ed1d3-4ec7-436c-a273-6b846f3119b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "from mio import *\n",
    "from sampler import *\n",
    "from my_utils import *\n",
    "from sound_proc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcee66e-e8e4-49dc-afa6-01edb16055d9",
   "metadata": {},
   "source": [
    "## Load Distribution Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fde0dea-a96a-405e-b572-6c49a04f9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_gamma_params(\"phones_length_gamma.param\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfacae-8759-4db4-b7a8-c7890d43ddf9",
   "metadata": {},
   "source": [
    "## Define Open and Cut Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d058f4-1b9f-4f26-bd9c-c64447a5aed5",
   "metadata": {},
   "source": [
    "### Ground Truth Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2ec99a-58c5-4e76-abcd-185a1d248e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_cut_phones(wave_path, annos_path, params):\n",
    "    sp = Sound_Proc()\n",
    "    filtered_df = filter_tokens_and_get_df(annos_path, keepSIL=False)\n",
    "    flat_starts, flat_ends, c_duration = filtered_df[\"start_time\"].to_numpy(), filtered_df[\"end_time\"].to_numpy(), filtered_df[\"duration\"].to_numpy()\n",
    "    \n",
    "    rec, sample_rate = torchaudio.load(wave_path)\n",
    "    cut_recs = sp.cut_rec(rec, flat_starts, flat_ends)\n",
    "    \n",
    "    tokens = filtered_df[\"token\"].to_numpy()\n",
    "    \n",
    "    cst, cet = flat_starts, flat_ends\n",
    "    \n",
    "    # Framify\n",
    "    # Create a dictionary with the three lists as values and the column names as keys\n",
    "    data = {'rec': os.path.splitext(os.path.basename(wave_path))[0], \"idx\": list(map(\"{:08d}\".format, range(len(c_duration)))), 'start_time': cst, 'end_time': cet, 'token': tokens, 'duration': c_duration}\n",
    "    # Create a Pandas DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return cut_recs, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4857c8-be44-4f42-9ec7-0955e66013df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr, df = open_and_cut_phones(os.path.join(wav_path, \"s0101a.wav\"), os.path.join(phones_extract_path, \"s0101a.csv\"), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9353d3-bd3e-4ea4-8f87-3b898a44beaa",
   "metadata": {},
   "source": [
    "### Random Sampling Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dafcd58-9b46-443e-b3ca-dd5c3f2d14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_cut_phones_random_sampling(wave_path, anno_path, params): \n",
    "    sp = Sound_Proc()\n",
    "    metadata = torchaudio.info(wave_path)\n",
    "    rec_len = sp.get_rec_length(metadata)\n",
    "    samples = gamma_samples_sum(rec_len, params, shift=0.0125)\n",
    "\n",
    "    flat_starts, flat_ends = samples2idx_with_se(samples)\n",
    "    \n",
    "    rec, sample_rate = torchaudio.load(wave_path)\n",
    "    cut_recs = sp.cut_rec(rec, flat_starts, flat_ends)\n",
    "    \n",
    "    cst, cet = flat_starts, flat_ends\n",
    "    c_duration = [cet[i] - cst[i] for i in range(len(cst))]\n",
    "    \n",
    "    # Framify\n",
    "    # Create a dictionary with the three lists as values and the column names as keys\n",
    "    data = {'rec': os.path.splitext(os.path.basename(wave_path))[0], \"idx\": list(map(\"{:08d}\".format, range(len(c_duration)))), 'start_time': cst, 'end_time': cet, 'token': \"\", 'duration': c_duration}\n",
    "    # Create a Pandas DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return cut_recs, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39c8f6-498c-40fa-beca-8f1612ca6c70",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "To make processing easier, both open-and-cut functions return the same output: `cut_recs` (a list of NumPy arrays) and a `token_list` (a Pandas DataFrame).\n",
    "\n",
    "In order to speed up the processing time, you can use multiprocessing to plan the work and distribute it to the two open-and-cut functions. This will allow each function to work on a separate process, which can be run simultaneously, potentially reducing the overall processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cb8f30-045c-4221-ac88-1866adb404fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaboration_single_work(my_work_pool, fun, my_wave_dir, my_anno_dir, my_save_dir, my_log_dir, my_params): \n",
    "    print(\"Working from {} to {}\".format(my_work_pool[0], my_work_pool[-1]))\n",
    "    for rec_name in my_work_pool: \n",
    "        rec_raw, ext = os.path.splitext(rec_name)\n",
    "        cut_recs, corr_df = fun(\n",
    "            os.path.join(my_wave_dir, rec_name), \n",
    "            os.path.join(my_anno_dir, rec_raw + \".csv\"),\n",
    "            my_params\n",
    "        )\n",
    "        save_cut_waves_and_log(\n",
    "            save_dir=my_save_dir, \n",
    "            log_dir=my_log_dir, \n",
    "            cut_list=cut_recs, \n",
    "            corr_df=corr_df, \n",
    "        )\n",
    "    print(\"Work from {} to {} ends\".format(my_work_pool[0], my_work_pool[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1021cdc8-5070-4b0e-8d04-0a49b7ad6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiprocessManager: \n",
    "    def __init__(self, fun, my_wave_dir, my_anno_dir, my_save_dir, my_log_dir, my_params, num_workers=4): \n",
    "        self.fun = fun\n",
    "        self.my_wave_dir = my_wave_dir\n",
    "        self.my_anno_dir = my_anno_dir\n",
    "        self.my_save_dir = my_save_dir\n",
    "        self.my_log_dir = my_log_dir\n",
    "        self.my_params = my_params\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def divide_work(self, work):\n",
    "        # determine the number of items per worker\n",
    "        items_per_worker = math.ceil(len(work) / self.num_workers)\n",
    "\n",
    "        # divide the work into chunks\n",
    "        work_chunks = [work[i:i + items_per_worker] for i in range(0, len(work), items_per_worker)]\n",
    "\n",
    "        return work_chunks\n",
    "    \n",
    "    def collaboration_work(self): \n",
    "        flat_tasks = os.listdir(self.my_wave_dir)\n",
    "        task_pools = self.divide_work(flat_tasks)\n",
    "        print(self.num_workers)\n",
    "        p = Pool(self.num_workers)\n",
    "        for i in range(self.num_workers):\n",
    "            p.apply_async(collaboration_single_work, args=(task_pools[i], self.fun, self.my_wave_dir, self.my_anno_dir, self.my_save_dir, self.my_log_dir, self.my_params, ))\n",
    "        print('Waiting for all subprocesses done...')\n",
    "        p.close()\n",
    "        p.join()\n",
    "        print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a416c2c-dd64-4af7-9902-73bf80192d01",
   "metadata": {},
   "source": [
    "## Run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738eb8b3-a57d-4cea-a594-55d01618d1bd",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a612d40d-dfb6-4065-8205-86a1b255ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpm = MultiprocessManager(open_and_cut_phones_random_sampling, wav_path, phones_extract_path, phone_seg_random_path, phone_seg_random_log_path, params, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fbbce3-c754-4115-917b-6e25071db902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Working from s4002a.wav to s1101a.wavWorking from s2402b.wav to s3601b.wavWorking from s0504a.wav to s2502a.wavWorking from s1001b.wav to s1202a.wavWorking from s0203b.wav to s3701a.wavWorking from s1901a.wav to s0101b.wavWorking from s0202b.wav to s3502b.wavWorking from s3402a.wav to s0302a.wav\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Waiting for all subprocesses done...\n",
      "Work from s0504a.wav to s2502a.wav ends\n",
      "Work from s0203b.wav to s3701a.wav ends\n",
      "Work from s4002a.wav to s1101a.wav ends\n",
      "Work from s2402b.wav to s3601b.wav ends\n",
      "Work from s1901a.wav to s0101b.wav ends\n",
      "Work from s0202b.wav to s3502b.wav ends\n",
      "Work from s1001b.wav to s1202a.wav ends\n",
      "Work from s3402a.wav to s0302a.wav ends\n",
      "All subprocesses done.\n"
     ]
    }
   ],
   "source": [
    "mpm.collaboration_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31545bb1-f07f-4e4e-8e79-ad96510ff42a",
   "metadata": {},
   "source": [
    "#### Bind csvs into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a503866-cbf3-4da4-82ce-74fca4a974b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the CSV files in the directory that start with 's'\n",
    "directory = phone_seg_random_log_path\n",
    "csv_files = sorted([f for f in os.listdir(directory) if f.startswith('s') and f.endswith('.csv')])\n",
    "\n",
    "# Read and concatenate the CSV files using pandas\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory, file))\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataframe as \"log.csv\"\n",
    "concatenated_df.to_csv(os.path.join(directory, 'log.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e8a5a-3559-488b-abc5-1d287e50827d",
   "metadata": {},
   "source": [
    "### Aligned Cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5820d018-e1bd-48fe-9fb5-538e293e6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpm = MultiprocessManager(open_and_cut_phones, wav_path, phones_extract_path, phone_seg_anno_path, phone_seg_anno_log_path, params, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1decb493-716c-40e6-8ab6-a52fdf3e7552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Working from s4002a.wav to s1101a.wavWorking from s0504a.wav to s2502a.wavWorking from s2402b.wav to s3601b.wavWorking from s1901a.wav to s0101b.wavWorking from s0202b.wav to s3502b.wavWorking from s0203b.wav to s3701a.wavWorking from s1001b.wav to s1202a.wav\n",
      "\n",
      "Working from s3402a.wav to s0302a.wav\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Waiting for all subprocesses done...\n",
      "Work from s0504a.wav to s2502a.wav ends\n",
      "Work from s0203b.wav to s3701a.wav ends\n",
      "Work from s0202b.wav to s3502b.wav ends\n",
      "Work from s1001b.wav to s1202a.wav ends\n",
      "Work from s4002a.wav to s1101a.wav ends\n",
      "Work from s1901a.wav to s0101b.wav ends\n",
      "Work from s3402a.wav to s0302a.wav ends\n",
      "Work from s2402b.wav to s3601b.wav ends\n",
      "All subprocesses done.\n"
     ]
    }
   ],
   "source": [
    "mpm.collaboration_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43746849-0539-43f7-bfa7-09f55a40f063",
   "metadata": {},
   "source": [
    "#### Bind csvs into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a422691c-1771-4cce-9ac9-a4b71d35d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the CSV files in the directory that start with 's'\n",
    "directory = phone_seg_anno_log_path\n",
    "csv_files = sorted([f for f in os.listdir(directory) if f.startswith('s') and f.endswith('.csv')])\n",
    "\n",
    "# Read and concatenate the CSV files using pandas\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory, file))\n",
    "    dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataframe as \"log.csv\"\n",
    "concatenated_df.to_csv(os.path.join(directory, 'log.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa7e60-c94a-42a4-b8bc-18af4d19e8b4",
   "metadata": {},
   "source": [
    "### Zip to ease later data transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ef30a3-aff2-44c7-9995-83941a4b81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../src/bsc/phone_seg_random/ has been zipped to phone_seg_random.zip!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # Iterate over all the files in the directory\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            # Get the full path of the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Add the file to the zip archive\n",
    "            ziph.write(file_path)\n",
    "\n",
    "# Name of the zip file to create\n",
    "zip_name = 'phone_seg_random.zip'\n",
    "\n",
    "# Path of the directory to be zipped\n",
    "dir_path = phone_seg_random_path\n",
    "\n",
    "# Create a ZipFile object with the zip file name and mode\n",
    "zipf = zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED)\n",
    "\n",
    "# Call the zipdir function to add the directory to the zip archive\n",
    "zipdir(dir_path, zipf)\n",
    "\n",
    "# Close the zip file\n",
    "zipf.close()\n",
    "\n",
    "print(f'{dir_path} has been zipped to {zip_name}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dce87d-23c6-45f1-8759-b2c760a66a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
