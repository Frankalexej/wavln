{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mljeGlqMqo"
   },
   "source": [
    "# Sequence Learning - Direct - English - Testing Session - Phoneme Plots\n",
    "20230921: Progression plot of single phonemes.  \n",
    "Written after finding out the failure of model learning representation of phonemes but only remenbering occurrance \n",
    "orders. This is bad, since what we wanted to see was that the model could separate the different phonemes (at least phones).   \n",
    "However, it remains a doubt whether the model has learned the conditional & nonconditional distribution of \n",
    "phonemes, despite not learning them separately. That is to say, we want to know whether the model has learned to put phonemes\n",
    "that love to stay in very distinct phonological contexts into distinct places OR whether the model can only distinguish this \n",
    "when they are in the context. That is, ex. whether /ng/ will be projected to ONSET community if being fed alone or it will \n",
    "be projected to CODA community like when fed with words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jN5DNuExjwet"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padding import generate_mask_from_lengths_mat, mask_it\n",
    "from paths import *\n",
    "from my_utils import *\n",
    "from loss import *\n",
    "from model import SimplerPhxLearner\n",
    "from dataset import SeqDatasetAnno, MelSpecTransform\n",
    "from my_dataset import DS_Tools\n",
    "from reshandler import AnnoEncoderResHandler\n",
    "from misc_progress_bar import draw_progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "iGouCDYD3h18"
   },
   "outputs": [],
   "source": [
    "model_save_dir = model_eng_save_dir\n",
    "\n",
    "log_path = phone_seg_anno_log_path\n",
    "rec_path = phone_seg_anno_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "INPUT_DIM = 64\n",
    "OUTPUT_DIM = 64\n",
    "\n",
    "INTER_DIM_0 = 32\n",
    "INTER_DIM_1 = 16\n",
    "INTER_DIM_2 = 3\n",
    "\n",
    "ENC_SIZE_LIST = [INPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "DEC_SIZE_LIST = [OUTPUT_DIM, INTER_DIM_0, INTER_DIM_1, INTER_DIM_2]\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "REC_SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "N_MELS = 64\n",
    "\n",
    "LOADER_WORKER = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-related defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "lUxoYBUg1jLq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "masked_recon_loss = MaskedLoss(recon_loss)\n",
    "model_loss = masked_recon_loss\n",
    "\n",
    "model = SimplerPhxLearner(enc_size_list=ENC_SIZE_LIST, dec_size_list=DEC_SIZE_LIST, num_layers=2)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ts = \"0918192113\"\n",
    "stop_epoch = \"299\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimplerPhxLearner(\n",
       "  (encoder): RLEncoder(\n",
       "    (rnn): LSTM(64, 16, num_layers=2, batch_first=True)\n",
       "    (lin_2): LinearPack(\n",
       "      (linear): Linear(in_features=16, out_features=3, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RALDecoder(\n",
       "    (rnn): LSTM(64, 3, num_layers=2, batch_first=True)\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (w_q): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_k): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (w_v): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (lin_3): LinearPack(\n",
       "      (linear): Linear(in_features=3, out_features=64, bias=True)\n",
       "      (relu): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw_name = \"PT_{}_{}_full\".format(load_ts, stop_epoch)\n",
    "model_name = model_raw_name + \".pt\"\n",
    "model_path = os.path.join(model_save_dir, model_name)\n",
    "state = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that due to the separate setting of word and phone datasets, we cannot really make it to select those that have not been trained on \n",
    "for this test. This is a point to further fix. Make reference to out first work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6OCx4nqP40fz"
   },
   "outputs": [],
   "source": [
    "mytrans = MelSpecTransform(sample_rate=REC_SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)\n",
    "ds = SeqDatasetAnno(rec_path, os.path.join(log_path, \"log.csv\"), transform=mytrans)\n",
    "\n",
    "# valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, \"valid_ds_{}.pkl\".format(load_ts)))\n",
    "\n",
    "# valid_ds = torch.utils.data.Subset(ds, valid_ds_indices)\n",
    "\n",
    "# this is to reduce the size of the dataset when the training power is not sufficient\n",
    "small_len = int(0.05 * len(ds))\n",
    "other_len = len(ds) - small_len\n",
    "\n",
    "# # Randomly split the dataset into train and validation sets\n",
    "valid_ds, other_ds = random_split(ds, [small_len, other_len])\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKER, collate_fn=SeqDatasetAnno.collate_fn)\n",
    "valid_num = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41640"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(): \n",
    "    model.eval()\n",
    "    reshandler = AnnoEncoderResHandler(whole_res_dir=phone_plot_res_path, file_prefix=model_raw_name)\n",
    "    all_res = np.empty((0, 3))\n",
    "    all_token = []\n",
    "    all_name = []\n",
    "\n",
    "    log_token = []  # for making csv to map sound to filename\n",
    "    log_name = []\n",
    "\n",
    "    total = len(valid_loader)\n",
    "\n",
    "    for idx, (x, x_lens, token, name) in enumerate(valid_loader): \n",
    "        token = token[0]\n",
    "        name = name[0]\n",
    "\n",
    "        x_mask = generate_mask_from_lengths_mat(x_lens, device=device)\n",
    "        \n",
    "        x = x.to(device)\n",
    "\n",
    "        hid_r = model.encode(x, x_lens, x_mask)\n",
    "\n",
    "        hid_r = hid_r.cpu().detach().numpy().squeeze()\n",
    "\n",
    "        length = hid_r.shape[0]\n",
    "\n",
    "        all_res = np.concatenate((all_res, hid_r), axis=0)\n",
    "        all_token += [token] * length\n",
    "        all_name += [name] * length\n",
    "        log_token += [token]\n",
    "        log_name += [name]\n",
    "\n",
    "        if idx % 100 == 0: \n",
    "            draw_progress_bar(idx, total)\n",
    "    \n",
    "\n",
    "    reshandler.res = all_res\n",
    "    reshandler.tok = all_token\n",
    "    reshandler.name = all_name\n",
    "    reshandler.save()\n",
    "\n",
    "    # save guideline\n",
    "    df = pd.DataFrame({'Name': log_name, 'Token': log_token})\n",
    "    df.to_csv(os.path.join(phone_plot_res_path, model_raw_name + '_guide.csv'), index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 99%"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manyOuts2progFrame(manyOuts, groups): \n",
    "    df = pd.DataFrame(manyOuts, columns=[\"dim_0\", \"dim_1\", \"dim_2\"])\n",
    "    df[\"name\"] = groups\n",
    "\n",
    "    df = df.sort_values(by=[\"name\"])\n",
    "    # Group the DataFrame by the grouping column and assign timesteps within each group\n",
    "    df['timestep'] = df.groupby(\"name\").cumcount() + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneOut2ProgFrame(oneOut): \n",
    "    # oneOut is of tensor of shape (L, D)\n",
    "    df = pd.DataFrame(oneOut, columns=[\"dim_0\", \"dim_1\", \"dim_2\"])\n",
    "    df[\"timestep\"] = df.index\n",
    "    df = df[[\"timestep\", \"dim_0\", \"dim_1\", \"dim_2\"]]\n",
    "    return df\n",
    "def minmax(arr, a=-1, b=1): \n",
    "    min = arr.min()\n",
    "    max = arr.max()\n",
    "    return (b - a) * ((arr - min) / (max - min)) + a\n",
    "def operate_on(arr): \n",
    "    # return minmax(arr)\n",
    "    return arr\n",
    "def framify(these_hids): \n",
    "    # these are token categories to be included\n",
    "    # these hids are the corresponding hids\n",
    "    # these numtags are the corresponding tags, named using indices in these\n",
    "    # these_hids = st.zscore(these_hids, axis=0)\n",
    "    df = pd.DataFrame(data=these_hids)\n",
    "    # df = df.rename(columns={0: \"dim_0\", 1: \"dim_1\", 2: \"dim_2\"})\n",
    "    df['dim_0_norm'] = operate_on(df['dim_0'])\n",
    "    df['dim_1_norm'] = operate_on(df['dim_1'])\n",
    "    df['dim_2_norm'] = operate_on(df['dim_2'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framify_group(these_hids, these_tags): \n",
    "    # these are token categories to be included\n",
    "    # these hids are the corresponding hids\n",
    "    # these numtags are the corresponding tags, named using indices in these\n",
    "    # these_hids = st.zscore(these_hids, axis=0)\n",
    "    df = pd.DataFrame(data=these_hids)\n",
    "    df = df.rename(columns={0: \"dim_0\", 1: \"dim_1\", 2: \"dim_2\"})\n",
    "    df['dim_0_norm'] = operate_on(df['dim_0'])\n",
    "    df['dim_1_norm'] = operate_on(df['dim_1'])\n",
    "    df['dim_2_norm'] = operate_on(df['dim_2'])\n",
    "\n",
    "    df[\"Tag\"] = these_tags\n",
    "    return df\n",
    "def plot3dGroup(X, y): \n",
    "    df = framify_group(X, y)\n",
    "    config = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        'filename': 'custom_image',\n",
    "        'height': 1280,\n",
    "        'width': 1280,\n",
    "        'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "    }\n",
    "    fig = px.scatter_3d(df, x=\"dim_0_norm\", y=\"dim_1_norm\", z=\"dim_2_norm\",\n",
    "                color='Tag')\n",
    "    fig.update_traces(marker=dict(size=2),\n",
    "                    selector=dict(mode='markers'))\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        yaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        zaxis = dict(nticks=8, range=[-1,1],),),)\n",
    "    fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "    fig.update_layout(legend_title_text='Class')\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0,\n",
    "            y=1,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=36,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            # bgcolor=\"LightSteelBlue\",\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    )\n",
    "    camera = dict(\n",
    "        eye=dict(x=0., y=0., z=2.5)\n",
    "    )\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    html_plot = fig.to_html(full_html=False, config=config)\n",
    "    # fig.show(config=config)\n",
    "    return html_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3dtrajectory(X): \n",
    "    config = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        'filename': 'custom_image',\n",
    "        'height': 1280,\n",
    "        'width': 1280,\n",
    "        'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "    }\n",
    "\n",
    "    fig = px.line_3d(framify(X), x=\"dim_0_norm\", y=\"dim_1_norm\", z=\"dim_2_norm\", \n",
    "                     hover_data=[\"timestep\"], markers=True)\n",
    "    fig.update_traces(marker=dict(size=2, color=\"red\"))\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        yaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        zaxis = dict(nticks=8, range=[-1,1],),),)\n",
    "    # fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "    # fig.update_layout(legend_title_text='Phone')\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0,\n",
    "            y=1,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=36,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            # bgcolor=\"LightSteelBlue\",\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    )\n",
    "    camera = dict(\n",
    "        eye=dict(x=0., y=0., z=2.5)\n",
    "    )\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    html_plot = fig.to_html(full_html=False, config=config)\n",
    "    # fig.show(config=config)\n",
    "    return html_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3dtrajectoryAndGroup(X): \n",
    "    config = {\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        'filename': 'custom_image',\n",
    "        'height': 1280,\n",
    "        'width': 1280,\n",
    "        'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "    }\n",
    "\n",
    "    fig = px.line_3d(framify(X), x=\"dim_0_norm\", y=\"dim_1_norm\", z=\"dim_2_norm\", \n",
    "                     hover_data=[\"timestep\"], color=\"name\", markers=True)\n",
    "    fig.update_traces(marker=dict(size=2, color=\"red\"))\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        yaxis = dict(nticks=8, range=[-1,1],),\n",
    "                        zaxis = dict(nticks=8, range=[-1,1],),),)\n",
    "    # fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "    # fig.update_layout(legend_title_text='Phone')\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0,\n",
    "            y=1,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=36,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            # bgcolor=\"LightSteelBlue\",\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    )\n",
    "    camera = dict(\n",
    "        eye=dict(x=0., y=0., z=2.5)\n",
    "    )\n",
    "    fig.update_layout(scene_camera=camera)\n",
    "    html_plot = fig.to_html(full_html=False, config=config)\n",
    "    # fig.show(config=config)\n",
    "    return html_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html_traj(htmlplot, save_name, token, model_serialnum=\"\"): \n",
    "    save_html_path = os.path.join(phone_plot_path, \"traj_{}-{}_{}.html\".format(token, model_serialnum, save_name))\n",
    "    with open(save_html_path, \"w\") as f: \n",
    "        f.write('<meta charset=\"UTF-8\">')\n",
    "        f.write(\"<h3>Rec: {}</h3>\".format(save_name))\n",
    "        f.write(\"<h3>Token: {}</h3>\".format(token))\n",
    "        f.write(\"<hr>\")\n",
    "        f.write(htmlplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html_phone(htmlplot, save_name, token, model_serialnum=\"\"): \n",
    "    save_html_path = os.path.join(phone_plot_path, \"phone_{}_{}.html\".format(save_name, model_serialnum))\n",
    "    with open(save_html_path, \"w\") as f: \n",
    "        f.write('<meta charset=\"UTF-8\">')\n",
    "        f.write(\"<h3>Rec: {}</h3>\".format(save_name))\n",
    "        f.write(\"<h3>Token: {}</h3>\".format(token))\n",
    "        f.write(\"<hr>\")\n",
    "        f.write(htmlplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshandler = AnnoEncoderResHandler(whole_res_dir=phone_plot_res_path, file_prefix=model_raw_name)\n",
    "reshandler.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(data, guide, selector):\n",
    "    # Ensure that the lengths of annotations and data_array match\n",
    "    if len(guide) != data.shape[0]:\n",
    "        raise ValueError(\"The length of guide must match the number of items in the data.\")\n",
    "\n",
    "    # Create a boolean mask for selected annotations\n",
    "    mask = np.isin(guide, selector)\n",
    "\n",
    "    # Use the mask to select the corresponding items from the data array\n",
    "    selected_items = data[mask]\n",
    "\n",
    "    return selected_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by Phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get usable cluster groups\n",
    "cluster_groups = [\"aa\", \"uw\"]\n",
    "\n",
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.tok, \n",
    "                 selector=cluster_groups)\n",
    "tags_cs = select(data=np.array(reshandler.tok), \n",
    "                 guide=reshandler.tok, \n",
    "                 selector=cluster_groups)\n",
    "\n",
    "htmlplot = plot3dGroup(hidr_cs, tags_cs)\n",
    "save_html_phone(htmlplot=htmlplot, save_name=\"{}\".format(\"-\".join(cluster_groups)), token=\" \".join(cluster_groups), model_serialnum=model_raw_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_df = pd.read_csv(os.path.join(phone_plot_res_path, \"{}_guide.csv\".format(model_raw_name)))\n",
    "total_len = len(guide_df[\"Name\"].tolist())\n",
    "\n",
    "all_name = guide_df[\"Name\"]\n",
    "all_token = guide_df[\"Token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "randidx = random.randint(0, total_len)\n",
    "save_name = all_name[randidx]\n",
    "token = all_token[randidx]\n",
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.name, \n",
    "                 selector=[save_name])\n",
    "res_df = oneOut2ProgFrame(hidr_cs)\n",
    "res_df = framify(res_df)\n",
    "htmlplot = plot3dtrajectory(res_df)\n",
    "save_html_traj(htmlplot, save_name, token=token, model_serialnum=model_raw_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by phoneme and rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_df = pd.read_csv(os.path.join(phone_plot_res_path, \"{}_guide.csv\".format(model_raw_name)))\n",
    "total_len = len(guide_df[\"Name\"].tolist())\n",
    "\n",
    "all_name = guide_df[\"Name\"].to_numpy()\n",
    "all_token = guide_df[\"Token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token = \"aan\"\n",
    "\n",
    "names_by_token = select(data=all_name, \n",
    "                        guide=all_token, \n",
    "                        selector=[target_token])\n",
    "names_by_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 8\n",
    "random_subset_names_by_token = np.random.choice(names_by_token, size=subset_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidr_cs = select(data=reshandler.res, \n",
    "                 guide=reshandler.name, \n",
    "                 selector=random_subset_names_by_token)\n",
    "tags_cs = select(data=np.array(reshandler.name), \n",
    "                 guide=reshandler.name, \n",
    "                 selector=random_subset_names_by_token)\n",
    "\n",
    "res_df = manyOuts2progFrame(hidr_cs, tags_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = framify(res_df)\n",
    "htmlplot = plot3dtrajectoryAndGroup(res_df)\n",
    "save_html_traj(htmlplot, \"rand-{}\".format(subset_size), token=target_token, model_serialnum=model_raw_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
